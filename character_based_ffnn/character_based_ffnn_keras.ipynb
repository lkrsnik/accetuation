{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import unicode_literals\n",
    "# text in Western (Windows 1252)\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import load_model\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run ../prepare_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING CONTENT...\n",
      "CONTENT READ SUCCESSFULY\n",
      "CREATING DICTIONARY...\n",
      "DICTIONARY CREATION SUCCESSFUL!\n",
      "HERE!\n",
      "2018553\n"
     ]
    }
   ],
   "source": [
    "dictionary, max_word, max_num_vowels, content, vowels, accetuated_vowels = create_dict()\n",
    "print('HERE!')\n",
    "num = count_vowels(content, vowels)\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING CONTENT...\n",
      "CONTENT READ SUCCESSFULY\n",
      "CREATING DICTIONARY...\n",
      "DICTIONARY CREATION SUCCESSFUL!\n",
      "1.85924481321\n",
      "GENERATING X AND y...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-a30f91275e08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# X, y = load_inputs('shuffeled_full_matrix_inputs.h5')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_pure\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_full_vowel_matrix_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/luka/Developement/masters/character_based_learning/prepare_data.py\u001b[0m in \u001b[0;36mgenerate_full_vowel_matrix_inputs\u001b[1;34m()\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;31m# X = np.zeros((len(content), max_word*len(dictionary)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_num_vowels\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmax_num_vowels\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2018553\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m     \u001b[1;31m# X_pure = []\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;31m# X = []\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# X, y = generate_inputs()\n",
    "# save_inputs('ordered_inputs.h5', X, y)\n",
    "# X, y = load_inputs('ordered_inputs.h5')\n",
    "\n",
    "# X, y = generate_matrix_inputs()\n",
    "# save_inputs('ordered_matrix_inputs.h5', X, y)\n",
    "# X, y = load_inputs('ordered_matrix_inputs.h5')\n",
    "\n",
    "# X, y = generate_full_matrix_inputs()\n",
    "# save_inputs('shuffeled_full_matrix_inputs.h5', X, y)\n",
    "# X, y = load_inputs('shuffeled_full_matrix_inputs.h5')\n",
    "\n",
    "X, y, X_pure = generate_full_vowel_matrix_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(536432, 23, 43)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING CONTENT...\n",
      "CONTENT READ SUCCESSFULY\n",
      "CREATING DICTIONARY...\n",
      "DICTIONARY CREATION SUCCESSFUL!"
     ]
    }
   ],
   "source": [
    "testX, testY = generate_full_vowel_matrix_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X = X[:100000]\n",
    "# y = y[:100000]\n",
    "# def unison_shuffled_copies(a, b):\n",
    "#     assert len(a) == len(b)\n",
    "#     p = np.random.permutation(len(a))\n",
    "#     return a[p], b[p]\n",
    "# X, y = unison_shuffled_copies(X, y)\n",
    "# print X.shape\n",
    "\n",
    "# train_X = X.astype(np.float32)\n",
    "# train_y = y.astype(np.int32)\n",
    "\n",
    "num_examples = len(X) # training set size\n",
    "# nn_input_dim = max_word * len(dictionary) # input layer dimensionality\n",
    "# nn_output_dim = max_num_vowels * max_num_vowels # output layer dimensionality\n",
    "nn_output_dim = 121\n",
    "nn_hdim = 516\n",
    "\n",
    "# Gradient descent parameters (I picked these by hand)\n",
    "# epsilon = 1 # learning rate for gradient descent\n",
    "# reg_lambda = 1 # regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, (3, 3), input_shape=(3, 32, 32), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "\n",
    "# create model\n",
    "# model = Sequential()\n",
    "# model.add(Conv1D(43, (3), input_shape=(23, 43), padding='same', activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Conv1D(43, (3), padding='same', activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Conv1D(86, (3), padding='same', activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Conv1D(86, (3), padding='same', activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Conv1D(172, (3), padding='same', activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Conv1D(172, (3), padding='same', activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# # model.add(Conv1D(43, (3), input_shape=(None, 43), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(1032, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(516, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(nn_output_dim, activation='softmax'))\n",
    "\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(43, (3), input_shape=(23, 43), padding='same', activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(43, (3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Conv1D(43, (3), input_shape=(None, 43), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(1032, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(516, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nn_output_dim, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "lrate = 0.1\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Compile model\n",
    "# model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "429145/429145 [==============================] - 1474s - loss: 8.9041e-04 - acc: 0.9352  \n",
      "Epoch 2/5\n",
      "429145/429145 [==============================] - 1515s - loss: 8.6358e-04 - acc: 0.9371  \n",
      "Epoch 3/5\n",
      "429145/429145 [==============================] - 1578s - loss: 8.4486e-04 - acc: 0.9392  \n",
      "Epoch 4/5\n",
      "429145/429145 [==============================] - 1566s - loss: 8.3320e-04 - acc: 0.9396  \n",
      "Epoch 5/5\n",
      "429145/429145 [==============================] - 1595s - loss: 8.1393e-04 - acc: 0.9416  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8472c5a710>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit_generator((X, y), 536432/2, epochs=5)\n",
    "# testX = X[:536432/16]\n",
    "# print testX.shape\n",
    "# testY = y[:536432/16]\n",
    "# print testY.shape\n",
    "model.fit(X[:429145], y[:429145], epochs=5, batch_size=10)\n",
    "# model.fit(X, y, epochs=5, validation_split=0.2, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('cnn_i2_s_c43-3relu_d20_c43-3relu_mp2_f_516relu_d20_121sigmoid_mse_adam_a65_10epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('cnn_i2_s_c43-3relu_d20_c43-3relu_mp2_f_516relu_d20_121sigmoid_mse_adam_a65.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107232/107287 [============================>.] - ETA: 0s\n",
      "acc: 96.52%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X[429145:], y[429145:])\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# calculate predictions\n",
    "# test = generate_input_from_word('test', max_word, dictionary)\n",
    "# print test.shape\n",
    "# print test.T.shape\n",
    "predictions = model.predict(np.array([generate_input_from_word('biotski', max_word, dictionary)]))\n",
    "# round predictions\n",
    "\n",
    "print decode_position(predictions[0], max_num_vowels)\n",
    "\n",
    "b_pred = 0\n",
    "ind = 0\n",
    "i = 0\n",
    "for el in predictions[0]:\n",
    "    if b_pred < el:\n",
    "        b_pred = el\n",
    "        ind = i\n",
    "    i += 1\n",
    "    \n",
    "print(ind)\n",
    "# rounded = [round(x[0]) for x in predictions]\n",
    "# print(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print max_num_vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING CONTENT...\n",
      "CONTENT READ SUCCESSFULY\n",
      "CREATING DICTIONARY...\n",
      "DICTIONARY CREATION SUCCESSFUL!\n"
     ]
    }
   ],
   "source": [
    "dictionary, max_word, max_num_vowels, content, vowels, accetuated_vowels = create_dict()\n",
    "def generate_input_from_word(word, max_word, dictionary):\n",
    "    x = np.zeros((max_word, len(dictionary)))\n",
    "    j = 0\n",
    "    for c in list(word):\n",
    "        index = 0\n",
    "        for d in dictionary:\n",
    "            if c == d:\n",
    "                x[j, index] = 1\n",
    "                break\n",
    "            index += 1\n",
    "        j += 1\n",
    "    return x\n",
    "\n",
    "# model = load_model()\n",
    "# prediction = predict(model, generate_input_from_word('hidrija'))\n",
    "# print decode_position(prediction[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
