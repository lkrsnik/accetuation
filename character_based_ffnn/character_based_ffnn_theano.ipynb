{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import unicode_literals\n",
    "# text in Western (Windows 1252)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import matplotlib\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import pydot\n",
    "from IPython.display import Image\n",
    "from IPython.display import SVG\n",
    "import timeit\n",
    "\n",
    "# Display plots inline and change default figure size\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "file_name = 'data_theano.h5'\n",
    "\n",
    "def save_model(model):\n",
    "#     a = np.random.random(size=(100,20))\n",
    "#     h5f.close()\n",
    "    h5f = h5py.File(file_name, 'w')\n",
    "    adict=dict(W1=model['W1'], b1=model['b1'], W2=model['W2'], b2=model['b2'])\n",
    "    for k,v in adict.items():\n",
    "        h5f.create_dataset(k,data=v)\n",
    "\n",
    "#     h5f.create_dataset('dataset_1', data=model)\n",
    "    h5f.close()\n",
    "\n",
    "def load_model():\n",
    "    h5f = h5py.File(file_name,'r')\n",
    "    model = {}\n",
    "    W1.set_value(h5f['W1'][:])\n",
    "    b1.set_value(h5f['b1'][:])\n",
    "    W2.set_value(h5f['W2'][:])\n",
    "    b2.set_value(h5f['b2'][:])\n",
    "#     model['W1'] = h5f['W1'][:]\n",
    "#     model['b1'] = h5f['b1'][:]\n",
    "#     model['W2'] = h5f['W2'][:]\n",
    "#     model['b2'] = h5f['b2'][:]\n",
    "    h5f.close()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../../data/SlovarIJS_BESEDE_utf8.lex') as f:\n",
    "    content = f.readlines()\n",
    "content = [x.decode('utf8').split('\\t') for x in content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CREATE dictionary AND max_word\n",
    "accetuated_vowels = [u'à', u'á', u'ä', u'é', u'ë', u'ì', u'í', u'î', u'ó', u'ô', u'ö', u'ú', u'ü']\n",
    "default_vowels = [u'a', u'e', u'i', u'o', u'u']\n",
    "vowels = []\n",
    "vowels.extend(accetuated_vowels)\n",
    "vowels.extend(default_vowels)\n",
    "def is_vowel(word_list, position):\n",
    "    if word_list[position] in vowels:\n",
    "        return True\n",
    "    if word_list[position] == u'r' and \\\n",
    "    (position - 1 < 0 or word_list[position - 1] not in vowels) and \\\n",
    "    (position + 1 >= len(word_list) or word_list[position + 1] not in vowels):\n",
    "        return True\n",
    "    return False\n",
    "        \n",
    "    \n",
    "\n",
    "dictionary = ['']\n",
    "line = 0\n",
    "max_word = 0\n",
    "# ADD 'EMPTY' VOWEL\n",
    "max_num_vowels = 0\n",
    "for el in content:\n",
    "    num_vowels = 0\n",
    "    i = 0\n",
    "    try: \n",
    "        if len(el[3]) > max_word:\n",
    "            max_word = len(el[3])\n",
    "#             print line\n",
    "        if len(el[0]) > max_word:\n",
    "            max_word = len(el[0])\n",
    "            print line\n",
    "        for c in list(el[3]):\n",
    "            if is_vowel(list(el[3]), i):\n",
    "                num_vowels += 1\n",
    "            if c not in dictionary:\n",
    "                dictionary.append(c)\n",
    "            i += 1\n",
    "        for c in list(el[0]):\n",
    "            if c not in dictionary:\n",
    "                dictionary.append(c)\n",
    "        if num_vowels > max_num_vowels:\n",
    "            max_num_vowels = num_vowels\n",
    "#             print line\n",
    "    except Exception, e:\n",
    "        print line - 1\n",
    "        print el\n",
    "    line += 1\n",
    "dictionary = sorted(dictionary)\n",
    "max_num_vowels += 1\n",
    "\n",
    "# for e in dictionary:\n",
    "#     print e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GENERATE X and y\n",
    "def generate_presentable_y(accetuations_list, word_list):\n",
    "#     print accetuations_list\n",
    "#     print word_list\n",
    "    while len(accetuations_list) < 2:\n",
    "        accetuations_list.append(0)\n",
    "    if len(accetuations_list) > 2:\n",
    "        accetuations_list = accetuations_list[:2]\n",
    "#     empty has to be positive\n",
    "    accetuations_list = np.array(accetuations_list)\n",
    "#     accetuations_list += 1\n",
    "    final_position = accetuations_list[0] + max_num_vowels * accetuations_list[1]\n",
    "    return final_position\n",
    "    \n",
    "\n",
    "X = np.zeros((len(content), max_word*len(dictionary)))\n",
    "y = np.zeros((len(content), max_num_vowels * max_num_vowels ))\n",
    "\n",
    "\n",
    "i = 0\n",
    "for el in content:\n",
    "    j = 0\n",
    "    for c in list(el[0]):\n",
    "        index = 0\n",
    "        for d in dictionary:\n",
    "            if c == d:\n",
    "                X[i][index + j * max_word] = 1\n",
    "                break\n",
    "            index += 1\n",
    "        j += 1\n",
    "    j = 0\n",
    "    word_accetuations = []\n",
    "    num_vowels = 0\n",
    "    for c in list(el[3]):\n",
    "        index = 0\n",
    "#         in_dict = False\n",
    "        if is_vowel(el[3], j):\n",
    "            num_vowels += 1\n",
    "        for d in accetuated_vowels:\n",
    "#             print c\n",
    "#             print d\n",
    "            if c == d:\n",
    "#                 print 'HERE!'\n",
    "                word_accetuations.append(num_vowels)\n",
    "#                 y[j * len(dictionary) + index][i] = 1\n",
    "#                 in_dict = True\n",
    "                break\n",
    "            index += 1\n",
    "#         if not in_dict:\n",
    "#             print 'NOOOOO!!!'\n",
    "#             print el\n",
    "#             print i\n",
    "        j += 1\n",
    "#     print len(y.T[i])\n",
    "#     print sum(y.T[i])\n",
    "    \n",
    "#     y = y.T\n",
    "    y[i][generate_presentable_y(word_accetuations, list(el[3]))] = 1\n",
    "#     print '---------------------------------'\n",
    "#     for a in y[i]:\n",
    "#         print a\n",
    "#     print sum(y[i])\n",
    "#     print y[:][i]\n",
    "#     if i > 100:\n",
    "#         break\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decode_position(y):\n",
    "    max_el = 0\n",
    "    i = 0\n",
    "    pos = -1\n",
    "#     pos = y.argmax(axis=0)\n",
    "    for el in y:\n",
    "#         print el\n",
    "        if el > max_el:\n",
    "            \n",
    "            max_el = el\n",
    "#             print 'HERE!!!'\n",
    "#             print pos\n",
    "            pos = i\n",
    "        i += 1\n",
    "    return [pos % max_num_vowels, pos / max_num_vowels]\n",
    "    \n",
    "decode_position(y[157303])\n",
    "# decode_position(y[157241])\n",
    "# print y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X[:100000]\n",
    "y = y[:100000]\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "X, y = unison_shuffled_copies(X, y)\n",
    "# print X.shape\n",
    "\n",
    "train_X = X.astype(np.float32)\n",
    "train_y = y.astype(np.int32)\n",
    "\n",
    "num_examples = len(X) # training set size\n",
    "nn_input_dim = max_word * len(dictionary) # input layer dimensionality\n",
    "nn_output_dim = max_num_vowels * max_num_vowels # output layer dimensionality\n",
    "nn_hdim = 500\n",
    "\n",
    "# Gradient descent parameters (I picked these by hand)\n",
    "epsilon = 1 # learning rate for gradient descent\n",
    "reg_lambda = 1 # regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_y.shape\n",
    "\n",
    "# Our data vectors\n",
    "X = T.matrix('X') # matrix of doubles\n",
    "y = T.lmatrix('y') # vector of doubles\n",
    "\n",
    "# Shared variables with initial values. We need to learn these.\n",
    "W1 = theano.shared(np.random.randn(nn_input_dim, nn_hdim), name='W1')\n",
    "b1 = theano.shared(np.zeros(nn_hdim), name='b1')\n",
    "W2 = theano.shared(np.random.randn(nn_hdim, nn_output_dim), name='W2')\n",
    "b2 = theano.shared(np.zeros(nn_output_dim), name='b2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Forward propagation\n",
    "# Note: We are just defining the expressions, nothing is evaluated here!\n",
    "z1 = X.dot(W1) + b1\n",
    "a1 = T.tanh(z1)\n",
    "z2 = a1.dot(W2) + b2\n",
    "y_hat = T.nnet.softmax(z2) # output probabilties\n",
    "\n",
    "# The regularization term (optional)\n",
    "loss_reg = 1./num_examples * reg_lambda/2 * (T.sum(T.sqr(W1)) + T.sum(T.sqr(W2))) \n",
    "# the loss function we want to optimize\n",
    "loss = T.nnet.categorical_crossentropy(y_hat, y).mean() + loss_reg\n",
    "# loss = T.nnet.binary_crossentropy(y_hat, y).mean() + loss_reg\n",
    "\n",
    "\n",
    "# Returns a class prediction\n",
    "prediction = T.argmax(y_hat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Theano functions that can be called from our Python code\n",
    "forward_prop = theano.function([X], y_hat)\n",
    "calculate_loss = theano.function([X, y], loss)\n",
    "predict = theano.function([X], prediction)\n",
    "\n",
    "# Example call: Forward Propagation\n",
    "# forward_prop([[1,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dW2 = T.grad(loss, W2)\n",
    "db2 = T.grad(loss, b2)\n",
    "dW1 = T.grad(loss, W1)\n",
    "db1 = T.grad(loss, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gradient_step = theano.function(\n",
    "    [X, y],\n",
    "    updates=((W2, W2 - epsilon * dW2),\n",
    "             (W1, W1 - epsilon * dW1),\n",
    "             (b2, b2 - epsilon * db2),\n",
    "             (b1, b1 - epsilon * db1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function learns parameters for the neural network and returns the model.\n",
    "# - num_passes: Number of passes through the training data for gradient descent\n",
    "# - print_loss: If True, print the loss every 1000 iterations\n",
    "def build_model(num_passes=125, print_loss=False):\n",
    "    \n",
    "    # Re-Initialize the parameters to random values. We need to learn these.\n",
    "    # (Needed in case we call this function multiple times)\n",
    "    np.random.seed(0)\n",
    "    W1.set_value(np.random.randn(nn_input_dim, nn_hdim) / np.sqrt(nn_input_dim))\n",
    "    b1.set_value(np.zeros(nn_hdim))\n",
    "    W2.set_value(np.random.randn(nn_hdim, nn_output_dim) / np.sqrt(nn_hdim))\n",
    "    b2.set_value(np.zeros(nn_output_dim))\n",
    "    \n",
    "    # Gradient descent. For each batch...\n",
    "    for i in xrange(0, num_passes):\n",
    "#         print type(W1)\n",
    "        save_model({'W1': W1.get_value(borrow=True), 'b1': b1.get_value(borrow=True), 'W2': W2.get_value(borrow=True), 'b2': b2.get_value(borrow=True)})\n",
    "        # This will update our parameters W2, b2, W1 and b1!\n",
    "        print 'NUM: ' + str(i)\n",
    "        gradient_step(train_X, train_y)\n",
    "        # Optionally print the loss.\n",
    "        # This is expensive because it uses the whole dataset, so we don't want to do it too often.\n",
    "        if print_loss and i % 25 == 0:\n",
    "            print \"Loss after iteration %i: %f\" %(i, calculate_loss(train_X, train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.int32'>\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "(100000, 989)\n",
      "(100000, 121)\n",
      "[[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print type(train_y[0][0])\n",
    "print train_X[:3]\n",
    "print train_X.shape\n",
    "print train_y.shape\n",
    "print train_y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM: 0\n",
      "Loss after iteration 0: 3.883366\n",
      "NUM: 1\n",
      "NUM: 2\n",
      "NUM: 3\n",
      "NUM: 4\n",
      "NUM: 5\n",
      "NUM: 6\n",
      "NUM: 7\n",
      "NUM: 8\n",
      "NUM: 9\n",
      "NUM: 10\n",
      "NUM: 11\n",
      "NUM: 12\n",
      "NUM: 13\n",
      "NUM: 14\n",
      "NUM: 15\n",
      "NUM: 16\n",
      "NUM: 17\n",
      "NUM: 18\n",
      "NUM: 19\n",
      "NUM: 20\n",
      "NUM: 21\n",
      "NUM: 22\n",
      "NUM: 23\n",
      "NUM: 24\n",
      "NUM: 25\n",
      "Loss after iteration 25: 1.222089\n",
      "NUM: 26\n",
      "NUM: 27\n",
      "NUM: 28\n",
      "NUM: 29\n",
      "NUM: 30\n",
      "NUM: 31\n",
      "NUM: 32\n",
      "NUM: 33\n",
      "NUM: 34\n",
      "NUM: 35\n",
      "NUM: 36\n",
      "NUM: 37\n",
      "NUM: 38\n",
      "NUM: 39\n",
      "NUM: 40\n",
      "NUM: 41\n",
      "NUM: 42\n",
      "NUM: 43\n",
      "NUM: 44\n",
      "NUM: 45\n",
      "NUM: 46\n",
      "NUM: 47\n",
      "NUM: 48\n",
      "NUM: 49\n",
      "NUM: 50\n",
      "Loss after iteration 50: 0.897985\n",
      "NUM: 51\n",
      "NUM: 52\n",
      "NUM: 53\n",
      "NUM: 54\n",
      "NUM: 55\n",
      "NUM: 56\n",
      "NUM: 57\n",
      "NUM: 58\n",
      "NUM: 59\n",
      "NUM: 60\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-177-fe299ce730f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Build a model with a 3-dimensional hidden layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprint_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Plot the decision boundary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplot_decision_boundary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-176-47d61b13ccc8>\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(num_passes, print_loss)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# This will update our parameters W2, b2, W1 and b1!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m'NUM: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mgradient_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;31m# Optionally print the loss.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# This is expensive because it uses the whole dataset, so we don't want to do it too often.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/luka/Developement/nn-from-scratch/venv/local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Build a model with a 3-dimensional hidden layer\n",
    "build_model(print_loss=True)\n",
    "\n",
    "# Plot the decision boundary\n",
    "plot_decision_boundary(lambda x: predict(x))\n",
    "plt.title(\"Decision Boundary for hidden layer size 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict([generate_input_from_word('testiram')])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "Unable to open file (Unable to open file: name = 'data_theano.h5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-3135a691c1f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerate_input_from_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hidrija'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mdecode_position\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-c5c8bfe2b56e>\u001b[0m in \u001b[0;36mload_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mh5f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/luka/Developement/nn-from-scratch/venv/local/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/luka/Developement/nn-from-scratch/venv/local/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/tmp/pip-nCYoKW-build/h5py/_objects.c:2840)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/tmp/pip-nCYoKW-build/h5py/_objects.c:2798)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open (/tmp/pip-nCYoKW-build/h5py/h5f.c:2117)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: Unable to open file (Unable to open file: name = 'data_theano.h5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "def generate_input_from_word(word):\n",
    "    x = np.zeros(max_word*len(dictionary))\n",
    "    j = 0\n",
    "    for c in list(word):\n",
    "        index = 0\n",
    "        for d in dictionary:\n",
    "            if c == d:\n",
    "                x[index + j * max_word] = 1\n",
    "                break\n",
    "            index += 1\n",
    "        j += 1\n",
    "    return x\n",
    "\n",
    "model = load_model()\n",
    "prediction = predict(model, generate_input_from_word('hidrija'))\n",
    "print decode_position(prediction[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
