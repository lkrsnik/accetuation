{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import unicode_literals\n",
    "# text in Western (Windows 1252)\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "# import StringIO\n",
    "import math\n",
    "from keras import optimizers, metrics\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import regularizers\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import load_model\n",
    "# from keras import backend as Input\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %run ../../../prepare_data.py\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../../')\n",
    "from prepare_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING DATA...\n",
      "LOAD SUCCESSFUL!\n"
     ]
    }
   ],
   "source": [
    "# %run ../../../prepare_data.py\n",
    "# X_train, X_other_features_train, y_train, X_test, X_other_features_test, y_test, X_validate, X_other_features_validate, y_validate = generate_syllable_inputs('../../internal_representations/inputs/content_shuffle_vector.h5', '../../internal_representations/inputs/shuffle_vector')\n",
    "# save_inputs('../../internal_representations/inputs/shuffeled_syllable_train_inputs.h5', X_train, y_train, other_features = X_other_features_train)\n",
    "# save_inputs('../../internal_representations/inputs/shuffeled_syllable_test_inputs.h5', X_test, y_test, other_features = X_other_features_test)\n",
    "# save_inputs('../../internal_representations/inputs/shuffeled_syllable_validate_inputs.h5', X_validate, y_validate,  other_features = X_other_features_validate)\n",
    "# X_train, X_other_features_train, y_train = load_inputs('../../internal_representations/inputs/shuffeled_syllable_train_inputs.h5', other_features=True)\n",
    "# X_test, X_other_features_test, y_test = load_inputs('../../internal_representations/inputs/shuffeled_syllable_test_inputs.h5', other_features=True)\n",
    "# X_validate, X_other_features_validate, y_validate = load_inputs('../../internal_representations/inputs/shuffeled_syllable_validate_inputs.h5', other_features=True)\n",
    "\n",
    "# syllable_letters_translator = create_syllable_letters_translator(max_syllable, syllable_dictionary, dictionary, vowels)\n",
    "\n",
    "data = Data('sl')\n",
    "data.generate_data('shuffled_syllable_reversed_train',\n",
    "                   'shuffled_syllable_reversed_test',\n",
    "                   'shuffled_syllable_reversed_validate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ../../../prepare_data.py\n",
    "gen = data.generator('train', 16)\n",
    "test = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 11, 252)\n",
      "na\n",
      "ja\n",
      "ktu\n",
      "a\n",
      "lnej\n",
      "Å¡a\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prints test word from generator\n",
    "# print(X_train[0])\n",
    "# print(syllable_dictionary[test[0][0][0][0].tolist().index(1)])\n",
    "print(np.array(test[0][0]).shape)\n",
    "for el in test[0][0][0]:\n",
    "    syllable = ''\n",
    "    for pos in range(0, len(el), 36):\n",
    "        syllable += data.decode_x([el[pos:pos+36]], dictionary)\n",
    "    print(syllable)\n",
    "#     print(el)\n",
    "    \n",
    "#     print(syllable_dictionary[el.tolist().index(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_examples = len(data.x_train) # training set size\n",
    "\n",
    "nn_output_dim = 10\n",
    "nn_hdim = 516\n",
    "batch_size = 16\n",
    "actual_epoch = 1\n",
    "num_fake_epoch = 20\n",
    "\n",
    "\n",
    "\n",
    "conv_input_shape=(10, 252)\n",
    "othr_input = (140, )\n",
    "\n",
    "conv_input = Input(shape=conv_input_shape, name='conv_input')\n",
    "# x_conv = Conv1D(43, (3), padding='same', activation='relu')(conv_input)\n",
    "x_conv = Conv1D(44, (3), padding='same', activation='relu')(conv_input)\n",
    "x_conv = MaxPooling1D(pool_size=2)(x_conv)\n",
    "x_conv = Flatten()(x_conv)\n",
    "# x_conv = Dense(516, activation='relu', kernel_constraint=maxnorm(3))(x_conv)\n",
    "\n",
    "othr_input = Input(shape=othr_input, name='othr_input')\n",
    "# x_othr = Dense(256, input_dim=167, activation='relu')(othr_input)\n",
    "# x_othr = Dropout(0.3)(x_othr)\n",
    "# x_othr = Dense(512, activation='relu')(othr_input)\n",
    "# x_othr = Dropout(0.3)(x_othr)\n",
    "# x_othr = Dense(256, activation='relu')(othr_input)\n",
    "\n",
    "x = concatenate([x_conv, othr_input])\n",
    "# x = Dense(1024, input_dim=(516 + 256), activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(nn_output_dim, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=[conv_input, othr_input], outputs=x)\n",
    "opt = optimizers.Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[actual_accuracy,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1345/1344 [==============================] - 25s - loss: 0.1859 - actual_accuracy: 0.3887 - val_loss: 0.1213 - val_actual_accuracy: 0.6196\n",
      "Epoch 2/20\n",
      "1345/1344 [==============================] - 27s - loss: 0.1119 - actual_accuracy: 0.6344 - val_loss: 0.1016 - val_actual_accuracy: 0.7090\n",
      "Epoch 3/20\n",
      "1345/1344 [==============================] - 27s - loss: 0.0980 - actual_accuracy: 0.7034 - val_loss: 0.0947 - val_actual_accuracy: 0.7462\n",
      "Epoch 4/20\n",
      "1345/1344 [==============================] - 28s - loss: 0.0913 - actual_accuracy: 0.7341 - val_loss: 0.0880 - val_actual_accuracy: 0.7577\n",
      "Epoch 5/20\n",
      "1345/1344 [==============================] - 28s - loss: 0.0854 - actual_accuracy: 0.7572 - val_loss: 0.0885 - val_actual_accuracy: 0.7638\n",
      "Epoch 6/20\n",
      "1345/1344 [==============================] - 29s - loss: 0.0795 - actual_accuracy: 0.7782 - val_loss: 0.0820 - val_actual_accuracy: 0.7883\n",
      "Epoch 7/20\n",
      "1345/1344 [==============================] - 30s - loss: 0.0755 - actual_accuracy: 0.7887 - val_loss: 0.0779 - val_actual_accuracy: 0.8140\n",
      "Epoch 8/20\n",
      "1345/1344 [==============================] - 30s - loss: 0.0725 - actual_accuracy: 0.8005 - val_loss: 0.0790 - val_actual_accuracy: 0.7956\n",
      "Epoch 9/20\n",
      "1345/1344 [==============================] - 30s - loss: 0.0671 - actual_accuracy: 0.8178 - val_loss: 0.0802 - val_actual_accuracy: 0.8160\n",
      "Epoch 10/20\n",
      "1345/1344 [==============================] - 30s - loss: 0.0653 - actual_accuracy: 0.8231 - val_loss: 0.0787 - val_actual_accuracy: 0.8232\n",
      "Epoch 11/20\n",
      "1345/1344 [==============================] - 29s - loss: 0.0624 - actual_accuracy: 0.8335 - val_loss: 0.0729 - val_actual_accuracy: 0.8252\n",
      "Epoch 12/20\n",
      "1345/1344 [==============================] - 31s - loss: 0.0599 - actual_accuracy: 0.8404 - val_loss: 0.0721 - val_actual_accuracy: 0.8202\n",
      "Epoch 13/20\n",
      "1345/1344 [==============================] - 35s - loss: 0.0563 - actual_accuracy: 0.8499 - val_loss: 0.0776 - val_actual_accuracy: 0.8229\n",
      "Epoch 14/20\n",
      "1345/1344 [==============================] - 31s - loss: 0.0576 - actual_accuracy: 0.8498 - val_loss: 0.0742 - val_actual_accuracy: 0.8263\n",
      "Epoch 15/20\n",
      "1345/1344 [==============================] - 31s - loss: 0.0531 - actual_accuracy: 0.8608 - val_loss: 0.0751 - val_actual_accuracy: 0.8271\n",
      "Epoch 16/20\n",
      "1345/1344 [==============================] - 29s - loss: 0.0512 - actual_accuracy: 0.8645 - val_loss: 0.0716 - val_actual_accuracy: 0.8520\n",
      "Epoch 17/20\n",
      "1345/1344 [==============================] - 26s - loss: 0.0496 - actual_accuracy: 0.8711 - val_loss: 0.0748 - val_actual_accuracy: 0.8340\n",
      "Epoch 18/20\n",
      "1345/1344 [==============================] - 28s - loss: 0.0474 - actual_accuracy: 0.8770 - val_loss: 0.0773 - val_actual_accuracy: 0.8248\n",
      "Epoch 19/20\n",
      "1345/1344 [==============================] - 28s - loss: 0.0464 - actual_accuracy: 0.8829 - val_loss: 0.0783 - val_actual_accuracy: 0.8428\n",
      "Epoch 20/20\n",
      "1345/1344 [==============================] - 24s - loss: 0.0452 - actual_accuracy: 0.8827 - val_loss: 0.0826 - val_actual_accuracy: 0.8413\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(data.generator('train', batch_size), \n",
    "                              data.x_train.shape[0]/(batch_size * num_fake_epoch), \n",
    "                              epochs=actual_epoch*num_fake_epoch, \n",
    "                              validation_data=data.generator('test', batch_size), \n",
    "                              validation_steps=data.x_test.shape[0]/(batch_size * num_fake_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = '1_epoch'\n",
    "model.save(name + '.h5')\n",
    "output = open(name + '_history.pkl', 'wb')\n",
    "pickle.dump(history.history, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dictionary, max_word, max_num_vowels, content, vowels, accetuated_vowels = create_dict()\n",
    "# train_content, test_content, validate_content = split_content(content, 0.2, '../../internal_representations/inputs/content_shuffle_vector.h5')\n",
    "# feature_dictionary = create_feature_dictionary()\n",
    "# syllable_dictionary = create_syllables_dictionary(content, vowels)\n",
    "# max_syllable = get_max_syllable(syllable_dictionary)\n",
    "\n",
    "\n",
    "content = data._read_content('../../../data/SlovarIJS_BESEDE_utf8.lex')\n",
    "dictionary, max_word, max_num_vowels, vowels, accented_vowels = data._create_dict(content)\n",
    "feature_dictionary = data._create_feature_dictionary()\n",
    "syllable_dictionary = data._create_syllables_dictionary(content, vowels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ../../../prepare_data.py\n",
    "# generate_X_and_y(dictionary, max_word, max_num_vowels, content, vowels, accetuated_vowels, feature_dictionary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
