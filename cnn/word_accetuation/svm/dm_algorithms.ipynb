{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import unicode_literals\n",
    "# text in Western (Windows 1252)\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "# import StringIO\n",
    "import math\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from skmultilearn.problem_transform.br import BinaryRelevance\n",
    "from scipy import sparse\n",
    "import gc\n",
    "\n",
    "\n",
    "# from keras import backend as Input\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "#%run ../../../prepare_data.py\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../../')\n",
    "from prepare_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING DATA...\n",
      "LOAD SUCCESSFUL!\n"
     ]
    }
   ],
   "source": [
    "%run ../../../prepare_data.py\n",
    "\n",
    "mode = 'l'\n",
    "\n",
    "\n",
    "data = Data(mode)\n",
    "if mode == 'l':\n",
    "    data.generate_data('../../internal_representations/inputs/letters_word_accentuation_train',\n",
    "                       '../../internal_representations/inputs/letters_word_accentuation_test',\n",
    "                       '../../internal_representations/inputs/letters_word_accentuation_validate')\n",
    "else:\n",
    "    data.generate_data('../../internal_representations/inputs/syllables_word_accetuation_train',\n",
    "                       '../../internal_representations/inputs/syllables_word_accetuation_test',\n",
    "                       '../../internal_representations/inputs/syllables_word_accetuation_validate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content = data._read_content('../../../data/SlovarIJS_BESEDE_utf8.lex')\n",
    "dictionary, max_word, max_num_vowels, vowels, accented_vowels = data._create_dict(content)\n",
    "feature_dictionary = data._create_feature_dictionary()\n",
    "syllable_dictionary = data._create_syllables_dictionary(content, vowels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(430151, 10)\n",
      "[4738 1873    2 1677 1226 2130    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(data.x_train.shape)\n",
    "print(data.x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'test_dump_train'\n",
    "pickle.dump(reshaped_train, open(filename, 'wb'))\n",
    "filename = 'test_dump_test'\n",
    "pickle.dump(data.y_train, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_dump_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-85ca50019453>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test_dump_train'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreshaped_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test_dump_test'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_dump_train'"
     ]
    }
   ],
   "source": [
    "filename = 'test_dump_train'\n",
    "reshaped_train = pickle.load(open(filename, 'rb'))\n",
    "filename = 'test_dump_test'\n",
    "y_train = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(430151, 23, 36)\n",
      "[[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "(430151, 828)\n",
      "  (0, 3)\t1\n",
      "  (0, 30)\t1\n",
      "  (0, 45)\t1\n",
      "  (0, 67)\t1\n",
      "  (0, 69)\t1\n",
      "  (0, 70)\t1\n",
      "  (0, 79)\t1\n",
      "  (0, 102)\t1\n",
      "  (0, 136)\t1\n",
      "  (0, 139)\t1\n",
      "  (0, 141)\t1\n",
      "  (0, 143)\t1\n",
      "  (0, 156)\t1\n",
      "  (0, 175)\t1\n",
      "  (0, 176)\t1\n",
      "  (0, 187)\t1\n",
      "  (0, 210)\t1\n",
      "  (0, 237)\t1\n",
      "  (0, 247)\t1\n",
      "  (0, 249)\t1\n",
      "  (0, 251)\t1\n",
      "  (0, 263)\t1\n",
      "  (0, 282)\t1\n",
      "  (0, 314)\t1\n",
      "  (0, 319)\t1\n",
      "  (0, 321)\t1\n",
      "  (0, 322)\t1\n",
      "  (0, 327)\t1\n",
      "  (0, 354)\t1\n",
      "  (0, 379)\t1\n",
      "  (0, 391)\t1\n",
      "  (0, 392)\t1\n",
      "  (0, 422)\t1\n",
      "  (0, 427)\t1\n",
      "  (0, 429)\t1\n",
      "  (0, 430)\t1\n",
      "  (0, 443)\t1\n",
      "  (0, 462)\t1\n",
      "  (0, 480)\t1\n",
      "  (0, 499)\t1\n",
      "  (0, 500)\t1\n",
      "  (0, 507)\t1\n",
      "  (0, 534)\t1\n",
      "  (0, 556)\t1\n",
      "  (0, 571)\t1\n",
      "  (0, 572)\t1\n",
      "(430151, 140)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ce0d86f64b8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreshaped_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_other_features_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mfinal_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreshaped_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_other_features_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreshape_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
     ]
    }
   ],
   "source": [
    "# print (X_train.shape)\n",
    "# print (X_test.shape)\n",
    "# print (X_validate.shape)\n",
    "pos = 0\n",
    "# print (decode_input(X_train[pos], dictionary))\n",
    "# print (decode_X_features(feature_dictionary, [X_other_features_train[pos]]))\n",
    "# print(decode_position(y_train[pos]))\n",
    "# print('------------------------------------')\n",
    "\n",
    "print (data.x_train.shape)\n",
    "print (data.x_train[0])\n",
    "#test = [np.reshape(data.x_train[i], 828) for i in range(data.x_train.shape[0])]\n",
    "#test = np.reshape(data.x_train[0], 23 * 36)\n",
    "#print(test[0])\n",
    "#print(test[0])\n",
    "reshaped_train = np.reshape(data.x_train, (data.x_train.shape[0], 828))\n",
    "reshaped_train = sparse.csr_matrix(reshaped_train)\n",
    "del(data.x_train)\n",
    "gc.collect()\n",
    "\n",
    "print(reshaped_train.shape)\n",
    "print(reshaped_train[1])\n",
    "print (data.x_other_features_train.shape)\n",
    "final_train = np.concatenate((reshaped_train, data.x_other_features_train), axis=1)\n",
    "final_train = sparse.csr_matrix(final_train)\n",
    "print(final_train.shape)\n",
    "def reshape_set(s, size):\n",
    "    return np.reshape(s, (size, 828))\n",
    "\n",
    "430151 * 828"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(430151, 10)\n"
     ]
    }
   ],
   "source": [
    "print (data.y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d8fab24be779>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#cls.fit(reshaped_train, data.y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreshaped_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.5/site-packages/skmultilearn/problem_transform/br.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0my_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_data_subset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             classifier.fit(self.ensure_input_format(\n\u001b[0;32m---> 71\u001b[0;31m                 X), self.ensure_output_format(y_subset))\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.5/site-packages/sklearn/svm/classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr',\n\u001b[0;32m--> 227\u001b[0;31m                          dtype=np.float64, order=\"C\")\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                       force_all_finite)\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svm = LinearSVC(random_state=0)\n",
    "cls = BinaryRelevance(classifier=svm)\n",
    "\n",
    "#cls.fit(reshaped_train, data.y_train)\n",
    "cls.fit(reshaped_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05\n",
      "0.554266395175\n",
      "0.0001\n",
      "0.611394982519\n",
      "0.001\n",
      "0.626954550693\n",
      "0.01\n",
      "0.629240462561\n",
      "0.1\n",
      "0.629278881248\n",
      "1.0\n",
      "0.629931998924\n",
      "10.0\n",
      "0.62906757847\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'finalized_model_c_100.0.sav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2b3100cabccc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'finalized_model_c_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.sav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreshaped_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'finalized_model_c_100.0.sav'"
     ]
    }
   ],
   "source": [
    "reshaped_test = np.reshape(data.x_test, (data.x_test.shape[0], 828))\n",
    "\n",
    "for i in range(-5, 5):\n",
    "    val = math.pow(10, i)\n",
    "    filename = 'finalized_model_c_' + str(val) + '.sav'\n",
    "    cls = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "    result = cls.score(reshaped_test, data.y_test)\n",
    "    print(val)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05\n",
      "0.377290714203\n",
      "0.0001\n",
      "0.427427100542\n",
      "0.001\n",
      "0.45159245457\n",
      "0.01\n",
      "0.45731683891\n",
      "0.1\n",
      "0.457816281839\n",
      "1.0\n",
      "0.457624188405\n",
      "10.0\n",
      "0.461542894464\n",
      "100.0\n",
      "0.553056206539\n",
      "1000.0\n",
      "0.523761957816\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'finalized_model_c_balanced_10000.0.sav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fa6be09074ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'finalized_model_c_balanced_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.sav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreshaped_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'finalized_model_c_balanced_10000.0.sav'"
     ]
    }
   ],
   "source": [
    "reshaped_test = np.reshape(data.x_test, (data.x_test.shape[0], 828))\n",
    "\n",
    "for i in range(-5, 5):\n",
    "    val = math.pow(10, i)\n",
    "    filename = 'finalized_model_c_balanced_' + str(val) + '.sav'\n",
    "    cls = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "    result = cls.score(reshaped_test, data.y_test)\n",
    "    print(val)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'data/letters_word_accentuation_x_train.pkl'\n",
    "x_train = pickle.load(open(filename, 'rb'))\n",
    "filename = 'data/letters_word_accentuation_x_test.pkl'\n",
    "x_test = pickle.load(open(filename, 'rb'))\n",
    "filename = 'data/letters_word_accentuation_y_train.pkl'\n",
    "y_train = pickle.load(open(filename, 'rb'))\n",
    "filename = 'data/letters_word_accentuation_y_test.pkl'\n",
    "y_test = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BaggingClassifier\n",
    "\n",
    "\n",
    "rf = BaggingClassifier(random_state=0)\n",
    "cls = BinaryRelevance(classifier=rf)\n",
    "\n",
    "#cls.fit(reshaped_train, data.y_train)\n",
    "cls.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = cls.score(x_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=0),\n",
       "        require_dense=[True, True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AdaBoostClassifier, BaggingClassifier\n",
    "\n",
    "\n",
    "rf = AdaBoostClassifier(random_state=0)\n",
    "cls = BinaryRelevance(classifier=rf)\n",
    "\n",
    "#cls.fit(reshaped_train, data.y_train)\n",
    "cls.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = cls.score(x_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   34.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   43.6s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   40.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   41.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   48.9s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   45.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   47.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   34.4s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   26.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=True,\n",
       "            warm_start=False),\n",
       "        require_dense=[True, True])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RANDOM FOREST\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0, verbose=True)\n",
    "cls = BinaryRelevance(classifier=rf)\n",
    "\n",
    "#cls.fit(reshaped_train, data.y_train)\n",
    "cls.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.785009028391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "result = cls.score(x_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "res = cls.predict_proba(x_test)\n",
    "#for i in range(50):\n",
    "#    print(data.decode_x(data.x_test[i], dictionary)[::-1])\n",
    "predicts = res.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy, errors = data.test_accuracy(predicts, data.x_test, data.x_other_features_test, data.y_test, dictionary, feature_dictionary, vowels, syllable_dictionary=syllable_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = open('rf_errors.pkl', 'wb')\n",
    "pickle.dump(errors, output)\n",
    "output.close()\n",
    "output = open('rf_predictions.pkl', 'wb')\n",
    "pickle.dump(predicts, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.641227092858\n"
     ]
    }
   ],
   "source": [
    "# reshaped_test = np.reshape(data.x_test, (data.x_test.shape[0], 828))\n",
    "\n",
    "filename = 'data/letters_word_accentuation_x_test.pkl'\n",
    "x_test = pickle.load(open(filename, 'rb'))\n",
    "filename = 'data/letters_word_accentuation_y_test.pkl'\n",
    "y_test = pickle.load(open(filename, 'rb'))\n",
    "filename = 'complete_input.sav'\n",
    "cls = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "result = cls.score(x_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akbig\n",
      "hinjovop\n",
      "olitsupod\n",
      "ovokinevtsnanz\n",
      "vetižorobo\n",
      "menazaman\n",
      "miničiramčrk\n",
      "avivajop\n",
      "ivijlovodaz\n",
      "menhidv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print (data.decode_x(data.x_test[i], dictionary))\n",
    "result.todense()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
