{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import unicode_literals\n",
    "# text in Western (Windows 1252)\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "# import StringIO\n",
    "import math\n",
    "from keras import optimizers, metrics\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import regularizers\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import load_model\n",
    "# from keras import backend as Input\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ../../../prepare_data.py\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../../')\n",
    "from prepare_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING CONTENT...\n",
      "CONTENT READ SUCCESSFULY\n",
      "CREATING DICTIONARY...\n",
      "DICTIONARY CREATION SUCCESSFUL!\n",
      "CREATING SYLLABLE DICTIONARY...\n",
      "CREATION SUCCESSFUL!\n",
      "GENERATING X AND y...\n",
      "CREATING OTHER FEATURES...\n",
      "OTHER FEATURES CREATED!\n",
      "SHUFFELING INPUTS...\n",
      "INPUTS SHUFFELED!\n",
      "CREATING OTHER FEATURES...\n",
      "OTHER FEATURES CREATED!\n",
      "SHUFFELING INPUTS...\n",
      "INPUTS SHUFFELED!\n",
      "CREATING OTHER FEATURES...\n",
      "OTHER FEATURES CREATED!\n",
      "SHUFFELING INPUTS...\n",
      "INPUTS SHUFFELED!\n",
      "GENERATION SUCCESSFUL!\n"
     ]
    }
   ],
   "source": [
    "# %run ../../../prepare_data.py\n",
    "X_train, X_other_features_train, y_train, X_test, X_other_features_test, y_test, X_validate, X_other_features_validate, y_validate = generate_syllable_inputs('../../internal_representations/inputs/content_shuffle_vector.h5', '../../internal_representations/inputs/shuffle_vector')\n",
    "save_inputs('../../internal_representations/inputs/shuffeled_syllable_train_inputs.h5', X_train, y_train, other_features = X_other_features_train)\n",
    "save_inputs('../../internal_representations/inputs/shuffeled_syllable_test_inputs.h5', X_test, y_test, other_features = X_other_features_test)\n",
    "save_inputs('../../internal_representations/inputs/shuffeled_syllable_validate_inputs.h5', X_validate, y_validate,  other_features = X_other_features_validate)\n",
    "# X_train, X_other_features_train, y_train = load_inputs('../../internal_representations/inputs/shuffeled_syllable_train_inputs.h5', other_features=True)\n",
    "# X_test, X_other_features_test, y_test = load_inputs('../../internal_representations/inputs/shuffeled_syllable_test_inputs.h5', other_features=True)\n",
    "# X_validate, X_other_features_validate, y_validate = load_inputs('../../internal_representations/inputs/shuffeled_syllable_validate_inputs.h5', other_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ../../../prepare_data.py\n",
    "gen = generate_fake_epoch_syllables(X_train[:20], X_other_features_train[:20], y_train[:20], 16, 5168)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 11, 5168)\n",
      "[0 0 0 ..., 0 0 0]\n",
      "bolj\n",
      "[0 0 0 ..., 0 0 0]\n",
      "Å¡i\n",
      "[0 0 0 ..., 0 0 0]\n",
      "mi\n",
      "[1 0 0 ..., 0 0 0]\n",
      "\n",
      "[1 0 0 ..., 0 0 0]\n",
      "\n",
      "[1 0 0 ..., 0 0 0]\n",
      "\n",
      "[1 0 0 ..., 0 0 0]\n",
      "\n",
      "[1 0 0 ..., 0 0 0]\n",
      "\n",
      "[1 0 0 ..., 0 0 0]\n",
      "\n",
      "[1 0 0 ..., 0 0 0]\n",
      "\n",
      "[1 0 0 ..., 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prints test word from generator\n",
    "# print(X_train[0])\n",
    "# print(syllable_dictionary[test[0][0][0][0].tolist().index(1)])\n",
    "print(np.array(test[0][0]).shape)\n",
    "for el in test[0][0][0]:\n",
    "    print(el)\n",
    "    print(syllable_dictionary[el.tolist().index(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(X_train[0])\n",
    "test = next(gen)\n",
    "# eye = np.eye(5168)[X_train[0]]\n",
    "# print(X_train[0].tolist())\n",
    "# np.eye(5168)[[2, 1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5168)\n"
     ]
    }
   ],
   "source": [
    "np.eye(10)[[3,7,2,5]]\n",
    "print(eye[[2, 3]].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54222, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validate.shape\n",
    "# len(syllable_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5168\n",
      "CREATING OTHER FEATURES...\n",
      "OTHER FEATURES CREATED!\n",
      "SHUFFELING INPUTS...\n",
      "(430151, 11)\n",
      "(430151,)\n",
      "INPUTS SHUFFELED!\n"
     ]
    }
   ],
   "source": [
    "print(len(syllable_dictionary))\n",
    "shuffle_vector_location = '../../internal_representations/inputs/shuffle_vector'\n",
    "X_train, X_other_features_train, y_train = generate_syllable_X_and_y(syllable_dictionary, max_word, max_num_vowels, train_content, vowels, accetuated_vowels, feature_dictionary, shuffle_vector_location + '_train.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(430151, 23, 30)\n",
      "(52058, 23, 30)\n",
      "(54222, 23, 30)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dictionary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-98de5454bb55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# print (X_other_features[178200])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdecode_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m38\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdecode_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecode_position\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# print (X_other_features_train[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdecode_X_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_dictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX_other_features_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecode_position\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dictionary' is not defined"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "print (X_validate.shape)\n",
    "# X_other_features = create_X_features(content)\n",
    "# print (X_other_features[178200])\n",
    "decode_position = 38\n",
    "print (decode_input(X_validate[decode_position], dictionary))\n",
    "# print (X_other_features_train[0])\n",
    "print (decode_X_features(feature_dictionary, [X_other_features_train[decode_position]]))\n",
    "# print (len(X_other_features_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_examples = len(X_train) # training set size\n",
    "# nn_input_dim = max_word * len(dictionary) # input layer dimensionality\n",
    "# nn_output_dim = max_num_vowels * max_num_vowels # output layer dimensionality\n",
    "nn_output_dim = 11\n",
    "nn_hdim = 516\n",
    "batch_size = 16\n",
    "actual_epoch = 10\n",
    "num_fake_epoch = 20\n",
    "\n",
    "# Gradient descent parameters (I picked these by hand)\n",
    "# epsilon = 1 # learning rate for gradient descent\n",
    "# reg_lambda = 1 # regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_input_shape=(11, 5168)\n",
    "othr_input = (140, )\n",
    "\n",
    "conv_input = Input(shape=conv_input_shape, name='conv_input')\n",
    "# x_conv = Conv1D(43, (3), padding='same', activation='relu')(conv_input)\n",
    "x_conv = Conv1D(43, (3), padding='same', activation='relu')(conv_input)\n",
    "x_conv = MaxPooling1D(pool_size=2)(x_conv)\n",
    "x_conv = Flatten()(x_conv)\n",
    "# x_conv = Dense(516, activation='relu', kernel_constraint=maxnorm(3))(x_conv)\n",
    "\n",
    "othr_input = Input(shape=othr_input, name='othr_input')\n",
    "# x_othr = Dense(256, input_dim=167, activation='relu')(othr_input)\n",
    "# x_othr = Dropout(0.3)(x_othr)\n",
    "# x_othr = Dense(512, activation='relu')(othr_input)\n",
    "# x_othr = Dropout(0.3)(x_othr)\n",
    "# x_othr = Dense(256, activation='relu')(othr_input)\n",
    "\n",
    "x = concatenate([x_conv, othr_input])\n",
    "# x = Dense(1024, input_dim=(516 + 256), activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(nn_output_dim, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[conv_input, othr_input], outputs=x)\n",
    "\n",
    "# epochs = 5\n",
    "# lrate = 0.1\n",
    "# decay = lrate/epochs\n",
    "# sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "# model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Compile model\n",
    "# keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "opt = optimizers.Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[actual_accuracy,])\n",
    "# model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# history = model.fit_generator(generate_fake_epoch_syllables(X_test[:1000], X_other_features_test[:1000], y_test[:1000], batch_size), X_test[:1000].shape[0]/(batch_size * num_fake_epoch), epochs=actual_epoch*num_fake_epoch, validation_data=generate_fake_epoch_syllables(X_test[:1000], X_other_features_test[:1000], y_test[:1000], batch_size), validation_steps=X_test[:1000].shape[0]/(batch_size * num_fake_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1345/1344 [==============================] - 359s - loss: 0.1989 - actual_accuracy: 0.2775 - val_loss: 0.1272 - val_actual_accuracy: 0.5721\n",
      "Epoch 2/200\n",
      "1345/1344 [==============================] - 182s - loss: 0.1079 - actual_accuracy: 0.6465 - val_loss: 0.0984 - val_actual_accuracy: 0.7147\n",
      "Epoch 3/200\n",
      "1345/1344 [==============================] - 188s - loss: 0.0836 - actual_accuracy: 0.7599 - val_loss: 0.0848 - val_actual_accuracy: 0.7918\n",
      "Epoch 4/200\n",
      "1345/1344 [==============================] - 194s - loss: 0.0705 - actual_accuracy: 0.8014 - val_loss: 0.0859 - val_actual_accuracy: 0.7814\n",
      "Epoch 5/200\n",
      "1345/1344 [==============================] - 202s - loss: 0.0606 - actual_accuracy: 0.8293 - val_loss: 0.0836 - val_actual_accuracy: 0.7975\n",
      "Epoch 6/200\n",
      "1345/1344 [==============================] - 198s - loss: 0.0527 - actual_accuracy: 0.8553 - val_loss: 0.0816 - val_actual_accuracy: 0.8025\n",
      "Epoch 7/200\n",
      "1345/1344 [==============================] - 204s - loss: 0.0471 - actual_accuracy: 0.8754 - val_loss: 0.0759 - val_actual_accuracy: 0.8378\n",
      "Epoch 8/200\n",
      "1345/1344 [==============================] - 199s - loss: 0.0425 - actual_accuracy: 0.8906 - val_loss: 0.0740 - val_actual_accuracy: 0.8190\n",
      "Epoch 9/200\n",
      "1345/1344 [==============================] - 210s - loss: 0.0383 - actual_accuracy: 0.8997 - val_loss: 0.0771 - val_actual_accuracy: 0.8416\n",
      "Epoch 10/200\n",
      "1345/1344 [==============================] - 235s - loss: 0.0361 - actual_accuracy: 0.9055 - val_loss: 0.0908 - val_actual_accuracy: 0.8190\n",
      "Epoch 11/200\n",
      "1345/1344 [==============================] - 224s - loss: 0.0332 - actual_accuracy: 0.9139 - val_loss: 0.0789 - val_actual_accuracy: 0.8367\n",
      "Epoch 12/200\n",
      "1345/1344 [==============================] - 232s - loss: 0.0298 - actual_accuracy: 0.9234 - val_loss: 0.0773 - val_actual_accuracy: 0.8439\n",
      "Epoch 13/200\n",
      "1345/1344 [==============================] - 224s - loss: 0.0272 - actual_accuracy: 0.9305 - val_loss: 0.0845 - val_actual_accuracy: 0.8413\n",
      "Epoch 14/200\n",
      "1345/1344 [==============================] - 227s - loss: 0.0271 - actual_accuracy: 0.9319 - val_loss: 0.0856 - val_actual_accuracy: 0.8336\n",
      "Epoch 15/200\n",
      "1345/1344 [==============================] - 221s - loss: 0.0250 - actual_accuracy: 0.9375 - val_loss: 0.0868 - val_actual_accuracy: 0.8436\n",
      "Epoch 16/200\n",
      "1345/1344 [==============================] - 219s - loss: 0.0239 - actual_accuracy: 0.9372 - val_loss: 0.0863 - val_actual_accuracy: 0.8543\n",
      "Epoch 17/200\n",
      "1345/1344 [==============================] - 219s - loss: 0.0222 - actual_accuracy: 0.9430 - val_loss: 0.0835 - val_actual_accuracy: 0.8551\n",
      "Epoch 18/200\n",
      "1345/1344 [==============================] - 229s - loss: 0.0215 - actual_accuracy: 0.9467 - val_loss: 0.1032 - val_actual_accuracy: 0.8367\n",
      "Epoch 19/200\n",
      "1345/1344 [==============================] - 231s - loss: 0.0200 - actual_accuracy: 0.9505 - val_loss: 0.0949 - val_actual_accuracy: 0.8547\n",
      "Epoch 20/200\n",
      "1345/1344 [==============================] - 219s - loss: 0.0200 - actual_accuracy: 0.9518 - val_loss: 0.1078 - val_actual_accuracy: 0.8359\n",
      "Epoch 21/200\n",
      "1345/1344 [==============================] - 234s - loss: 0.0182 - actual_accuracy: 0.9548 - val_loss: 0.0958 - val_actual_accuracy: 0.8508\n",
      "Epoch 22/200\n",
      "1345/1344 [==============================] - 231s - loss: 0.0175 - actual_accuracy: 0.9581 - val_loss: 0.0942 - val_actual_accuracy: 0.8574\n",
      "Epoch 23/200\n",
      "1345/1344 [==============================] - 226s - loss: 0.0166 - actual_accuracy: 0.9597 - val_loss: 0.1001 - val_actual_accuracy: 0.8505\n",
      "Epoch 24/200\n",
      "1345/1344 [==============================] - 229s - loss: 0.0159 - actual_accuracy: 0.9625 - val_loss: 0.1074 - val_actual_accuracy: 0.8558\n",
      "Epoch 25/200\n",
      "1345/1344 [==============================] - 230s - loss: 0.0150 - actual_accuracy: 0.9634 - val_loss: 0.1021 - val_actual_accuracy: 0.8627\n",
      "Epoch 26/200\n",
      "1345/1344 [==============================] - 221s - loss: 0.0144 - actual_accuracy: 0.9654 - val_loss: 0.0947 - val_actual_accuracy: 0.8662\n",
      "Epoch 27/200\n",
      "1345/1344 [==============================] - 234s - loss: 0.0140 - actual_accuracy: 0.9666 - val_loss: 0.0917 - val_actual_accuracy: 0.8700\n",
      "Epoch 28/200\n",
      "1345/1344 [==============================] - 224s - loss: 0.0131 - actual_accuracy: 0.9684 - val_loss: 0.1039 - val_actual_accuracy: 0.8612\n",
      "Epoch 29/200\n",
      "1345/1344 [==============================] - 237s - loss: 0.0128 - actual_accuracy: 0.9694 - val_loss: 0.1241 - val_actual_accuracy: 0.8447\n",
      "Epoch 30/200\n",
      "1345/1344 [==============================] - 238s - loss: 0.0127 - actual_accuracy: 0.9694 - val_loss: 0.1161 - val_actual_accuracy: 0.8566\n",
      "Epoch 31/200\n",
      "1345/1344 [==============================] - 237s - loss: 0.0124 - actual_accuracy: 0.9714 - val_loss: 0.1013 - val_actual_accuracy: 0.8501\n",
      "Epoch 32/200\n",
      "1345/1344 [==============================] - 233s - loss: 0.0114 - actual_accuracy: 0.9742 - val_loss: 0.1135 - val_actual_accuracy: 0.8574\n",
      "Epoch 33/200\n",
      "1345/1344 [==============================] - 229s - loss: 0.0106 - actual_accuracy: 0.9745 - val_loss: 0.1090 - val_actual_accuracy: 0.8677\n",
      "Epoch 34/200\n",
      "1345/1344 [==============================] - 243s - loss: 0.0118 - actual_accuracy: 0.9746 - val_loss: 0.1325 - val_actual_accuracy: 0.8401\n",
      "Epoch 35/200\n",
      "1345/1344 [==============================] - 238s - loss: 0.0111 - actual_accuracy: 0.9743 - val_loss: 0.1080 - val_actual_accuracy: 0.8804\n",
      "Epoch 36/200\n",
      "1345/1344 [==============================] - 239s - loss: 0.0106 - actual_accuracy: 0.9753 - val_loss: 0.1209 - val_actual_accuracy: 0.8681\n",
      "Epoch 37/200\n",
      "1345/1344 [==============================] - 224s - loss: 0.0104 - actual_accuracy: 0.9764 - val_loss: 0.1211 - val_actual_accuracy: 0.8719\n",
      "Epoch 38/200\n",
      "1345/1344 [==============================] - 233s - loss: 0.0104 - actual_accuracy: 0.9770 - val_loss: 0.1238 - val_actual_accuracy: 0.8663\n",
      "Epoch 39/200\n",
      "1345/1344 [==============================] - 221s - loss: 0.0103 - actual_accuracy: 0.9770 - val_loss: 0.1338 - val_actual_accuracy: 0.8508\n",
      "Epoch 40/200\n",
      "1345/1344 [==============================] - 219s - loss: 0.0104 - actual_accuracy: 0.9756 - val_loss: 0.1169 - val_actual_accuracy: 0.8620\n",
      "Epoch 41/200\n",
      "1345/1344 [==============================] - 230s - loss: 0.0092 - actual_accuracy: 0.9776 - val_loss: 0.1209 - val_actual_accuracy: 0.8581\n",
      "Epoch 42/200\n",
      "1345/1344 [==============================] - 238s - loss: 0.0091 - actual_accuracy: 0.9798 - val_loss: 0.1360 - val_actual_accuracy: 0.8516\n",
      "Epoch 43/200\n",
      "1345/1344 [==============================] - 241s - loss: 0.0089 - actual_accuracy: 0.9789 - val_loss: 0.1362 - val_actual_accuracy: 0.8554\n",
      "Epoch 44/200\n",
      "1345/1344 [==============================] - 232s - loss: 0.0088 - actual_accuracy: 0.9803 - val_loss: 0.1356 - val_actual_accuracy: 0.8616\n",
      "Epoch 45/200\n",
      "1345/1344 [==============================] - 235s - loss: 0.0079 - actual_accuracy: 0.9815 - val_loss: 0.1270 - val_actual_accuracy: 0.8623\n",
      "Epoch 46/200\n",
      "1345/1344 [==============================] - 231s - loss: 0.0082 - actual_accuracy: 0.9820 - val_loss: 0.1208 - val_actual_accuracy: 0.8646\n",
      "Epoch 47/200\n",
      "1345/1344 [==============================] - 228s - loss: 0.0081 - actual_accuracy: 0.9819 - val_loss: 0.1284 - val_actual_accuracy: 0.8666\n",
      "Epoch 48/200\n",
      "1345/1344 [==============================] - 227s - loss: 0.0075 - actual_accuracy: 0.9822 - val_loss: 0.1657 - val_actual_accuracy: 0.8367\n",
      "Epoch 49/200\n",
      "1345/1344 [==============================] - 231s - loss: 0.0072 - actual_accuracy: 0.9836 - val_loss: 0.1398 - val_actual_accuracy: 0.8600\n",
      "Epoch 50/200\n",
      "1345/1344 [==============================] - 236s - loss: 0.0075 - actual_accuracy: 0.9818 - val_loss: 0.1490 - val_actual_accuracy: 0.8520\n",
      "Epoch 51/200\n",
      "1345/1344 [==============================] - 247s - loss: 0.0079 - actual_accuracy: 0.9825 - val_loss: 0.1414 - val_actual_accuracy: 0.8581\n",
      "Epoch 52/200\n",
      "1345/1344 [==============================] - 233s - loss: 0.0071 - actual_accuracy: 0.9834 - val_loss: 0.1507 - val_actual_accuracy: 0.8554\n",
      "Epoch 53/200\n",
      "1345/1344 [==============================] - 223s - loss: 0.0066 - actual_accuracy: 0.9851 - val_loss: 0.1464 - val_actual_accuracy: 0.8516\n",
      "Epoch 54/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1345/1344 [==============================] - 228s - loss: 0.0075 - actual_accuracy: 0.9829 - val_loss: 0.1420 - val_actual_accuracy: 0.8650\n",
      "Epoch 55/200\n",
      "1345/1344 [==============================] - 226s - loss: 0.0070 - actual_accuracy: 0.9848 - val_loss: 0.1336 - val_actual_accuracy: 0.8700\n",
      "Epoch 56/200\n",
      "1345/1344 [==============================] - 222s - loss: 0.0067 - actual_accuracy: 0.9846 - val_loss: 0.1662 - val_actual_accuracy: 0.8566\n",
      "Epoch 57/200\n",
      "1345/1344 [==============================] - 230s - loss: 0.0068 - actual_accuracy: 0.9852 - val_loss: 0.1388 - val_actual_accuracy: 0.8578\n",
      "Epoch 58/200\n",
      "1345/1344 [==============================] - 227s - loss: 0.0063 - actual_accuracy: 0.9865 - val_loss: 0.1476 - val_actual_accuracy: 0.8524\n",
      "Epoch 59/200\n",
      "1345/1344 [==============================] - 227s - loss: 0.0071 - actual_accuracy: 0.9845 - val_loss: 0.1395 - val_actual_accuracy: 0.8700\n",
      "Epoch 60/200\n",
      "1345/1344 [==============================] - 230s - loss: 0.0070 - actual_accuracy: 0.9850 - val_loss: 0.1355 - val_actual_accuracy: 0.8646\n",
      "Epoch 61/200\n",
      "1345/1344 [==============================] - 237s - loss: 0.0058 - actual_accuracy: 0.9874 - val_loss: 0.1476 - val_actual_accuracy: 0.8689\n",
      "Epoch 62/200\n",
      "1345/1344 [==============================] - 235s - loss: 0.0060 - actual_accuracy: 0.9874 - val_loss: 0.1410 - val_actual_accuracy: 0.8631\n",
      "Epoch 63/200\n",
      "1345/1344 [==============================] - 238s - loss: 0.0058 - actual_accuracy: 0.9865 - val_loss: 0.1621 - val_actual_accuracy: 0.8551\n",
      "Epoch 64/200\n",
      "1345/1344 [==============================] - 239s - loss: 0.0059 - actual_accuracy: 0.9866 - val_loss: 0.1583 - val_actual_accuracy: 0.8547\n",
      "Epoch 65/200\n",
      "1345/1344 [==============================] - 239s - loss: 0.0051 - actual_accuracy: 0.9882 - val_loss: 0.1449 - val_actual_accuracy: 0.8654\n",
      "Epoch 66/200\n",
      "1345/1344 [==============================] - 229s - loss: 0.0058 - actual_accuracy: 0.9875 - val_loss: 0.1632 - val_actual_accuracy: 0.8570\n",
      "Epoch 67/200\n",
      "1345/1344 [==============================] - 228s - loss: 0.0057 - actual_accuracy: 0.9878 - val_loss: 0.1778 - val_actual_accuracy: 0.8405\n",
      "Epoch 68/200\n",
      "1345/1344 [==============================] - 231s - loss: 0.0051 - actual_accuracy: 0.9887 - val_loss: 0.1558 - val_actual_accuracy: 0.8531\n",
      "Epoch 69/200\n",
      "1345/1344 [==============================] - 228s - loss: 0.0050 - actual_accuracy: 0.9893 - val_loss: 0.1698 - val_actual_accuracy: 0.8558\n",
      "Epoch 70/200\n",
      "1345/1344 [==============================] - 229s - loss: 0.0055 - actual_accuracy: 0.9888 - val_loss: 0.1489 - val_actual_accuracy: 0.865898 - ETA: 5s - loss:\n",
      "Epoch 71/200\n",
      "1345/1344 [==============================] - 231s - loss: 0.0055 - actual_accuracy: 0.9879 - val_loss: 0.1556 - val_actual_accuracy: 0.8570\n",
      "Epoch 72/200\n",
      "1345/1344 [==============================] - 232s - loss: 0.0049 - actual_accuracy: 0.9896 - val_loss: 0.1479 - val_actual_accuracy: 0.8650\n",
      "Epoch 73/200\n",
      "1345/1344 [==============================] - 234s - loss: 0.0044 - actual_accuracy: 0.9900 - val_loss: 0.1668 - val_actual_accuracy: 0.8635\n",
      "Epoch 74/200\n",
      "1345/1344 [==============================] - 235s - loss: 0.0052 - actual_accuracy: 0.9892 - val_loss: 0.1656 - val_actual_accuracy: 0.8577\n",
      "Epoch 75/200\n",
      "1345/1344 [==============================] - 237s - loss: 0.0053 - actual_accuracy: 0.9884 - val_loss: 0.1777 - val_actual_accuracy: 0.8589\n",
      "Epoch 76/200\n",
      "1345/1344 [==============================] - 235s - loss: 0.0051 - actual_accuracy: 0.9889 - val_loss: 0.1750 - val_actual_accuracy: 0.8593\n",
      "Epoch 77/200\n",
      "1345/1344 [==============================] - 238s - loss: 0.0049 - actual_accuracy: 0.9892 - val_loss: 0.1620 - val_actual_accuracy: 0.8566\n",
      "Epoch 78/200\n",
      "1345/1344 [==============================] - 237s - loss: 0.0047 - actual_accuracy: 0.9898 - val_loss: 0.1650 - val_actual_accuracy: 0.8662\n",
      "Epoch 79/200\n",
      "1345/1344 [==============================] - 239s - loss: 0.0046 - actual_accuracy: 0.9908 - val_loss: 0.1623 - val_actual_accuracy: 0.8558\n",
      "Epoch 80/200\n",
      "1345/1344 [==============================] - 239s - loss: 0.0051 - actual_accuracy: 0.9892 - val_loss: 0.1583 - val_actual_accuracy: 0.8681\n",
      "Epoch 81/200\n",
      "1345/1344 [==============================] - 240s - loss: 0.0043 - actual_accuracy: 0.9900 - val_loss: 0.1669 - val_actual_accuracy: 0.8566\n",
      "Epoch 82/200\n",
      "1345/1344 [==============================] - 235s - loss: 0.0047 - actual_accuracy: 0.9900 - val_loss: 0.1612 - val_actual_accuracy: 0.8646\n",
      "Epoch 83/200\n",
      "1345/1344 [==============================] - 239s - loss: 0.0043 - actual_accuracy: 0.9896 - val_loss: 0.1757 - val_actual_accuracy: 0.8482\n",
      "Epoch 84/200\n",
      "1345/1344 [==============================] - 245s - loss: 0.0045 - actual_accuracy: 0.9900 - val_loss: 0.1727 - val_actual_accuracy: 0.8558\n",
      "Epoch 85/200\n",
      "1345/1344 [==============================] - 237s - loss: 0.0041 - actual_accuracy: 0.9908 - val_loss: 0.1634 - val_actual_accuracy: 0.8620\n",
      "Epoch 86/200\n",
      "1345/1344 [==============================] - 237s - loss: 0.0041 - actual_accuracy: 0.9908 - val_loss: 0.1873 - val_actual_accuracy: 0.8447\n",
      "Epoch 87/200\n",
      "1345/1344 [==============================] - 238s - loss: 0.0047 - actual_accuracy: 0.9898 - val_loss: 0.1685 - val_actual_accuracy: 0.8528\n",
      "Epoch 88/200\n",
      "1345/1344 [==============================] - 241s - loss: 0.0041 - actual_accuracy: 0.9917 - val_loss: 0.1598 - val_actual_accuracy: 0.8669\n",
      "Epoch 89/200\n",
      "1345/1344 [==============================] - 242s - loss: 0.0040 - actual_accuracy: 0.9914 - val_loss: 0.1749 - val_actual_accuracy: 0.8524\n",
      "Epoch 90/200\n",
      "1345/1344 [==============================] - 246s - loss: 0.0044 - actual_accuracy: 0.9900 - val_loss: 0.1809 - val_actual_accuracy: 0.8443\n",
      "Epoch 91/200\n",
      "1345/1344 [==============================] - 242s - loss: 0.0042 - actual_accuracy: 0.9905 - val_loss: 0.1760 - val_actual_accuracy: 0.8604\n",
      "Epoch 92/200\n",
      "1345/1344 [==============================] - 241s - loss: 0.0038 - actual_accuracy: 0.9924 - val_loss: 0.1590 - val_actual_accuracy: 0.8715\n",
      "Epoch 93/200\n",
      "1345/1344 [==============================] - 242s - loss: 0.0035 - actual_accuracy: 0.9921 - val_loss: 0.1659 - val_actual_accuracy: 0.8589\n",
      "Epoch 94/200\n",
      "1345/1344 [==============================] - 243s - loss: 0.0041 - actual_accuracy: 0.9909 - val_loss: 0.1891 - val_actual_accuracy: 0.8562\n",
      "Epoch 95/200\n",
      "1345/1344 [==============================] - 242s - loss: 0.0041 - actual_accuracy: 0.9914 - val_loss: 0.1952 - val_actual_accuracy: 0.8520\n",
      "Epoch 96/200\n",
      "1345/1344 [==============================] - 245s - loss: 0.0040 - actual_accuracy: 0.9912 - val_loss: 0.1709 - val_actual_accuracy: 0.8508\n",
      "Epoch 97/200\n",
      "1345/1344 [==============================] - 243s - loss: 0.0036 - actual_accuracy: 0.9928 - val_loss: 0.1776 - val_actual_accuracy: 0.8639\n",
      "Epoch 98/200\n",
      "1345/1344 [==============================] - 246s - loss: 0.0036 - actual_accuracy: 0.9925 - val_loss: 0.1915 - val_actual_accuracy: 0.8489\n",
      "Epoch 99/200\n",
      "1345/1344 [==============================] - 242s - loss: 0.0038 - actual_accuracy: 0.9914 - val_loss: 0.1804 - val_actual_accuracy: 0.8623\n",
      "Epoch 100/200\n",
      "1345/1344 [==============================] - 241s - loss: 0.0043 - actual_accuracy: 0.9914 - val_loss: 0.1644 - val_actual_accuracy: 0.8600\n",
      "Epoch 101/200\n",
      "1345/1344 [==============================] - 238s - loss: 0.0034 - actual_accuracy: 0.9923 - val_loss: 0.1720 - val_actual_accuracy: 0.8662\n",
      "Epoch 102/200\n",
      "1345/1344 [==============================] - 240s - loss: 0.0036 - actual_accuracy: 0.9928 - val_loss: 0.1834 - val_actual_accuracy: 0.8562\n",
      "Epoch 103/200\n",
      "1345/1344 [==============================] - 244s - loss: 0.0032 - actual_accuracy: 0.9930 - val_loss: 0.1916 - val_actual_accuracy: 0.8589\n",
      "Epoch 104/200\n",
      "1345/1344 [==============================] - 248s - loss: 0.0035 - actual_accuracy: 0.9921 - val_loss: 0.1915 - val_actual_accuracy: 0.8512\n",
      "Epoch 105/200\n",
      "1345/1344 [==============================] - 244s - loss: 0.0030 - actual_accuracy: 0.9934 - val_loss: 0.1938 - val_actual_accuracy: 0.8524\n",
      "Epoch 106/200\n",
      "1345/1344 [==============================] - 246s - loss: 0.0034 - actual_accuracy: 0.9932 - val_loss: 0.1798 - val_actual_accuracy: 0.8562\n",
      "Epoch 107/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1345/1344 [==============================] - 247s - loss: 0.0034 - actual_accuracy: 0.9927 - val_loss: 0.1871 - val_actual_accuracy: 0.8620\n",
      "Epoch 108/200\n",
      "1345/1344 [==============================] - 246s - loss: 0.0033 - actual_accuracy: 0.9926 - val_loss: 0.1899 - val_actual_accuracy: 0.8593\n",
      "Epoch 109/200\n",
      "1345/1344 [==============================] - 247s - loss: 0.0029 - actual_accuracy: 0.9935 - val_loss: 0.2048 - val_actual_accuracy: 0.8574\n",
      "Epoch 110/200\n",
      "1345/1344 [==============================] - 252s - loss: 0.0039 - actual_accuracy: 0.9910 - val_loss: 0.1691 - val_actual_accuracy: 0.8704\n",
      "Epoch 111/200\n",
      "1345/1344 [==============================] - 249s - loss: 0.0034 - actual_accuracy: 0.9921 - val_loss: 0.1848 - val_actual_accuracy: 0.8608\n",
      "Epoch 112/200\n",
      "1345/1344 [==============================] - 247s - loss: 0.0030 - actual_accuracy: 0.9938 - val_loss: 0.2009 - val_actual_accuracy: 0.8535\n",
      "Epoch 113/200\n",
      "1345/1344 [==============================] - 245s - loss: 0.0027 - actual_accuracy: 0.9935 - val_loss: 0.2007 - val_actual_accuracy: 0.8577\n",
      "Epoch 114/200\n",
      "1345/1344 [==============================] - 254s - loss: 0.0033 - actual_accuracy: 0.9921 - val_loss: 0.2059 - val_actual_accuracy: 0.8474\n",
      "Epoch 115/200\n",
      "1345/1344 [==============================] - 251s - loss: 0.0034 - actual_accuracy: 0.9925 - val_loss: 0.1938 - val_actual_accuracy: 0.8581\n",
      "Epoch 116/200\n",
      "1345/1344 [==============================] - 250s - loss: 0.0032 - actual_accuracy: 0.9929 - val_loss: 0.1963 - val_actual_accuracy: 0.8666\n",
      "Epoch 117/200\n",
      "1345/1344 [==============================] - 249s - loss: 0.0029 - actual_accuracy: 0.9938 - val_loss: 0.1985 - val_actual_accuracy: 0.8543\n",
      "Epoch 118/200\n",
      "1345/1344 [==============================] - 250s - loss: 0.0027 - actual_accuracy: 0.9948 - val_loss: 0.1980 - val_actual_accuracy: 0.8597\n",
      "Epoch 119/200\n",
      "1345/1344 [==============================] - 253s - loss: 0.0030 - actual_accuracy: 0.9928 - val_loss: 0.2060 - val_actual_accuracy: 0.8466\n",
      "Epoch 120/200\n",
      "1345/1344 [==============================] - 253s - loss: 0.0032 - actual_accuracy: 0.9930 - val_loss: 0.1794 - val_actual_accuracy: 0.8654\n",
      "Epoch 121/200\n",
      "1345/1344 [==============================] - 252s - loss: 0.0026 - actual_accuracy: 0.9941 - val_loss: 0.1947 - val_actual_accuracy: 0.8662\n",
      "Epoch 122/200\n",
      "1345/1344 [==============================] - 254s - loss: 0.0032 - actual_accuracy: 0.9930 - val_loss: 0.1861 - val_actual_accuracy: 0.8562\n",
      "Epoch 123/200\n",
      "1345/1344 [==============================] - 251s - loss: 0.0027 - actual_accuracy: 0.9943 - val_loss: 0.2143 - val_actual_accuracy: 0.8455\n",
      "Epoch 124/200\n",
      "1345/1344 [==============================] - 257s - loss: 0.0028 - actual_accuracy: 0.9941 - val_loss: 0.2007 - val_actual_accuracy: 0.8524\n",
      "Epoch 125/200\n",
      "1345/1344 [==============================] - 260s - loss: 0.0024 - actual_accuracy: 0.9950 - val_loss: 0.2077 - val_actual_accuracy: 0.8505\n",
      "Epoch 126/200\n",
      "1345/1344 [==============================] - 249s - loss: 0.0029 - actual_accuracy: 0.9941 - val_loss: 0.2094 - val_actual_accuracy: 0.8558\n",
      "Epoch 127/200\n",
      "1345/1344 [==============================] - 253s - loss: 0.0029 - actual_accuracy: 0.9943 - val_loss: 0.2244 - val_actual_accuracy: 0.8413\n",
      "Epoch 128/200\n",
      "1345/1344 [==============================] - 253s - loss: 0.0027 - actual_accuracy: 0.9944 - val_loss: 0.1914 - val_actual_accuracy: 0.8608\n",
      "Epoch 129/200\n",
      "1345/1344 [==============================] - 252s - loss: 0.0024 - actual_accuracy: 0.9946 - val_loss: 0.1961 - val_actual_accuracy: 0.8639\n",
      "Epoch 130/200\n",
      "1345/1344 [==============================] - 253s - loss: 0.0034 - actual_accuracy: 0.9927 - val_loss: 0.1618 - val_actual_accuracy: 0.8646\n",
      "Epoch 131/200\n",
      "1345/1344 [==============================] - 257s - loss: 0.0027 - actual_accuracy: 0.9940 - val_loss: 0.2120 - val_actual_accuracy: 0.8508\n",
      "Epoch 132/200\n",
      "1345/1344 [==============================] - 250s - loss: 0.0027 - actual_accuracy: 0.9948 - val_loss: 0.1977 - val_actual_accuracy: 0.8593\n",
      "Epoch 133/200\n",
      "1345/1344 [==============================] - 250s - loss: 0.0022 - actual_accuracy: 0.9949 - val_loss: 0.2088 - val_actual_accuracy: 0.8470\n",
      "Epoch 134/200\n",
      "1345/1344 [==============================] - 249s - loss: 0.0029 - actual_accuracy: 0.9940 - val_loss: 0.1909 - val_actual_accuracy: 0.8604\n",
      "Epoch 135/200\n",
      "1345/1344 [==============================] - 256s - loss: 0.0026 - actual_accuracy: 0.9949 - val_loss: 0.2025 - val_actual_accuracy: 0.8581\n",
      "Epoch 136/200\n",
      "1345/1344 [==============================] - 247s - loss: 0.0025 - actual_accuracy: 0.9943 - val_loss: 0.2010 - val_actual_accuracy: 0.8520\n",
      "Epoch 137/200\n",
      "1345/1344 [==============================] - 251s - loss: 0.0026 - actual_accuracy: 0.9949 - val_loss: 0.1980 - val_actual_accuracy: 0.8620\n",
      "Epoch 138/200\n",
      "1345/1344 [==============================] - 251s - loss: 0.0025 - actual_accuracy: 0.9947 - val_loss: 0.2121 - val_actual_accuracy: 0.8432\n",
      "Epoch 139/200\n",
      "1345/1344 [==============================] - 249s - loss: 0.0024 - actual_accuracy: 0.9947 - val_loss: 0.2011 - val_actual_accuracy: 0.8485\n",
      "Epoch 140/200\n",
      "1345/1344 [==============================] - 252s - loss: 0.0027 - actual_accuracy: 0.9944 - val_loss: 0.1969 - val_actual_accuracy: 0.8600\n",
      "Epoch 141/200\n",
      "1345/1344 [==============================] - 248s - loss: 0.0023 - actual_accuracy: 0.9947 - val_loss: 0.1956 - val_actual_accuracy: 0.8643\n",
      "Epoch 142/200\n",
      "1345/1344 [==============================] - 252s - loss: 0.0028 - actual_accuracy: 0.9942 - val_loss: 0.2320 - val_actual_accuracy: 0.8397\n",
      "Epoch 143/200\n",
      "1345/1344 [==============================] - 250s - loss: 0.0021 - actual_accuracy: 0.9955 - val_loss: 0.2112 - val_actual_accuracy: 0.8505\n",
      "Epoch 144/200\n",
      "1345/1344 [==============================] - 256s - loss: 0.0022 - actual_accuracy: 0.9947 - val_loss: 0.2292 - val_actual_accuracy: 0.8378\n",
      "Epoch 145/200\n",
      "1345/1344 [==============================] - 255s - loss: 0.0022 - actual_accuracy: 0.9953 - val_loss: 0.2160 - val_actual_accuracy: 0.8593\n",
      "Epoch 146/200\n",
      "1345/1344 [==============================] - 253s - loss: 0.0023 - actual_accuracy: 0.9953 - val_loss: 0.2095 - val_actual_accuracy: 0.8585\n",
      "Epoch 147/200\n",
      "1345/1344 [==============================] - 251s - loss: 0.0024 - actual_accuracy: 0.9945 - val_loss: 0.2293 - val_actual_accuracy: 0.8512\n",
      "Epoch 148/200\n",
      "1345/1344 [==============================] - 252s - loss: 0.0024 - actual_accuracy: 0.9946 - val_loss: 0.1916 - val_actual_accuracy: 0.8662\n",
      "Epoch 149/200\n",
      "1345/1344 [==============================] - 249s - loss: 0.0021 - actual_accuracy: 0.9957 - val_loss: 0.2008 - val_actual_accuracy: 0.8589\n",
      "Epoch 150/200\n",
      "1345/1344 [==============================] - 254s - loss: 0.0024 - actual_accuracy: 0.9952 - val_loss: 0.2275 - val_actual_accuracy: 0.8485\n",
      "Epoch 151/200\n",
      "1345/1344 [==============================] - 255s - loss: 0.0025 - actual_accuracy: 0.9951 - val_loss: 0.2144 - val_actual_accuracy: 0.8547\n",
      "Epoch 152/200\n",
      "1345/1344 [==============================] - 253s - loss: 0.0022 - actual_accuracy: 0.9956 - val_loss: 0.2341 - val_actual_accuracy: 0.8455\n",
      "Epoch 153/200\n",
      "1345/1344 [==============================] - 258s - loss: 0.0020 - actual_accuracy: 0.9956 - val_loss: 0.2090 - val_actual_accuracy: 0.8524\n",
      "Epoch 154/200\n",
      "1345/1344 [==============================] - 259s - loss: 0.0021 - actual_accuracy: 0.9951 - val_loss: 0.2049 - val_actual_accuracy: 0.8662\n",
      "Epoch 155/200\n",
      "1345/1344 [==============================] - 262s - loss: 0.0025 - actual_accuracy: 0.9943 - val_loss: 0.2397 - val_actual_accuracy: 0.8489\n",
      "Epoch 156/200\n",
      "1345/1344 [==============================] - 266s - loss: 0.0024 - actual_accuracy: 0.9947 - val_loss: 0.2185 - val_actual_accuracy: 0.8620\n",
      "Epoch 157/200\n",
      "1345/1344 [==============================] - 261s - loss: 0.0023 - actual_accuracy: 0.9954 - val_loss: 0.2320 - val_actual_accuracy: 0.8390\n",
      "Epoch 158/200\n",
      "1345/1344 [==============================] - 263s - loss: 0.0021 - actual_accuracy: 0.9953 - val_loss: 0.2158 - val_actual_accuracy: 0.8585\n",
      "Epoch 159/200\n",
      "1345/1344 [==============================] - 261s - loss: 0.0020 - actual_accuracy: 0.9951 - val_loss: 0.2019 - val_actual_accuracy: 0.8562\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1345/1344 [==============================] - 259s - loss: 0.0022 - actual_accuracy: 0.9952 - val_loss: 0.2302 - val_actual_accuracy: 0.8535 - los - ETA: 2s - loss: 0.0022 - actual_\n",
      "Epoch 161/200\n",
      "1345/1344 [==============================] - 266s - loss: 0.0020 - actual_accuracy: 0.9955 - val_loss: 0.2546 - val_actual_accuracy: 0.8344\n",
      "Epoch 162/200\n",
      "1345/1344 [==============================] - 260s - loss: 0.0022 - actual_accuracy: 0.9952 - val_loss: 0.2386 - val_actual_accuracy: 0.8462\n",
      "Epoch 163/200\n",
      "1345/1344 [==============================] - 259s - loss: 0.0019 - actual_accuracy: 0.9960 - val_loss: 0.2581 - val_actual_accuracy: 0.8466\n",
      "Epoch 164/200\n",
      "1345/1344 [==============================] - 254s - loss: 0.0019 - actual_accuracy: 0.9959 - val_loss: 0.2220 - val_actual_accuracy: 0.8581\n",
      "Epoch 165/200\n",
      "1345/1344 [==============================] - 257s - loss: 0.0018 - actual_accuracy: 0.9964 - val_loss: 0.2294 - val_actual_accuracy: 0.8497\n",
      "Epoch 166/200\n",
      "1345/1344 [==============================] - 260s - loss: 0.0020 - actual_accuracy: 0.9955 - val_loss: 0.2169 - val_actual_accuracy: 0.8531\n",
      "Epoch 167/200\n",
      "1345/1344 [==============================] - 261s - loss: 0.0020 - actual_accuracy: 0.9958 - val_loss: 0.1937 - val_actual_accuracy: 0.8742\n",
      "Epoch 168/200\n",
      "1345/1344 [==============================] - 263s - loss: 0.0019 - actual_accuracy: 0.9959 - val_loss: 0.1925 - val_actual_accuracy: 0.8604\n",
      "Epoch 169/200\n",
      "1345/1344 [==============================] - 262s - loss: 0.0020 - actual_accuracy: 0.9958 - val_loss: 0.2206 - val_actual_accuracy: 0.8508\n",
      "Epoch 170/200\n",
      "1345/1344 [==============================] - 258s - loss: 0.0021 - actual_accuracy: 0.9951 - val_loss: 0.2155 - val_actual_accuracy: 0.8559\n",
      "Epoch 171/200\n",
      "1345/1344 [==============================] - 261s - loss: 0.0023 - actual_accuracy: 0.9951 - val_loss: 0.2278 - val_actual_accuracy: 0.8489\n",
      "Epoch 172/200\n",
      "1345/1344 [==============================] - 259s - loss: 0.0021 - actual_accuracy: 0.9953 - val_loss: 0.2092 - val_actual_accuracy: 0.8612\n",
      "Epoch 173/200\n",
      "1345/1344 [==============================] - 264s - loss: 0.0015 - actual_accuracy: 0.9963 - val_loss: 0.1986 - val_actual_accuracy: 0.8658\n",
      "Epoch 174/200\n",
      "1345/1344 [==============================] - 270s - loss: 0.0019 - actual_accuracy: 0.9961 - val_loss: 0.2155 - val_actual_accuracy: 0.8574\n",
      "Epoch 175/200\n",
      "1345/1344 [==============================] - 269s - loss: 0.0019 - actual_accuracy: 0.9957 - val_loss: 0.2262 - val_actual_accuracy: 0.8574\n",
      "Epoch 176/200\n",
      "1345/1344 [==============================] - 264s - loss: 0.0018 - actual_accuracy: 0.9959 - val_loss: 0.2367 - val_actual_accuracy: 0.8485\n",
      "Epoch 177/200\n",
      "1345/1344 [==============================] - 264s - loss: 0.0019 - actual_accuracy: 0.9963 - val_loss: 0.2081 - val_actual_accuracy: 0.8535\n",
      "Epoch 178/200\n",
      "1345/1344 [==============================] - 272s - loss: 0.0018 - actual_accuracy: 0.9964 - val_loss: 0.1989 - val_actual_accuracy: 0.8696\n",
      "Epoch 179/200\n",
      "1345/1344 [==============================] - 275s - loss: 0.0018 - actual_accuracy: 0.9955 - val_loss: 0.1982 - val_actual_accuracy: 0.8577\n",
      "Epoch 180/200\n",
      "1345/1344 [==============================] - 273s - loss: 0.0020 - actual_accuracy: 0.9954 - val_loss: 0.2527 - val_actual_accuracy: 0.8344\n",
      "Epoch 181/200\n",
      "1345/1344 [==============================] - 269s - loss: 0.0018 - actual_accuracy: 0.9957 - val_loss: 0.2387 - val_actual_accuracy: 0.8501\n",
      "Epoch 182/200\n",
      "1345/1344 [==============================] - 268s - loss: 0.0021 - actual_accuracy: 0.9947 - val_loss: 0.2432 - val_actual_accuracy: 0.8543\n",
      "Epoch 183/200\n",
      "1345/1344 [==============================] - 272s - loss: 0.0020 - actual_accuracy: 0.9955 - val_loss: 0.2087 - val_actual_accuracy: 0.8574\n",
      "Epoch 184/200\n",
      "1345/1344 [==============================] - 277s - loss: 0.0016 - actual_accuracy: 0.9961 - val_loss: 0.2379 - val_actual_accuracy: 0.8478\n",
      "Epoch 185/200\n",
      "1345/1344 [==============================] - 282s - loss: 0.0016 - actual_accuracy: 0.9964 - val_loss: 0.2356 - val_actual_accuracy: 0.8524\n",
      "Epoch 186/200\n",
      "1345/1344 [==============================] - 268s - loss: 0.0015 - actual_accuracy: 0.9972 - val_loss: 0.2333 - val_actual_accuracy: 0.8566\n",
      "Epoch 187/200\n",
      "1345/1344 [==============================] - 265s - loss: 0.0019 - actual_accuracy: 0.9959 - val_loss: 0.2013 - val_actual_accuracy: 0.8623\n",
      "Epoch 188/200\n",
      "1345/1344 [==============================] - 272s - loss: 0.0018 - actual_accuracy: 0.9963 - val_loss: 0.2336 - val_actual_accuracy: 0.8558\n",
      "Epoch 189/200\n",
      "1345/1344 [==============================] - 267s - loss: 0.0016 - actual_accuracy: 0.9966 - val_loss: 0.2144 - val_actual_accuracy: 0.8628\n",
      "Epoch 190/200\n",
      "1345/1344 [==============================] - 266s - loss: 0.0022 - actual_accuracy: 0.9950 - val_loss: 0.2330 - val_actual_accuracy: 0.8420\n",
      "Epoch 191/200\n",
      "1345/1344 [==============================] - 283s - loss: 0.0018 - actual_accuracy: 0.9961 - val_loss: 0.2262 - val_actual_accuracy: 0.8531\n",
      "Epoch 192/200\n",
      "1345/1344 [==============================] - 280s - loss: 0.0017 - actual_accuracy: 0.9966 - val_loss: 0.2057 - val_actual_accuracy: 0.8635\n",
      "Epoch 193/200\n",
      "1345/1344 [==============================] - 275s - loss: 0.0015 - actual_accuracy: 0.9966 - val_loss: 0.2387 - val_actual_accuracy: 0.8489\n",
      "Epoch 194/200\n",
      "1345/1344 [==============================] - 273s - loss: 0.0017 - actual_accuracy: 0.9962 - val_loss: 0.2109 - val_actual_accuracy: 0.8562\n",
      "Epoch 195/200\n",
      "1345/1344 [==============================] - 280s - loss: 0.0020 - actual_accuracy: 0.9955 - val_loss: 0.2462 - val_actual_accuracy: 0.8382\n",
      "Epoch 196/200\n",
      "1345/1344 [==============================] - 273s - loss: 0.0015 - actual_accuracy: 0.9971 - val_loss: 0.2376 - val_actual_accuracy: 0.8543\n",
      "Epoch 197/200\n",
      "1345/1344 [==============================] - 278s - loss: 0.0016 - actual_accuracy: 0.9968 - val_loss: 0.2251 - val_actual_accuracy: 0.8597\n",
      "Epoch 198/200\n",
      "1345/1344 [==============================] - 274s - loss: 0.0014 - actual_accuracy: 0.9971 - val_loss: 0.2309 - val_actual_accuracy: 0.8497\n",
      "Epoch 199/200\n",
      "1345/1344 [==============================] - 272s - loss: 0.0017 - actual_accuracy: 0.9964 - val_loss: 0.2669 - val_actual_accuracy: 0.8340\n",
      "Epoch 200/200\n",
      "1345/1344 [==============================] - 267s - loss: 0.0013 - actual_accuracy: 0.9973 - val_loss: 0.2542 - val_actual_accuracy: 0.8478\n"
     ]
    }
   ],
   "source": [
    "# history = model.fit_generator(generate_fake_epoch(X_train, X_other_features_train, y_train, batch_size), X_train.shape[0]/(batch_size * num_fake_epoch), epochs=actual_epoch*num_fake_epoch, validation_data=([X_test, X_other_features_test], y_test))\n",
    "history = model.fit_generator(generate_fake_epoch_syllables(X_train, X_other_features_train, y_train, batch_size), X_train.shape[0]/(batch_size * num_fake_epoch), epochs=actual_epoch*num_fake_epoch, validation_data=generate_fake_epoch_syllables(X_test, X_other_features_test, y_test, batch_size), validation_steps=X_test.shape[0]/(batch_size * num_fake_epoch))\n",
    "\n",
    "\n",
    "# model.fit([X_train, X_other_features_train], y_train, validation_data=([X_validate, X_other_features_validate], y_validate), epochs=1, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = '10_epoch'\n",
    "model.save(name + '.h5')\n",
    "output = open(name + '_history.pkl', 'wb')\n",
    "pickle.dump(history.history, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING CONTENT...\n",
      "CONTENT READ SUCCESSFULY\n",
      "CREATING DICTIONARY...\n",
      "DICTIONARY CREATION SUCCESSFUL!\n"
     ]
    }
   ],
   "source": [
    "dictionary, max_word, max_num_vowels, content, vowels, accetuated_vowels = create_dict()\n",
    "train_content, test_content, validate_content = split_content(content, 0.2, '../../internal_representations/inputs/content_shuffle_vector.h5')\n",
    "feature_dictionary = create_feature_dictionary()\n",
    "syllable_dictionary = create_syllables_dictionary(content, vowels)\n",
    "def generate_input_from_word(word, max_word, dictionary):\n",
    "    x = np.zeros((max_word, len(dictionary)))\n",
    "    j = 0\n",
    "    for c in list(word):\n",
    "        index = 0\n",
    "        for d in dictionary:\n",
    "            if c == d:\n",
    "                x[j, index] = 1\n",
    "                break\n",
    "            index += 1\n",
    "        j += 1\n",
    "    return x\n",
    "\n",
    "# model = load_model()\n",
    "# prediction = predict(model, generate_input_from_word('hidrija'))\n",
    "# print decode_position(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iz', 'zva', 'ti']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create_syllables(content[375488][0], vowels)\n",
    "create_syllables('izzvati', vowels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'content' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-22f58ededea8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msyllables_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_syllables_dictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvowels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'content' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "syllables_dictionary = create_syllables_dictionary(content, vowels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '-o',\n",
       " 'a',\n",
       " 'ab',\n",
       " 'ah',\n",
       " 'akt',\n",
       " 'al',\n",
       " 'alf',\n",
       " 'alg',\n",
       " 'alt',\n",
       " 'am',\n",
       " 'an',\n",
       " 'ant',\n",
       " 'ar',\n",
       " 'arh',\n",
       " 'as',\n",
       " 'at',\n",
       " 'av',\n",
       " 'ba',\n",
       " 'bab',\n",
       " 'bah',\n",
       " 'baj',\n",
       " 'bajt',\n",
       " 'bak',\n",
       " 'bal',\n",
       " 'bam',\n",
       " 'ban',\n",
       " 'banj',\n",
       " 'bank',\n",
       " 'bar',\n",
       " 'bark',\n",
       " 'barv',\n",
       " 'bas',\n",
       " 'bast',\n",
       " 'bat',\n",
       " 'bav',\n",
       " 'baz',\n",
       " 'baÄ',\n",
       " 'baÅ¡',\n",
       " 'baÅ¾',\n",
       " 'bde',\n",
       " 'bdel',\n",
       " 'bdet',\n",
       " 'bdeÄ',\n",
       " 'bdi',\n",
       " 'bdim',\n",
       " 'bdiÅ¡',\n",
       " 'be',\n",
       " 'bec',\n",
       " 'bed',\n",
       " 'beg',\n",
       " 'beh',\n",
       " 'bej',\n",
       " 'bek',\n",
       " 'bel',\n",
       " 'belc',\n",
       " 'belj',\n",
       " 'belk',\n",
       " 'bem',\n",
       " 'ben',\n",
       " 'benj',\n",
       " 'benk',\n",
       " 'bent',\n",
       " 'ber',\n",
       " 'bes',\n",
       " 'bet',\n",
       " 'bev',\n",
       " 'bez',\n",
       " 'beÄ',\n",
       " 'beÅ¡',\n",
       " 'beÅ¾',\n",
       " 'bi',\n",
       " 'bic',\n",
       " 'bih',\n",
       " 'bij',\n",
       " 'bik',\n",
       " 'bil',\n",
       " 'bilj',\n",
       " 'bilk',\n",
       " 'bim',\n",
       " 'bin',\n",
       " 'bir',\n",
       " 'bisk',\n",
       " 'bit',\n",
       " 'bitk',\n",
       " 'biv',\n",
       " 'biÄ',\n",
       " 'biÅ¡',\n",
       " 'biÅ¡Ä',\n",
       " 'bja',\n",
       " 'bjav',\n",
       " 'bje',\n",
       " 'bjej',\n",
       " 'bjekt',\n",
       " 'bjel',\n",
       " 'bjem',\n",
       " 'bjest',\n",
       " 'bjet',\n",
       " 'bjeÅ¡',\n",
       " 'bji',\n",
       " 'bjih',\n",
       " 'bjim',\n",
       " 'bjo',\n",
       " 'bju',\n",
       " 'bla',\n",
       " 'blag',\n",
       " 'blah',\n",
       " 'blak',\n",
       " 'blam',\n",
       " 'blan',\n",
       " 'blast',\n",
       " 'blat',\n",
       " 'ble',\n",
       " 'bled',\n",
       " 'blej',\n",
       " 'blek',\n",
       " 'blem',\n",
       " 'blesk',\n",
       " 'blest',\n",
       " 'blet',\n",
       " 'bleÄ',\n",
       " 'bli',\n",
       " 'blic',\n",
       " 'blih',\n",
       " 'blij',\n",
       " 'blik',\n",
       " 'blil',\n",
       " 'blim',\n",
       " 'blin',\n",
       " 'blisk',\n",
       " 'blit',\n",
       " 'bliz',\n",
       " 'bliÅ¡',\n",
       " 'bliÅ¡Ä',\n",
       " 'bliÅ¾',\n",
       " 'blja',\n",
       " 'bljah',\n",
       " 'bljaj',\n",
       " 'bljal',\n",
       " 'bljam',\n",
       " 'bljan',\n",
       " 'bljanj',\n",
       " 'bljat',\n",
       " 'bljav',\n",
       " 'bljaÅ¡',\n",
       " 'blje',\n",
       " 'bljem',\n",
       " 'bljen',\n",
       " 'bljenj',\n",
       " 'bljev',\n",
       " 'bljeÅ¡',\n",
       " 'blji',\n",
       " 'bljih',\n",
       " 'bljim',\n",
       " 'bljiv',\n",
       " 'bljo',\n",
       " 'blju',\n",
       " 'bljub',\n",
       " 'bljuj',\n",
       " 'bljuv',\n",
       " 'blo',\n",
       " 'blod',\n",
       " 'blok',\n",
       " 'blom',\n",
       " 'blov',\n",
       " 'blu',\n",
       " 'bme',\n",
       " 'bmi',\n",
       " 'bmo',\n",
       " 'bmol',\n",
       " 'bmor',\n",
       " 'bna',\n",
       " 'bnaj',\n",
       " 'bnal',\n",
       " 'bnam',\n",
       " 'bnanj',\n",
       " 'bnat',\n",
       " 'bnaÅ¡',\n",
       " 'bne',\n",
       " 'bnej',\n",
       " 'bnel',\n",
       " 'bnem',\n",
       " 'bnenj',\n",
       " 'bnest',\n",
       " 'bnet',\n",
       " 'bneÄ',\n",
       " 'bneÅ¡',\n",
       " 'bneÅ¾',\n",
       " 'bni',\n",
       " 'bnic',\n",
       " 'bnih',\n",
       " 'bnik',\n",
       " 'bnil',\n",
       " 'bnim',\n",
       " 'bnin',\n",
       " 'bnit',\n",
       " 'bniÅ¡',\n",
       " 'bno',\n",
       " 'bnom',\n",
       " 'bnost',\n",
       " 'bnov',\n",
       " 'bnu',\n",
       " 'bo',\n",
       " 'bob',\n",
       " 'bod',\n",
       " 'bog',\n",
       " 'boj',\n",
       " 'bok',\n",
       " 'boks',\n",
       " 'bol',\n",
       " 'bolh',\n",
       " 'bolj',\n",
       " 'bolk',\n",
       " 'bom',\n",
       " 'bomb',\n",
       " 'bon',\n",
       " 'bor',\n",
       " 'borb',\n",
       " 'borz',\n",
       " 'bos',\n",
       " 'bost',\n",
       " 'bot',\n",
       " 'bov',\n",
       " 'boÄ',\n",
       " 'boÅ¡',\n",
       " 'br',\n",
       " 'bra',\n",
       " 'brad',\n",
       " 'bral',\n",
       " 'bram',\n",
       " 'bramb',\n",
       " 'bran',\n",
       " 'branj',\n",
       " 'brat',\n",
       " 'braz',\n",
       " 'brazb',\n",
       " 'brazd',\n",
       " 'brc',\n",
       " 'bre',\n",
       " 'bred',\n",
       " 'breg',\n",
       " 'breh',\n",
       " 'brem',\n",
       " 'bren',\n",
       " 'brest',\n",
       " 'brez',\n",
       " 'bri',\n",
       " 'brid',\n",
       " 'brih',\n",
       " 'brij',\n",
       " 'brik',\n",
       " 'bril',\n",
       " 'brim',\n",
       " 'brin',\n",
       " 'bris',\n",
       " 'brit',\n",
       " 'briv',\n",
       " 'briz',\n",
       " 'briÅ¡',\n",
       " 'brk',\n",
       " 'brn',\n",
       " 'bro',\n",
       " 'brok',\n",
       " 'brom',\n",
       " 'bron',\n",
       " 'brost',\n",
       " 'brot',\n",
       " 'brov',\n",
       " 'broz',\n",
       " 'brozg',\n",
       " 'broÄ',\n",
       " 'broÅ¡k',\n",
       " 'brt',\n",
       " 'bru',\n",
       " 'bruh',\n",
       " 'brun',\n",
       " 'brv',\n",
       " 'brz',\n",
       " 'brÅ¾',\n",
       " 'bsti',\n",
       " 'bu',\n",
       " 'bud',\n",
       " 'buh',\n",
       " 'buj',\n",
       " 'buk',\n",
       " 'bul',\n",
       " 'bum',\n",
       " 'bun',\n",
       " 'bup',\n",
       " 'bus',\n",
       " 'but',\n",
       " 'buÄ',\n",
       " 'bva',\n",
       " 'bve',\n",
       " 'bven',\n",
       " 'bvi',\n",
       " 'bvla',\n",
       " 'bvo',\n",
       " 'ca',\n",
       " 'cah',\n",
       " 'caj',\n",
       " 'cal',\n",
       " 'cam',\n",
       " 'can',\n",
       " 'canj',\n",
       " 'cap',\n",
       " 'car',\n",
       " 'cat',\n",
       " 'cav',\n",
       " 'caÅ¡',\n",
       " 'ce',\n",
       " 'ced',\n",
       " 'ceh',\n",
       " 'cej',\n",
       " 'cek',\n",
       " 'cel',\n",
       " 'celj',\n",
       " 'cem',\n",
       " 'cen',\n",
       " 'cenc',\n",
       " 'cent',\n",
       " 'cep',\n",
       " 'ceps',\n",
       " 'cept',\n",
       " 'cer',\n",
       " 'cert',\n",
       " 'ces',\n",
       " 'cest',\n",
       " 'cev',\n",
       " 'cevk',\n",
       " 'ci',\n",
       " 'cid',\n",
       " 'cih',\n",
       " 'cij',\n",
       " 'cilj',\n",
       " 'cim',\n",
       " 'cin',\n",
       " 'cip',\n",
       " 'cir',\n",
       " 'cist',\n",
       " 'ciz',\n",
       " 'cka',\n",
       " 'ckah',\n",
       " 'ckaj',\n",
       " 'ckal',\n",
       " 'ckam',\n",
       " 'ckan',\n",
       " 'ckanj',\n",
       " 'ckat',\n",
       " 'ckaÅ¡',\n",
       " 'cke',\n",
       " 'cki',\n",
       " 'ckih',\n",
       " 'cko',\n",
       " 'ckom',\n",
       " 'ckov',\n",
       " 'cku',\n",
       " 'clja',\n",
       " 'cljaj',\n",
       " 'cljal',\n",
       " 'cljam',\n",
       " 'cljat',\n",
       " 'cljav',\n",
       " 'cljaÅ¡',\n",
       " 'clje',\n",
       " 'cljem',\n",
       " 'cljev',\n",
       " 'clji',\n",
       " 'cljih',\n",
       " 'clju',\n",
       " 'cme',\n",
       " 'cmo',\n",
       " 'cmok',\n",
       " 'cna',\n",
       " 'cne',\n",
       " 'cnem',\n",
       " 'cneÅ¡',\n",
       " 'cni',\n",
       " 'cnih',\n",
       " 'cnil',\n",
       " 'cnim',\n",
       " 'cnit',\n",
       " 'cnje',\n",
       " 'cnjen',\n",
       " 'cno',\n",
       " 'co',\n",
       " 'coj',\n",
       " 'con',\n",
       " 'cr',\n",
       " 'cu',\n",
       " 'cuj',\n",
       " 'cul',\n",
       " 'cunj',\n",
       " 'cur',\n",
       " 'cva',\n",
       " 'cve',\n",
       " 'cvet',\n",
       " 'cvi',\n",
       " 'cvr',\n",
       " 'cvre',\n",
       " 'cvrem',\n",
       " 'cvret',\n",
       " 'cvreÅ¡',\n",
       " 'cvri',\n",
       " 'cvrl',\n",
       " 'cvroÄ',\n",
       " 'cvrt',\n",
       " 'da',\n",
       " 'dah',\n",
       " 'daj',\n",
       " 'dak',\n",
       " 'dal',\n",
       " 'dalj',\n",
       " 'dalk',\n",
       " 'dam',\n",
       " 'dan',\n",
       " 'danj',\n",
       " 'dank',\n",
       " 'dar',\n",
       " 'dard',\n",
       " 'dast',\n",
       " 'dat',\n",
       " 'dav',\n",
       " 'daÅ¡',\n",
       " 'de',\n",
       " 'dec',\n",
       " 'ded',\n",
       " 'deh',\n",
       " 'dej',\n",
       " 'dek',\n",
       " 'deks',\n",
       " 'del',\n",
       " 'delj',\n",
       " 'dem',\n",
       " 'den',\n",
       " 'denc',\n",
       " 'denj',\n",
       " 'dent',\n",
       " 'dentk',\n",
       " 'der',\n",
       " 'des',\n",
       " 'desk',\n",
       " 'det',\n",
       " 'dev',\n",
       " 'dez',\n",
       " 'deÄ',\n",
       " 'deÅ¡',\n",
       " 'deÅ¾',\n",
       " 'di',\n",
       " 'dic',\n",
       " 'dig',\n",
       " 'dih',\n",
       " 'dij',\n",
       " 'dik',\n",
       " 'dil',\n",
       " 'dim',\n",
       " 'din',\n",
       " 'dinj',\n",
       " 'dink',\n",
       " 'dir',\n",
       " 'dirk',\n",
       " 'disk',\n",
       " 'dist',\n",
       " 'dit',\n",
       " 'div',\n",
       " 'diÄ',\n",
       " 'diÅ¡',\n",
       " 'diÅ¡Ä',\n",
       " 'diÅ¾',\n",
       " 'dja',\n",
       " 'djah',\n",
       " 'djam',\n",
       " 'djar',\n",
       " 'dje',\n",
       " 'djem',\n",
       " 'djev',\n",
       " 'djez',\n",
       " 'dji',\n",
       " 'djih',\n",
       " 'djim',\n",
       " 'djo',\n",
       " 'dju',\n",
       " 'dla',\n",
       " 'dlag',\n",
       " 'dlak',\n",
       " 'dlan',\n",
       " 'dle',\n",
       " 'dlem',\n",
       " 'dlet',\n",
       " 'dleÄ',\n",
       " 'dleÅ¾',\n",
       " 'dli',\n",
       " 'dlih',\n",
       " 'dlim',\n",
       " 'dlin',\n",
       " 'dlja',\n",
       " 'dljah',\n",
       " 'dljaj',\n",
       " 'dljam',\n",
       " 'dlje',\n",
       " 'dljem',\n",
       " 'dljev',\n",
       " 'dlji',\n",
       " 'dljih',\n",
       " 'dljiv',\n",
       " 'dljivk',\n",
       " 'dljo',\n",
       " 'dlju',\n",
       " 'dlo',\n",
       " 'dlog',\n",
       " 'dlok',\n",
       " 'dlom',\n",
       " 'dloÄ',\n",
       " 'dloÄb',\n",
       " 'dlu',\n",
       " 'dma',\n",
       " 'dme',\n",
       " 'dmem',\n",
       " 'dmer',\n",
       " 'dmet',\n",
       " 'dmev',\n",
       " 'dmi',\n",
       " 'dmih',\n",
       " 'dmik',\n",
       " 'dmim',\n",
       " 'dmin',\n",
       " 'dmo',\n",
       " 'dmor',\n",
       " 'dmr',\n",
       " 'dmre',\n",
       " 'dmrem',\n",
       " 'dmret',\n",
       " 'dmreÅ¡',\n",
       " 'dmri',\n",
       " 'dmrl',\n",
       " 'dmrt',\n",
       " 'dna',\n",
       " 'dne',\n",
       " 'dneh',\n",
       " 'dnej',\n",
       " 'dnem',\n",
       " 'dnest',\n",
       " 'dneÅ¡',\n",
       " 'dneÅ¾',\n",
       " 'dni',\n",
       " 'dnic',\n",
       " 'dnih',\n",
       " 'dnik',\n",
       " 'dnil',\n",
       " 'dnim',\n",
       " 'dnin',\n",
       " 'dnit',\n",
       " 'dnja',\n",
       " 'dnjah',\n",
       " 'dnjak',\n",
       " 'dnjam',\n",
       " 'dnjav',\n",
       " 'dnje',\n",
       " 'dnjem',\n",
       " 'dnjev',\n",
       " 'dnji',\n",
       " 'dnjic',\n",
       " 'dnjih',\n",
       " 'dnjik',\n",
       " 'dnjim',\n",
       " 'dnjiÄ',\n",
       " 'dnjo',\n",
       " 'dnju',\n",
       " 'dno',\n",
       " 'dnom',\n",
       " 'dnos',\n",
       " 'dnost',\n",
       " 'dnot',\n",
       " 'dnov',\n",
       " 'dnu',\n",
       " 'do',\n",
       " 'dob',\n",
       " 'dod',\n",
       " 'doj',\n",
       " 'dojk',\n",
       " 'dol',\n",
       " 'dolbst',\n",
       " 'dolg',\n",
       " 'dom',\n",
       " 'don',\n",
       " 'dont',\n",
       " 'dor',\n",
       " 'dost',\n",
       " 'dot',\n",
       " 'dov',\n",
       " 'doz',\n",
       " 'doÄ',\n",
       " 'dr',\n",
       " 'dra',\n",
       " 'drag',\n",
       " 'drah',\n",
       " 'draj',\n",
       " 'dral',\n",
       " 'dram',\n",
       " 'dran',\n",
       " 'dranj',\n",
       " 'dras',\n",
       " 'drast',\n",
       " 'drat',\n",
       " 'drav',\n",
       " 'draz',\n",
       " 'draÅ¡',\n",
       " 'dre',\n",
       " 'dred',\n",
       " 'dredb',\n",
       " 'dreg',\n",
       " 'drej',\n",
       " 'drek',\n",
       " 'drel',\n",
       " 'drem',\n",
       " 'dren',\n",
       " 'dres',\n",
       " 'dret',\n",
       " 'dreÄ',\n",
       " 'dreÅ¡',\n",
       " 'drg',\n",
       " 'dri',\n",
       " 'dric',\n",
       " 'drid',\n",
       " 'drih',\n",
       " 'drij',\n",
       " 'dril',\n",
       " 'drim',\n",
       " 'drin',\n",
       " 'drisk',\n",
       " 'drit',\n",
       " 'driv',\n",
       " 'driÅ¡',\n",
       " 'driÅ¡Ä',\n",
       " 'drl',\n",
       " 'dro',\n",
       " 'drob',\n",
       " 'drog',\n",
       " 'drom',\n",
       " 'drost',\n",
       " 'drov',\n",
       " 'droz',\n",
       " 'drozg',\n",
       " 'drt',\n",
       " 'dru',\n",
       " 'drug',\n",
       " 'druj',\n",
       " 'druÅ¾',\n",
       " 'druÅ¾b',\n",
       " 'drv',\n",
       " 'drÅ¾',\n",
       " 'dska',\n",
       " 'dske',\n",
       " 'dskem',\n",
       " 'dski',\n",
       " 'dskih',\n",
       " 'dskim',\n",
       " 'dsko',\n",
       " 'du',\n",
       " 'dud',\n",
       " 'duh',\n",
       " 'duj',\n",
       " 'duk',\n",
       " 'dukt',\n",
       " 'dum',\n",
       " 'dur',\n",
       " 'dut',\n",
       " 'duÅ¡',\n",
       " 'dva',\n",
       " 'dvaj',\n",
       " 'dve',\n",
       " 'dveh',\n",
       " 'dvest',\n",
       " 'dveÄ',\n",
       " 'dvi',\n",
       " 'dvic',\n",
       " 'dvig',\n",
       " 'dvij',\n",
       " 'dvil',\n",
       " 'dvit',\n",
       " 'dviÄ',\n",
       " 'dvla',\n",
       " 'dvlad',\n",
       " 'dvle',\n",
       " 'dvleÄ',\n",
       " 'dvo',\n",
       " 'dvoj',\n",
       " 'dvom',\n",
       " 'dvor',\n",
       " 'dvoz',\n",
       " 'dvr',\n",
       " 'dvra',\n",
       " 'dvre',\n",
       " 'dvreÄ',\n",
       " 'dvrst',\n",
       " 'dÅ¾a',\n",
       " 'dÅ¾un',\n",
       " 'e',\n",
       " 'ef',\n",
       " 'el',\n",
       " 'em',\n",
       " 'en',\n",
       " 'ent',\n",
       " 'entk',\n",
       " 'er',\n",
       " 'et',\n",
       " 'ev',\n",
       " 'fa',\n",
       " 'fag',\n",
       " 'fah',\n",
       " 'faj',\n",
       " 'fal',\n",
       " 'fam',\n",
       " 'fan',\n",
       " 'fanj',\n",
       " 'fant',\n",
       " 'far',\n",
       " 'farkt',\n",
       " 'farm',\n",
       " 'fat',\n",
       " 'faz',\n",
       " 'faÅ¡',\n",
       " 'fe',\n",
       " 'fekt',\n",
       " 'fen',\n",
       " 'fer',\n",
       " 'fev',\n",
       " 'fi',\n",
       " 'fih',\n",
       " 'fij',\n",
       " 'fil',\n",
       " 'film',\n",
       " 'fin',\n",
       " 'firm',\n",
       " 'fit',\n",
       " 'fje',\n",
       " 'flav',\n",
       " 'flavt',\n",
       " 'fle',\n",
       " 'fleks',\n",
       " 'fli',\n",
       " 'flikt',\n",
       " 'flo',\n",
       " 'flot',\n",
       " 'fne',\n",
       " 'fnem',\n",
       " 'fneÅ¡',\n",
       " 'fni',\n",
       " 'fnil',\n",
       " 'fnit',\n",
       " 'fo',\n",
       " 'fol',\n",
       " 'fom',\n",
       " 'fon',\n",
       " 'fond',\n",
       " 'for',\n",
       " 'form',\n",
       " 'fov',\n",
       " 'fr',\n",
       " 'fra',\n",
       " 'frah',\n",
       " 'fraj',\n",
       " 'frak',\n",
       " 'fral',\n",
       " 'fram',\n",
       " 'fran',\n",
       " 'frank',\n",
       " 'frat',\n",
       " 'fraz',\n",
       " 'fraÄ',\n",
       " 'fraÅ¡',\n",
       " 'fre',\n",
       " 'fresk',\n",
       " 'fri',\n",
       " 'fro',\n",
       " 'fron',\n",
       " 'front',\n",
       " 'fska',\n",
       " 'fske',\n",
       " 'fskem',\n",
       " 'fski',\n",
       " 'fskih',\n",
       " 'fskim',\n",
       " 'fsko',\n",
       " 'fta',\n",
       " 'ftar',\n",
       " 'fte',\n",
       " 'fti',\n",
       " 'fto',\n",
       " 'fu',\n",
       " 'fug',\n",
       " 'fum',\n",
       " 'fun',\n",
       " 'funt',\n",
       " 'fut',\n",
       " 'ga',\n",
       " 'ga_',\n",
       " 'gad',\n",
       " 'gah',\n",
       " 'gaj',\n",
       " 'gajn',\n",
       " 'gal',\n",
       " 'galk',\n",
       " 'gam',\n",
       " 'gan',\n",
       " 'gand',\n",
       " 'ganj',\n",
       " 'gank',\n",
       " 'gar',\n",
       " 'gar_',\n",
       " 'garn',\n",
       " 'gast',\n",
       " 'gat',\n",
       " 'gav',\n",
       " 'gaÄ',\n",
       " 'gaÅ¡',\n",
       " 'ge',\n",
       " 'geh',\n",
       " 'gej',\n",
       " 'gel',\n",
       " 'gelc',\n",
       " 'gelj',\n",
       " 'gem',\n",
       " 'gen',\n",
       " 'genc',\n",
       " 'gend',\n",
       " 'genj',\n",
       " 'gent',\n",
       " 'gentk',\n",
       " 'ger',\n",
       " 'gest',\n",
       " 'get',\n",
       " 'geÅ¡',\n",
       " 'gi',\n",
       " 'gib',\n",
       " 'gic',\n",
       " 'gih',\n",
       " 'gij',\n",
       " 'gik',\n",
       " 'gim',\n",
       " 'gin',\n",
       " 'ginj',\n",
       " 'giÄ',\n",
       " 'giÅ¡Ä',\n",
       " 'gje',\n",
       " 'gla',\n",
       " 'glad',\n",
       " 'glah',\n",
       " 'glam',\n",
       " 'glar',\n",
       " 'glas',\n",
       " 'glasb',\n",
       " 'glast',\n",
       " 'glat',\n",
       " 'glav',\n",
       " 'gle',\n",
       " 'gled',\n",
       " 'glej',\n",
       " 'glem',\n",
       " 'glen',\n",
       " 'gler',\n",
       " 'gleÄ',\n",
       " 'gli',\n",
       " 'glic',\n",
       " 'glih',\n",
       " 'glil',\n",
       " 'glim',\n",
       " 'glit',\n",
       " 'gliÅ¡',\n",
       " 'glja',\n",
       " 'gljaj',\n",
       " 'gljal',\n",
       " 'gljam',\n",
       " 'gljanj',\n",
       " 'gljat',\n",
       " 'gljaÅ¡',\n",
       " 'glje',\n",
       " 'gljem',\n",
       " 'gljen',\n",
       " 'gljev',\n",
       " 'glji',\n",
       " 'gljih',\n",
       " 'gljiv',\n",
       " 'glju',\n",
       " 'glo',\n",
       " 'glom',\n",
       " 'glost',\n",
       " 'glov',\n",
       " 'glu',\n",
       " 'gluh',\n",
       " 'gma',\n",
       " 'gmajn',\n",
       " 'gmen',\n",
       " 'gment',\n",
       " 'gmi',\n",
       " 'gmo',\n",
       " 'gmot',\n",
       " 'gna',\n",
       " 'gnal',\n",
       " 'gnan',\n",
       " 'gnanj',\n",
       " 'gnat',\n",
       " 'gne',\n",
       " 'gnem',\n",
       " 'gnest',\n",
       " 'gnet',\n",
       " 'gnev',\n",
       " 'gnez',\n",
       " 'gnezd',\n",
       " 'gneÄ',\n",
       " 'gneÅ¡',\n",
       " 'gni',\n",
       " 'gnih',\n",
       " 'gnij',\n",
       " 'gnil',\n",
       " 'gnin',\n",
       " 'gnit',\n",
       " 'gnja',\n",
       " 'gnjat',\n",
       " 'gnje',\n",
       " 'gnjem',\n",
       " 'gnjen',\n",
       " 'gnjenj',\n",
       " 'gnjev',\n",
       " 'gnji',\n",
       " 'gnjih',\n",
       " 'gnjiÅ¡Ä',\n",
       " 'gnju',\n",
       " 'gno',\n",
       " 'gnoj',\n",
       " 'gnom',\n",
       " 'gnov',\n",
       " 'gnoz',\n",
       " 'gnu',\n",
       " 'gnus',\n",
       " 'go',\n",
       " 'gob',\n",
       " 'god',\n",
       " 'godb',\n",
       " 'goj',\n",
       " 'gol',\n",
       " 'golt',\n",
       " 'gom',\n",
       " 'gon',\n",
       " 'gonj',\n",
       " 'gor',\n",
       " 'gos',\n",
       " 'gost',\n",
       " 'got',\n",
       " 'gov',\n",
       " 'govk',\n",
       " 'goz',\n",
       " 'gozd',\n",
       " 'goÄ',\n",
       " 'gr',\n",
       " 'gra',\n",
       " 'grad',\n",
       " 'graf',\n",
       " 'grah',\n",
       " 'graj',\n",
       " 'gral',\n",
       " 'gralk',\n",
       " 'gram',\n",
       " 'gran',\n",
       " 'granj',\n",
       " 'grat',\n",
       " 'graÄ',\n",
       " 'graÄk',\n",
       " 'graÅ¡',\n",
       " 'grb',\n",
       " 'grd',\n",
       " 'gre',\n",
       " 'greb',\n",
       " 'grebst',\n",
       " 'gred',\n",
       " 'greh',\n",
       " 'grej',\n",
       " 'grel',\n",
       " 'grem',\n",
       " 'gren',\n",
       " 'gres',\n",
       " 'gret',\n",
       " 'greÅ¡',\n",
       " 'gri',\n",
       " 'gric',\n",
       " 'grih',\n",
       " 'grist',\n",
       " 'griv',\n",
       " 'griz',\n",
       " 'griÄ',\n",
       " 'griÅ¡Ä',\n",
       " 'grl',\n",
       " 'grm',\n",
       " 'gro',\n",
       " 'grob',\n",
       " 'grof',\n",
       " 'grom',\n",
       " 'grov',\n",
       " 'groz',\n",
       " 'grozd',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllables_dictionary = sorted(syllables_dictionary)\n",
    "syllables_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ../../../prepare_data.py\n",
    "# generate_X_and_y(dictionary, max_word, max_num_vowels, content, vowels, accetuated_vowels, feature_dictionary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
