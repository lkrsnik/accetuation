{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import unicode_literals\n",
    "# text in Western (Windows 1252)\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "# import StringIO\n",
    "import math\n",
    "from keras import optimizers, metrics\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import regularizers\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import load_model\n",
    "# from keras import backend as Input\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ../../../prepare_data.py\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../../')\n",
    "from prepare_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run ../../../prepare_data.py\n",
    "# X_train, X_other_features_train, y_train, X_test, X_other_features_test, y_test, X_validate, X_other_features_validate, y_validate = generate_syllable_inputs('../../internal_representations/inputs/content_shuffle_vector.h5', '../../internal_representations/inputs/shuffle_vector')\n",
    "# save_inputs('../../internal_representations/inputs/shuffeled_syllable_train_inputs.h5', X_train, y_train, other_features = X_other_features_train)\n",
    "# save_inputs('../../internal_representations/inputs/shuffeled_syllable_test_inputs.h5', X_test, y_test, other_features = X_other_features_test)\n",
    "# save_inputs('../../internal_representations/inputs/shuffeled_syllable_validate_inputs.h5', X_validate, y_validate,  other_features = X_other_features_validate)\n",
    "X_train, X_other_features_train, y_train = load_inputs('../../internal_representations/inputs/shuffeled_syllable_train_inputs.h5', other_features=True)\n",
    "X_test, X_other_features_test, y_test = load_inputs('../../internal_representations/inputs/shuffeled_syllable_test_inputs.h5', other_features=True)\n",
    "X_validate, X_other_features_validate, y_validate = load_inputs('../../internal_representations/inputs/shuffeled_syllable_validate_inputs.h5', other_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../../prepare_data.py\n",
    "gen = generate_fake_epoch_syllables(X_train[:20], X_other_features_train[:20], y_train[:20], 16, 5168)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 11, 5168)\n",
      "[0 0 0 ..., 0 0 0]\n",
      "bolj\n",
      "[0 0 0 ..., 0 0 0]\n",
      "ši\n",
      "[0 0 0 ..., 0 0 0]\n",
      "mi\n",
      "[1 0 0 ..., 0 0 0]\n",
      "\n",
      "[1 0 0 ..., 0 0 0]\n",
      "\n",
      "[1 0 0 ..., 0 0 0]\n",
      "\n",
      "[1 0 0 ..., 0 0 0]\n",
      "\n",
      "[1 0 0 ..., 0 0 0]\n",
      "\n",
      "[1 0 0 ..., 0 0 0]\n",
      "\n",
      "[1 0 0 ..., 0 0 0]\n",
      "\n",
      "[1 0 0 ..., 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prints test word from generator\n",
    "# print(X_train[0])\n",
    "# print(syllable_dictionary[test[0][0][0][0].tolist().index(1)])\n",
    "print(np.array(test[0][0]).shape)\n",
    "for el in test[0][0][0]:\n",
    "    print(el)\n",
    "    print(syllable_dictionary[el.tolist().index(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train[0])\n",
    "test = next(gen)\n",
    "# eye = np.eye(5168)[X_train[0]]\n",
    "# print(X_train[0].tolist())\n",
    "# np.eye(5168)[[2, 1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5168)\n"
     ]
    }
   ],
   "source": [
    "np.eye(10)[[3,7,2,5]]\n",
    "print(eye[[2, 3]].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54222, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validate.shape\n",
    "# len(syllable_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5168\n",
      "CREATING OTHER FEATURES...\n",
      "OTHER FEATURES CREATED!\n",
      "SHUFFELING INPUTS...\n",
      "(430151, 11)\n",
      "(430151,)\n",
      "INPUTS SHUFFELED!\n"
     ]
    }
   ],
   "source": [
    "print(len(syllable_dictionary))\n",
    "shuffle_vector_location = '../../internal_representations/inputs/shuffle_vector'\n",
    "X_train, X_other_features_train, y_train = generate_syllable_X_and_y(syllable_dictionary, max_word, max_num_vowels, train_content, vowels, accetuated_vowels, feature_dictionary, shuffle_vector_location + '_train.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(430151, 23, 30)\n",
      "(52058, 23, 30)\n",
      "(54222, 23, 30)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dictionary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-98de5454bb55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# print (X_other_features[178200])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdecode_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m38\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdecode_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecode_position\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# print (X_other_features_train[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdecode_X_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_dictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX_other_features_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecode_position\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dictionary' is not defined"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print (X_test.shape)\n",
    "print (X_validate.shape)\n",
    "# X_other_features = create_X_features(content)\n",
    "# print (X_other_features[178200])\n",
    "decode_position = 38\n",
    "print (decode_input(X_validate[decode_position], dictionary))\n",
    "# print (X_other_features_train[0])\n",
    "print (decode_X_features(feature_dictionary, [X_other_features_train[decode_position]]))\n",
    "# print (len(X_other_features_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_examples = len(X_train) # training set size\n",
    "# nn_input_dim = max_word * len(dictionary) # input layer dimensionality\n",
    "# nn_output_dim = max_num_vowels * max_num_vowels # output layer dimensionality\n",
    "nn_output_dim = 11\n",
    "nn_hdim = 516\n",
    "batch_size = 16\n",
    "actual_epoch = 1\n",
    "num_fake_epoch = 20\n",
    "\n",
    "# Gradient descent parameters (I picked these by hand)\n",
    "# epsilon = 1 # learning rate for gradient descent\n",
    "# reg_lambda = 1 # regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_input_shape=(11, 5168)\n",
    "othr_input = (140, )\n",
    "\n",
    "conv_input = Input(shape=conv_input_shape, name='conv_input')\n",
    "# x_conv = Conv1D(43, (3), padding='same', activation='relu')(conv_input)\n",
    "x_conv = Conv1D(43, (3), padding='same', activation='relu')(conv_input)\n",
    "x_conv = MaxPooling1D(pool_size=2)(x_conv)\n",
    "x_conv = Flatten()(x_conv)\n",
    "# x_conv = Dense(516, activation='relu', kernel_constraint=maxnorm(3))(x_conv)\n",
    "\n",
    "othr_input = Input(shape=othr_input, name='othr_input')\n",
    "# x_othr = Dense(256, input_dim=167, activation='relu')(othr_input)\n",
    "# x_othr = Dropout(0.3)(x_othr)\n",
    "# x_othr = Dense(512, activation='relu')(othr_input)\n",
    "# x_othr = Dropout(0.3)(x_othr)\n",
    "# x_othr = Dense(256, activation='relu')(othr_input)\n",
    "\n",
    "x = concatenate([x_conv, othr_input])\n",
    "# x = Dense(1024, input_dim=(516 + 256), activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(nn_output_dim, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[conv_input, othr_input], outputs=x)\n",
    "\n",
    "# epochs = 5\n",
    "# lrate = 0.1\n",
    "# decay = lrate/epochs\n",
    "# sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "# model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Compile model\n",
    "# keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "opt = optimizers.Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[actual_accuracy,])\n",
    "# model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit_generator(generate_fake_epoch_syllables(X_test[:1000], X_other_features_test[:1000], y_test[:1000], batch_size), X_test[:1000].shape[0]/(batch_size * num_fake_epoch), epochs=actual_epoch*num_fake_epoch, validation_data=generate_fake_epoch_syllables(X_test[:1000], X_other_features_test[:1000], y_test[:1000], batch_size), validation_steps=X_test[:1000].shape[0]/(batch_size * num_fake_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1345/1344 [==============================] - 178s - loss: 0.1377 - actual_accuracy: 0.4956 - val_loss: 0.1006 - val_actual_accuracy: 0.6894\n",
      "Epoch 2/20\n",
      "1345/1344 [==============================] - 187s - loss: 0.0946 - actual_accuracy: 0.7099 - val_loss: 0.0819 - val_actual_accuracy: 0.7692\n",
      "Epoch 3/20\n",
      " 508/1344 [==========>...................] - ETA: 100s - loss: 0.0804 - actual_accuracy: 0.7710"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-2c1a3ea57e2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# history = model.fit_generator(generate_fake_epoch(X_train, X_other_features_train, y_train, batch_size), X_train.shape[0]/(batch_size * num_fake_epoch), epochs=actual_epoch*num_fake_epoch, validation_data=([X_test, X_other_features_test], y_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_fake_epoch_syllables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_other_features_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_fake_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactual_epoch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_fake_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerate_fake_epoch_syllables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_other_features_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_fake_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# model.fit([X_train, X_other_features_train], y_train, validation_data=([X_validate, X_other_features_validate], y_validate), epochs=1, batch_size=16)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1874\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1875\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1876\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1878\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1618\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.5/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# history = model.fit_generator(generate_fake_epoch(X_train, X_other_features_train, y_train, batch_size), X_train.shape[0]/(batch_size * num_fake_epoch), epochs=actual_epoch*num_fake_epoch, validation_data=([X_test, X_other_features_test], y_test))\n",
    "history = model.fit_generator(generate_fake_epoch_syllables(X_train, X_other_features_train, y_train, batch_size), X_train.shape[0]/(batch_size * num_fake_epoch), epochs=actual_epoch*num_fake_epoch, validation_data=generate_fake_epoch_syllables(X_test, X_other_features_test, y_test, batch_size), validation_steps=X_test.shape[0]/(batch_size * num_fake_epoch))\n",
    "\n",
    "\n",
    "# model.fit([X_train, X_other_features_train], y_train, validation_data=([X_validate, X_other_features_validate], y_validate), epochs=1, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = '1_epoch'\n",
    "model.save(name + '.h5')\n",
    "output = open(name + '_history.pkl', 'wb')\n",
    "pickle.dump(history.history, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING CONTENT...\n",
      "CONTENT READ SUCCESSFULY\n",
      "CREATING DICTIONARY...\n",
      "DICTIONARY CREATION SUCCESSFUL!\n"
     ]
    }
   ],
   "source": [
    "dictionary, max_word, max_num_vowels, content, vowels, accetuated_vowels = create_dict()\n",
    "train_content, test_content, validate_content = split_content(content, 0.2, '../../internal_representations/inputs/content_shuffle_vector.h5')\n",
    "feature_dictionary = create_feature_dictionary()\n",
    "syllable_dictionary = create_syllables_dictionary(content, vowels)\n",
    "def generate_input_from_word(word, max_word, dictionary):\n",
    "    x = np.zeros((max_word, len(dictionary)))\n",
    "    j = 0\n",
    "    for c in list(word):\n",
    "        index = 0\n",
    "        for d in dictionary:\n",
    "            if c == d:\n",
    "                x[j, index] = 1\n",
    "                break\n",
    "            index += 1\n",
    "        j += 1\n",
    "    return x\n",
    "\n",
    "# model = load_model()\n",
    "# prediction = predict(model, generate_input_from_word('hidrija'))\n",
    "# print decode_position(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iz', 'zva', 'ti']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create_syllables(content[375488][0], vowels)\n",
    "create_syllables('izzvati', vowels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'content' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-22f58ededea8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msyllables_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_syllables_dictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvowels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'content' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "syllables_dictionary = create_syllables_dictionary(content, vowels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '-o',\n",
       " 'a',\n",
       " 'ab',\n",
       " 'ah',\n",
       " 'akt',\n",
       " 'al',\n",
       " 'alf',\n",
       " 'alg',\n",
       " 'alt',\n",
       " 'am',\n",
       " 'an',\n",
       " 'ant',\n",
       " 'ar',\n",
       " 'arh',\n",
       " 'as',\n",
       " 'at',\n",
       " 'av',\n",
       " 'ba',\n",
       " 'bab',\n",
       " 'bah',\n",
       " 'baj',\n",
       " 'bajt',\n",
       " 'bak',\n",
       " 'bal',\n",
       " 'bam',\n",
       " 'ban',\n",
       " 'banj',\n",
       " 'bank',\n",
       " 'bar',\n",
       " 'bark',\n",
       " 'barv',\n",
       " 'bas',\n",
       " 'bast',\n",
       " 'bat',\n",
       " 'bav',\n",
       " 'baz',\n",
       " 'bač',\n",
       " 'baš',\n",
       " 'baž',\n",
       " 'bde',\n",
       " 'bdel',\n",
       " 'bdet',\n",
       " 'bdeč',\n",
       " 'bdi',\n",
       " 'bdim',\n",
       " 'bdiš',\n",
       " 'be',\n",
       " 'bec',\n",
       " 'bed',\n",
       " 'beg',\n",
       " 'beh',\n",
       " 'bej',\n",
       " 'bek',\n",
       " 'bel',\n",
       " 'belc',\n",
       " 'belj',\n",
       " 'belk',\n",
       " 'bem',\n",
       " 'ben',\n",
       " 'benj',\n",
       " 'benk',\n",
       " 'bent',\n",
       " 'ber',\n",
       " 'bes',\n",
       " 'bet',\n",
       " 'bev',\n",
       " 'bez',\n",
       " 'beč',\n",
       " 'beš',\n",
       " 'bež',\n",
       " 'bi',\n",
       " 'bic',\n",
       " 'bih',\n",
       " 'bij',\n",
       " 'bik',\n",
       " 'bil',\n",
       " 'bilj',\n",
       " 'bilk',\n",
       " 'bim',\n",
       " 'bin',\n",
       " 'bir',\n",
       " 'bisk',\n",
       " 'bit',\n",
       " 'bitk',\n",
       " 'biv',\n",
       " 'bič',\n",
       " 'biš',\n",
       " 'bišč',\n",
       " 'bja',\n",
       " 'bjav',\n",
       " 'bje',\n",
       " 'bjej',\n",
       " 'bjekt',\n",
       " 'bjel',\n",
       " 'bjem',\n",
       " 'bjest',\n",
       " 'bjet',\n",
       " 'bješ',\n",
       " 'bji',\n",
       " 'bjih',\n",
       " 'bjim',\n",
       " 'bjo',\n",
       " 'bju',\n",
       " 'bla',\n",
       " 'blag',\n",
       " 'blah',\n",
       " 'blak',\n",
       " 'blam',\n",
       " 'blan',\n",
       " 'blast',\n",
       " 'blat',\n",
       " 'ble',\n",
       " 'bled',\n",
       " 'blej',\n",
       " 'blek',\n",
       " 'blem',\n",
       " 'blesk',\n",
       " 'blest',\n",
       " 'blet',\n",
       " 'bleč',\n",
       " 'bli',\n",
       " 'blic',\n",
       " 'blih',\n",
       " 'blij',\n",
       " 'blik',\n",
       " 'blil',\n",
       " 'blim',\n",
       " 'blin',\n",
       " 'blisk',\n",
       " 'blit',\n",
       " 'bliz',\n",
       " 'bliš',\n",
       " 'blišč',\n",
       " 'bliž',\n",
       " 'blja',\n",
       " 'bljah',\n",
       " 'bljaj',\n",
       " 'bljal',\n",
       " 'bljam',\n",
       " 'bljan',\n",
       " 'bljanj',\n",
       " 'bljat',\n",
       " 'bljav',\n",
       " 'bljaš',\n",
       " 'blje',\n",
       " 'bljem',\n",
       " 'bljen',\n",
       " 'bljenj',\n",
       " 'bljev',\n",
       " 'blješ',\n",
       " 'blji',\n",
       " 'bljih',\n",
       " 'bljim',\n",
       " 'bljiv',\n",
       " 'bljo',\n",
       " 'blju',\n",
       " 'bljub',\n",
       " 'bljuj',\n",
       " 'bljuv',\n",
       " 'blo',\n",
       " 'blod',\n",
       " 'blok',\n",
       " 'blom',\n",
       " 'blov',\n",
       " 'blu',\n",
       " 'bme',\n",
       " 'bmi',\n",
       " 'bmo',\n",
       " 'bmol',\n",
       " 'bmor',\n",
       " 'bna',\n",
       " 'bnaj',\n",
       " 'bnal',\n",
       " 'bnam',\n",
       " 'bnanj',\n",
       " 'bnat',\n",
       " 'bnaš',\n",
       " 'bne',\n",
       " 'bnej',\n",
       " 'bnel',\n",
       " 'bnem',\n",
       " 'bnenj',\n",
       " 'bnest',\n",
       " 'bnet',\n",
       " 'bneč',\n",
       " 'bneš',\n",
       " 'bnež',\n",
       " 'bni',\n",
       " 'bnic',\n",
       " 'bnih',\n",
       " 'bnik',\n",
       " 'bnil',\n",
       " 'bnim',\n",
       " 'bnin',\n",
       " 'bnit',\n",
       " 'bniš',\n",
       " 'bno',\n",
       " 'bnom',\n",
       " 'bnost',\n",
       " 'bnov',\n",
       " 'bnu',\n",
       " 'bo',\n",
       " 'bob',\n",
       " 'bod',\n",
       " 'bog',\n",
       " 'boj',\n",
       " 'bok',\n",
       " 'boks',\n",
       " 'bol',\n",
       " 'bolh',\n",
       " 'bolj',\n",
       " 'bolk',\n",
       " 'bom',\n",
       " 'bomb',\n",
       " 'bon',\n",
       " 'bor',\n",
       " 'borb',\n",
       " 'borz',\n",
       " 'bos',\n",
       " 'bost',\n",
       " 'bot',\n",
       " 'bov',\n",
       " 'boč',\n",
       " 'boš',\n",
       " 'br',\n",
       " 'bra',\n",
       " 'brad',\n",
       " 'bral',\n",
       " 'bram',\n",
       " 'bramb',\n",
       " 'bran',\n",
       " 'branj',\n",
       " 'brat',\n",
       " 'braz',\n",
       " 'brazb',\n",
       " 'brazd',\n",
       " 'brc',\n",
       " 'bre',\n",
       " 'bred',\n",
       " 'breg',\n",
       " 'breh',\n",
       " 'brem',\n",
       " 'bren',\n",
       " 'brest',\n",
       " 'brez',\n",
       " 'bri',\n",
       " 'brid',\n",
       " 'brih',\n",
       " 'brij',\n",
       " 'brik',\n",
       " 'bril',\n",
       " 'brim',\n",
       " 'brin',\n",
       " 'bris',\n",
       " 'brit',\n",
       " 'briv',\n",
       " 'briz',\n",
       " 'briš',\n",
       " 'brk',\n",
       " 'brn',\n",
       " 'bro',\n",
       " 'brok',\n",
       " 'brom',\n",
       " 'bron',\n",
       " 'brost',\n",
       " 'brot',\n",
       " 'brov',\n",
       " 'broz',\n",
       " 'brozg',\n",
       " 'broč',\n",
       " 'brošk',\n",
       " 'brt',\n",
       " 'bru',\n",
       " 'bruh',\n",
       " 'brun',\n",
       " 'brv',\n",
       " 'brz',\n",
       " 'brž',\n",
       " 'bsti',\n",
       " 'bu',\n",
       " 'bud',\n",
       " 'buh',\n",
       " 'buj',\n",
       " 'buk',\n",
       " 'bul',\n",
       " 'bum',\n",
       " 'bun',\n",
       " 'bup',\n",
       " 'bus',\n",
       " 'but',\n",
       " 'buč',\n",
       " 'bva',\n",
       " 'bve',\n",
       " 'bven',\n",
       " 'bvi',\n",
       " 'bvla',\n",
       " 'bvo',\n",
       " 'ca',\n",
       " 'cah',\n",
       " 'caj',\n",
       " 'cal',\n",
       " 'cam',\n",
       " 'can',\n",
       " 'canj',\n",
       " 'cap',\n",
       " 'car',\n",
       " 'cat',\n",
       " 'cav',\n",
       " 'caš',\n",
       " 'ce',\n",
       " 'ced',\n",
       " 'ceh',\n",
       " 'cej',\n",
       " 'cek',\n",
       " 'cel',\n",
       " 'celj',\n",
       " 'cem',\n",
       " 'cen',\n",
       " 'cenc',\n",
       " 'cent',\n",
       " 'cep',\n",
       " 'ceps',\n",
       " 'cept',\n",
       " 'cer',\n",
       " 'cert',\n",
       " 'ces',\n",
       " 'cest',\n",
       " 'cev',\n",
       " 'cevk',\n",
       " 'ci',\n",
       " 'cid',\n",
       " 'cih',\n",
       " 'cij',\n",
       " 'cilj',\n",
       " 'cim',\n",
       " 'cin',\n",
       " 'cip',\n",
       " 'cir',\n",
       " 'cist',\n",
       " 'ciz',\n",
       " 'cka',\n",
       " 'ckah',\n",
       " 'ckaj',\n",
       " 'ckal',\n",
       " 'ckam',\n",
       " 'ckan',\n",
       " 'ckanj',\n",
       " 'ckat',\n",
       " 'ckaš',\n",
       " 'cke',\n",
       " 'cki',\n",
       " 'ckih',\n",
       " 'cko',\n",
       " 'ckom',\n",
       " 'ckov',\n",
       " 'cku',\n",
       " 'clja',\n",
       " 'cljaj',\n",
       " 'cljal',\n",
       " 'cljam',\n",
       " 'cljat',\n",
       " 'cljav',\n",
       " 'cljaš',\n",
       " 'clje',\n",
       " 'cljem',\n",
       " 'cljev',\n",
       " 'clji',\n",
       " 'cljih',\n",
       " 'clju',\n",
       " 'cme',\n",
       " 'cmo',\n",
       " 'cmok',\n",
       " 'cna',\n",
       " 'cne',\n",
       " 'cnem',\n",
       " 'cneš',\n",
       " 'cni',\n",
       " 'cnih',\n",
       " 'cnil',\n",
       " 'cnim',\n",
       " 'cnit',\n",
       " 'cnje',\n",
       " 'cnjen',\n",
       " 'cno',\n",
       " 'co',\n",
       " 'coj',\n",
       " 'con',\n",
       " 'cr',\n",
       " 'cu',\n",
       " 'cuj',\n",
       " 'cul',\n",
       " 'cunj',\n",
       " 'cur',\n",
       " 'cva',\n",
       " 'cve',\n",
       " 'cvet',\n",
       " 'cvi',\n",
       " 'cvr',\n",
       " 'cvre',\n",
       " 'cvrem',\n",
       " 'cvret',\n",
       " 'cvreš',\n",
       " 'cvri',\n",
       " 'cvrl',\n",
       " 'cvroč',\n",
       " 'cvrt',\n",
       " 'da',\n",
       " 'dah',\n",
       " 'daj',\n",
       " 'dak',\n",
       " 'dal',\n",
       " 'dalj',\n",
       " 'dalk',\n",
       " 'dam',\n",
       " 'dan',\n",
       " 'danj',\n",
       " 'dank',\n",
       " 'dar',\n",
       " 'dard',\n",
       " 'dast',\n",
       " 'dat',\n",
       " 'dav',\n",
       " 'daš',\n",
       " 'de',\n",
       " 'dec',\n",
       " 'ded',\n",
       " 'deh',\n",
       " 'dej',\n",
       " 'dek',\n",
       " 'deks',\n",
       " 'del',\n",
       " 'delj',\n",
       " 'dem',\n",
       " 'den',\n",
       " 'denc',\n",
       " 'denj',\n",
       " 'dent',\n",
       " 'dentk',\n",
       " 'der',\n",
       " 'des',\n",
       " 'desk',\n",
       " 'det',\n",
       " 'dev',\n",
       " 'dez',\n",
       " 'deč',\n",
       " 'deš',\n",
       " 'dež',\n",
       " 'di',\n",
       " 'dic',\n",
       " 'dig',\n",
       " 'dih',\n",
       " 'dij',\n",
       " 'dik',\n",
       " 'dil',\n",
       " 'dim',\n",
       " 'din',\n",
       " 'dinj',\n",
       " 'dink',\n",
       " 'dir',\n",
       " 'dirk',\n",
       " 'disk',\n",
       " 'dist',\n",
       " 'dit',\n",
       " 'div',\n",
       " 'dič',\n",
       " 'diš',\n",
       " 'dišč',\n",
       " 'diž',\n",
       " 'dja',\n",
       " 'djah',\n",
       " 'djam',\n",
       " 'djar',\n",
       " 'dje',\n",
       " 'djem',\n",
       " 'djev',\n",
       " 'djez',\n",
       " 'dji',\n",
       " 'djih',\n",
       " 'djim',\n",
       " 'djo',\n",
       " 'dju',\n",
       " 'dla',\n",
       " 'dlag',\n",
       " 'dlak',\n",
       " 'dlan',\n",
       " 'dle',\n",
       " 'dlem',\n",
       " 'dlet',\n",
       " 'dleč',\n",
       " 'dlež',\n",
       " 'dli',\n",
       " 'dlih',\n",
       " 'dlim',\n",
       " 'dlin',\n",
       " 'dlja',\n",
       " 'dljah',\n",
       " 'dljaj',\n",
       " 'dljam',\n",
       " 'dlje',\n",
       " 'dljem',\n",
       " 'dljev',\n",
       " 'dlji',\n",
       " 'dljih',\n",
       " 'dljiv',\n",
       " 'dljivk',\n",
       " 'dljo',\n",
       " 'dlju',\n",
       " 'dlo',\n",
       " 'dlog',\n",
       " 'dlok',\n",
       " 'dlom',\n",
       " 'dloč',\n",
       " 'dločb',\n",
       " 'dlu',\n",
       " 'dma',\n",
       " 'dme',\n",
       " 'dmem',\n",
       " 'dmer',\n",
       " 'dmet',\n",
       " 'dmev',\n",
       " 'dmi',\n",
       " 'dmih',\n",
       " 'dmik',\n",
       " 'dmim',\n",
       " 'dmin',\n",
       " 'dmo',\n",
       " 'dmor',\n",
       " 'dmr',\n",
       " 'dmre',\n",
       " 'dmrem',\n",
       " 'dmret',\n",
       " 'dmreš',\n",
       " 'dmri',\n",
       " 'dmrl',\n",
       " 'dmrt',\n",
       " 'dna',\n",
       " 'dne',\n",
       " 'dneh',\n",
       " 'dnej',\n",
       " 'dnem',\n",
       " 'dnest',\n",
       " 'dneš',\n",
       " 'dnež',\n",
       " 'dni',\n",
       " 'dnic',\n",
       " 'dnih',\n",
       " 'dnik',\n",
       " 'dnil',\n",
       " 'dnim',\n",
       " 'dnin',\n",
       " 'dnit',\n",
       " 'dnja',\n",
       " 'dnjah',\n",
       " 'dnjak',\n",
       " 'dnjam',\n",
       " 'dnjav',\n",
       " 'dnje',\n",
       " 'dnjem',\n",
       " 'dnjev',\n",
       " 'dnji',\n",
       " 'dnjic',\n",
       " 'dnjih',\n",
       " 'dnjik',\n",
       " 'dnjim',\n",
       " 'dnjič',\n",
       " 'dnjo',\n",
       " 'dnju',\n",
       " 'dno',\n",
       " 'dnom',\n",
       " 'dnos',\n",
       " 'dnost',\n",
       " 'dnot',\n",
       " 'dnov',\n",
       " 'dnu',\n",
       " 'do',\n",
       " 'dob',\n",
       " 'dod',\n",
       " 'doj',\n",
       " 'dojk',\n",
       " 'dol',\n",
       " 'dolbst',\n",
       " 'dolg',\n",
       " 'dom',\n",
       " 'don',\n",
       " 'dont',\n",
       " 'dor',\n",
       " 'dost',\n",
       " 'dot',\n",
       " 'dov',\n",
       " 'doz',\n",
       " 'doč',\n",
       " 'dr',\n",
       " 'dra',\n",
       " 'drag',\n",
       " 'drah',\n",
       " 'draj',\n",
       " 'dral',\n",
       " 'dram',\n",
       " 'dran',\n",
       " 'dranj',\n",
       " 'dras',\n",
       " 'drast',\n",
       " 'drat',\n",
       " 'drav',\n",
       " 'draz',\n",
       " 'draš',\n",
       " 'dre',\n",
       " 'dred',\n",
       " 'dredb',\n",
       " 'dreg',\n",
       " 'drej',\n",
       " 'drek',\n",
       " 'drel',\n",
       " 'drem',\n",
       " 'dren',\n",
       " 'dres',\n",
       " 'dret',\n",
       " 'dreč',\n",
       " 'dreš',\n",
       " 'drg',\n",
       " 'dri',\n",
       " 'dric',\n",
       " 'drid',\n",
       " 'drih',\n",
       " 'drij',\n",
       " 'dril',\n",
       " 'drim',\n",
       " 'drin',\n",
       " 'drisk',\n",
       " 'drit',\n",
       " 'driv',\n",
       " 'driš',\n",
       " 'drišč',\n",
       " 'drl',\n",
       " 'dro',\n",
       " 'drob',\n",
       " 'drog',\n",
       " 'drom',\n",
       " 'drost',\n",
       " 'drov',\n",
       " 'droz',\n",
       " 'drozg',\n",
       " 'drt',\n",
       " 'dru',\n",
       " 'drug',\n",
       " 'druj',\n",
       " 'druž',\n",
       " 'družb',\n",
       " 'drv',\n",
       " 'drž',\n",
       " 'dska',\n",
       " 'dske',\n",
       " 'dskem',\n",
       " 'dski',\n",
       " 'dskih',\n",
       " 'dskim',\n",
       " 'dsko',\n",
       " 'du',\n",
       " 'dud',\n",
       " 'duh',\n",
       " 'duj',\n",
       " 'duk',\n",
       " 'dukt',\n",
       " 'dum',\n",
       " 'dur',\n",
       " 'dut',\n",
       " 'duš',\n",
       " 'dva',\n",
       " 'dvaj',\n",
       " 'dve',\n",
       " 'dveh',\n",
       " 'dvest',\n",
       " 'dveč',\n",
       " 'dvi',\n",
       " 'dvic',\n",
       " 'dvig',\n",
       " 'dvij',\n",
       " 'dvil',\n",
       " 'dvit',\n",
       " 'dvič',\n",
       " 'dvla',\n",
       " 'dvlad',\n",
       " 'dvle',\n",
       " 'dvleč',\n",
       " 'dvo',\n",
       " 'dvoj',\n",
       " 'dvom',\n",
       " 'dvor',\n",
       " 'dvoz',\n",
       " 'dvr',\n",
       " 'dvra',\n",
       " 'dvre',\n",
       " 'dvreč',\n",
       " 'dvrst',\n",
       " 'dža',\n",
       " 'džun',\n",
       " 'e',\n",
       " 'ef',\n",
       " 'el',\n",
       " 'em',\n",
       " 'en',\n",
       " 'ent',\n",
       " 'entk',\n",
       " 'er',\n",
       " 'et',\n",
       " 'ev',\n",
       " 'fa',\n",
       " 'fag',\n",
       " 'fah',\n",
       " 'faj',\n",
       " 'fal',\n",
       " 'fam',\n",
       " 'fan',\n",
       " 'fanj',\n",
       " 'fant',\n",
       " 'far',\n",
       " 'farkt',\n",
       " 'farm',\n",
       " 'fat',\n",
       " 'faz',\n",
       " 'faš',\n",
       " 'fe',\n",
       " 'fekt',\n",
       " 'fen',\n",
       " 'fer',\n",
       " 'fev',\n",
       " 'fi',\n",
       " 'fih',\n",
       " 'fij',\n",
       " 'fil',\n",
       " 'film',\n",
       " 'fin',\n",
       " 'firm',\n",
       " 'fit',\n",
       " 'fje',\n",
       " 'flav',\n",
       " 'flavt',\n",
       " 'fle',\n",
       " 'fleks',\n",
       " 'fli',\n",
       " 'flikt',\n",
       " 'flo',\n",
       " 'flot',\n",
       " 'fne',\n",
       " 'fnem',\n",
       " 'fneš',\n",
       " 'fni',\n",
       " 'fnil',\n",
       " 'fnit',\n",
       " 'fo',\n",
       " 'fol',\n",
       " 'fom',\n",
       " 'fon',\n",
       " 'fond',\n",
       " 'for',\n",
       " 'form',\n",
       " 'fov',\n",
       " 'fr',\n",
       " 'fra',\n",
       " 'frah',\n",
       " 'fraj',\n",
       " 'frak',\n",
       " 'fral',\n",
       " 'fram',\n",
       " 'fran',\n",
       " 'frank',\n",
       " 'frat',\n",
       " 'fraz',\n",
       " 'frač',\n",
       " 'fraš',\n",
       " 'fre',\n",
       " 'fresk',\n",
       " 'fri',\n",
       " 'fro',\n",
       " 'fron',\n",
       " 'front',\n",
       " 'fska',\n",
       " 'fske',\n",
       " 'fskem',\n",
       " 'fski',\n",
       " 'fskih',\n",
       " 'fskim',\n",
       " 'fsko',\n",
       " 'fta',\n",
       " 'ftar',\n",
       " 'fte',\n",
       " 'fti',\n",
       " 'fto',\n",
       " 'fu',\n",
       " 'fug',\n",
       " 'fum',\n",
       " 'fun',\n",
       " 'funt',\n",
       " 'fut',\n",
       " 'ga',\n",
       " 'ga_',\n",
       " 'gad',\n",
       " 'gah',\n",
       " 'gaj',\n",
       " 'gajn',\n",
       " 'gal',\n",
       " 'galk',\n",
       " 'gam',\n",
       " 'gan',\n",
       " 'gand',\n",
       " 'ganj',\n",
       " 'gank',\n",
       " 'gar',\n",
       " 'gar_',\n",
       " 'garn',\n",
       " 'gast',\n",
       " 'gat',\n",
       " 'gav',\n",
       " 'gač',\n",
       " 'gaš',\n",
       " 'ge',\n",
       " 'geh',\n",
       " 'gej',\n",
       " 'gel',\n",
       " 'gelc',\n",
       " 'gelj',\n",
       " 'gem',\n",
       " 'gen',\n",
       " 'genc',\n",
       " 'gend',\n",
       " 'genj',\n",
       " 'gent',\n",
       " 'gentk',\n",
       " 'ger',\n",
       " 'gest',\n",
       " 'get',\n",
       " 'geš',\n",
       " 'gi',\n",
       " 'gib',\n",
       " 'gic',\n",
       " 'gih',\n",
       " 'gij',\n",
       " 'gik',\n",
       " 'gim',\n",
       " 'gin',\n",
       " 'ginj',\n",
       " 'gič',\n",
       " 'gišč',\n",
       " 'gje',\n",
       " 'gla',\n",
       " 'glad',\n",
       " 'glah',\n",
       " 'glam',\n",
       " 'glar',\n",
       " 'glas',\n",
       " 'glasb',\n",
       " 'glast',\n",
       " 'glat',\n",
       " 'glav',\n",
       " 'gle',\n",
       " 'gled',\n",
       " 'glej',\n",
       " 'glem',\n",
       " 'glen',\n",
       " 'gler',\n",
       " 'gleč',\n",
       " 'gli',\n",
       " 'glic',\n",
       " 'glih',\n",
       " 'glil',\n",
       " 'glim',\n",
       " 'glit',\n",
       " 'gliš',\n",
       " 'glja',\n",
       " 'gljaj',\n",
       " 'gljal',\n",
       " 'gljam',\n",
       " 'gljanj',\n",
       " 'gljat',\n",
       " 'gljaš',\n",
       " 'glje',\n",
       " 'gljem',\n",
       " 'gljen',\n",
       " 'gljev',\n",
       " 'glji',\n",
       " 'gljih',\n",
       " 'gljiv',\n",
       " 'glju',\n",
       " 'glo',\n",
       " 'glom',\n",
       " 'glost',\n",
       " 'glov',\n",
       " 'glu',\n",
       " 'gluh',\n",
       " 'gma',\n",
       " 'gmajn',\n",
       " 'gmen',\n",
       " 'gment',\n",
       " 'gmi',\n",
       " 'gmo',\n",
       " 'gmot',\n",
       " 'gna',\n",
       " 'gnal',\n",
       " 'gnan',\n",
       " 'gnanj',\n",
       " 'gnat',\n",
       " 'gne',\n",
       " 'gnem',\n",
       " 'gnest',\n",
       " 'gnet',\n",
       " 'gnev',\n",
       " 'gnez',\n",
       " 'gnezd',\n",
       " 'gneč',\n",
       " 'gneš',\n",
       " 'gni',\n",
       " 'gnih',\n",
       " 'gnij',\n",
       " 'gnil',\n",
       " 'gnin',\n",
       " 'gnit',\n",
       " 'gnja',\n",
       " 'gnjat',\n",
       " 'gnje',\n",
       " 'gnjem',\n",
       " 'gnjen',\n",
       " 'gnjenj',\n",
       " 'gnjev',\n",
       " 'gnji',\n",
       " 'gnjih',\n",
       " 'gnjišč',\n",
       " 'gnju',\n",
       " 'gno',\n",
       " 'gnoj',\n",
       " 'gnom',\n",
       " 'gnov',\n",
       " 'gnoz',\n",
       " 'gnu',\n",
       " 'gnus',\n",
       " 'go',\n",
       " 'gob',\n",
       " 'god',\n",
       " 'godb',\n",
       " 'goj',\n",
       " 'gol',\n",
       " 'golt',\n",
       " 'gom',\n",
       " 'gon',\n",
       " 'gonj',\n",
       " 'gor',\n",
       " 'gos',\n",
       " 'gost',\n",
       " 'got',\n",
       " 'gov',\n",
       " 'govk',\n",
       " 'goz',\n",
       " 'gozd',\n",
       " 'goč',\n",
       " 'gr',\n",
       " 'gra',\n",
       " 'grad',\n",
       " 'graf',\n",
       " 'grah',\n",
       " 'graj',\n",
       " 'gral',\n",
       " 'gralk',\n",
       " 'gram',\n",
       " 'gran',\n",
       " 'granj',\n",
       " 'grat',\n",
       " 'grač',\n",
       " 'gračk',\n",
       " 'graš',\n",
       " 'grb',\n",
       " 'grd',\n",
       " 'gre',\n",
       " 'greb',\n",
       " 'grebst',\n",
       " 'gred',\n",
       " 'greh',\n",
       " 'grej',\n",
       " 'grel',\n",
       " 'grem',\n",
       " 'gren',\n",
       " 'gres',\n",
       " 'gret',\n",
       " 'greš',\n",
       " 'gri',\n",
       " 'gric',\n",
       " 'grih',\n",
       " 'grist',\n",
       " 'griv',\n",
       " 'griz',\n",
       " 'grič',\n",
       " 'grišč',\n",
       " 'grl',\n",
       " 'grm',\n",
       " 'gro',\n",
       " 'grob',\n",
       " 'grof',\n",
       " 'grom',\n",
       " 'grov',\n",
       " 'groz',\n",
       " 'grozd',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllables_dictionary = sorted(syllables_dictionary)\n",
    "syllables_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run ../../../prepare_data.py\n",
    "# generate_X_and_y(dictionary, max_word, max_num_vowels, content, vowels, accetuated_vowels, feature_dictionary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
