{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import unicode_literals\n",
    "# text in Western (Windows 1252)\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "# import StringIO\n",
    "import math\n",
    "from keras import optimizers, metrics\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import regularizers\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import load_model\n",
    "# from keras import backend as Input\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %run ../../../prepare_data.py\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../../')\n",
    "from prepare_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING CONTENT...\n",
      "CONTENT READ SUCCESSFULLY\n",
      "CREATING DICTIONARY...\n",
      "DICTIONARY CREATION SUCCESSFUL!\n",
      "GENERATING X AND y...\n",
      "CREATING OTHER FEATURES...\n",
      "OTHER FEATURES CREATED!\n",
      "SHUFFELING INPUTS...\n",
      "INPUTS SHUFFELED!\n",
      "CREATING OTHER FEATURES...\n",
      "OTHER FEATURES CREATED!\n",
      "SHUFFELING INPUTS...\n",
      "INPUTS SHUFFELED!\n",
      "CREATING OTHER FEATURES...\n",
      "OTHER FEATURES CREATED!\n",
      "SHUFFELING INPUTS...\n",
      "INPUTS SHUFFELED!\n",
      "GENERATION SUCCESSFUL!\n"
     ]
    }
   ],
   "source": [
    "# %run ../../../prepare_data.py\n",
    "# X_train, X_other_features_train, y_train, X_test, X_other_features_test, y_test, X_validate, X_other_features_validate, y_validate = generate_full_matrix_inputs('../../internal_representations/inputs/content_shuffle_vector.h5', '../../internal_representations/inputs/shuffle_vector')\n",
    "# save_inputs('../../internal_representations/inputs/shuffled_letters_train.h5', X_train, y_train, other_features = X_other_features_train)\n",
    "# save_inputs('../../internal_representations/inputs/shuffled_letters_test.h5', X_test, y_test, other_features = X_other_features_test)\n",
    "# save_inputs('../../internal_representations/inputs/shuffled_letters_validate.h5', X_validate, y_validate,  other_features = X_other_features_validate)\n",
    "# X_train, X_other_features_train, y_train = load_inputs('../../internal_representations/inputs/shuffled_letters_train.h5', other_features=True)\n",
    "# X_test, X_other_features_test, y_test = load_inputs('../../internal_representations/inputs/shuffled_letters_test.h5', other_features=True)\n",
    "# X_validate, X_other_features_validate, y_validate = load_inputs('../../internal_representations/inputs/shuffled_letters_validate.h5', other_features=True)\n",
    "\n",
    "data = Data('l')\n",
    "data.generate_data('letters_word_accetuation_train',\n",
    "                   'letters_word_accetuation_test',\n",
    "                   'letters_word_accetuation_validate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen2 = data.generator('train', 16)\n",
    "# test1 = next(gen1)\n",
    "test2 = next(gen2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "(16, 23, 36)\n",
      "(16, 140)\n"
     ]
    }
   ],
   "source": [
    "pos = 0\n",
    "print(len(feature_dictionary))\n",
    "print(np.array(test2[0][0]).shape)\n",
    "print(np.array(test2[0][1]).shape)\n",
    "# for el in test2[0][0]:\n",
    "# #     print(el)\n",
    "#     print (data.decode_x(el, dictionary))\n",
    "#     print(data.decode_x_other_features(feature_dictionary, [el]))\n",
    "\n",
    "# for el in test2[1]:\n",
    "#     print(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(430151, 23, 36)\n",
      "(52058, 23, 36)\n",
      "(54222, 23, 36)\n",
      "amejnavejob\n",
      "Ncndi-\n",
      "Ncndi-\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "# print (X_train.shape)\n",
    "# print (X_test.shape)\n",
    "# print (X_validate.shape)\n",
    "pos = 7\n",
    "# print (decode_input(X_train[pos], dictionary))\n",
    "# print (decode_X_features(feature_dictionary, [X_other_features_train[pos]]))\n",
    "# print(decode_position(y_train[pos]))\n",
    "# print('------------------------------------')\n",
    "print (data.x_train.shape)\n",
    "print (data.x_test.shape)\n",
    "print (data.x_validate.shape)\n",
    "# pos = 2\n",
    "print (data.decode_x(data.x_train[pos], dictionary))\n",
    "print (data.decode_x_other_features(feature_dictionary, [data.x_other_features_train[pos]]))\n",
    "print(data.decode_y(data.y_train[pos]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-14b2a34f2fb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnum_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# training set size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnn_output_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnn_hdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m516\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mactual_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "num_examples = len(data.x_train) # training set size\n",
    "nn_output_dim = 10\n",
    "nn_hdim = 516\n",
    "batch_size = 16\n",
    "actual_epoch = 40\n",
    "num_fake_epoch = 20\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "conv_input_shape=(23, 36)\n",
    "othr_input = (140, )\n",
    "\n",
    "conv_input = Input(shape=conv_input_shape, name='conv_input')\n",
    "x_conv = Conv1D(115, (3), padding='same', activation='relu')(conv_input)\n",
    "x_conv = Conv1D(46, (3), padding='same', activation='relu')(x_conv)\n",
    "x_conv = MaxPooling1D(pool_size=2)(x_conv)\n",
    "x_conv = Flatten()(x_conv)\n",
    "# x_conv = Dense(516, activation='relu', kernel_constraint=maxnorm(3))(x_conv)\n",
    "\n",
    "othr_input = Input(shape=othr_input, name='othr_input')\n",
    "# x_othr = Dense(256, input_dim=167, activation='relu')(othr_input)\n",
    "# x_othr = Dropout(0.3)(x_othr)\n",
    "# x_othr = Dense(512, activation='relu')(othr_input)\n",
    "# x_othr = Dropout(0.3)(x_othr)\n",
    "# x_othr = Dense(256, activation='relu')(othr_input)\n",
    "\n",
    "x = concatenate([x_conv, othr_input])\n",
    "# x = Dense(1024, input_dim=(516 + 256), activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(nn_output_dim, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=[conv_input, othr_input], outputs=x)\n",
    "opt = optimizers.Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[actual_accuracy,])\n",
    "# model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b580509f414e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit_generator(data.generator('train', batch_size), \n\u001b[0m\u001b[1;32m      2\u001b[0m                               \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_fake_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactual_epoch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_fake_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                               validation_steps=data.x_test.shape[0]/(batch_size * num_fake_epoch))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(data.generator('train', batch_size), \n",
    "                              data.x_train.shape[0]/(batch_size * num_fake_epoch), \n",
    "                              epochs=actual_epoch*num_fake_epoch, \n",
    "                              validation_data=data.generator('test', batch_size), \n",
    "                              validation_steps=data.x_test.shape[0]/(batch_size * num_fake_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = '60_epoch'\n",
    "model.save(name + '.h5')\n",
    "output = open(name + '_history.pkl', 'wb')\n",
    "pickle.dump(history.history, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content = data._read_content('../../../data/SlovarIJS_BESEDE_utf8.lex')\n",
    "dictionary, max_word, max_num_vowels, vowels, accented_vowels = data._create_dict(content)\n",
    "feature_dictionary = data._create_feature_dictionary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
