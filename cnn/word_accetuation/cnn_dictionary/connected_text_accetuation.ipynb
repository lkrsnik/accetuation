{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import sys\n",
    "sys.path.insert(0, '../../../')\n",
    "from prepare_data import *\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Flatten\n",
    "from keras.models import load_model\n",
    "# from keras import backend as Input\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ LOCATION ########################\n",
    "letter_location_model = load_model('../cnn_dictionary/v3_10/20_test_epoch.h5', custom_objects={'actual_accuracy': actual_accuracy})\n",
    "\n",
    "# num_examples = len(data.x_train)  # training set size\n",
    "nn_output_dim = 10\n",
    "nn_hdim = 516\n",
    "batch_size = 16\n",
    "actual_epoch = 20\n",
    "num_fake_epoch = 20\n",
    "\n",
    "conv_input_shape=(10, 5168)\n",
    "othr_input = (140, )\n",
    "conv_input = Input(shape=conv_input_shape, name='conv_input')\n",
    "\n",
    "# syllabled letters\n",
    "x_conv = Conv1D(200, (2), padding='same', activation='relu')(conv_input)\n",
    "x_conv = MaxPooling1D(pool_size=2)(x_conv)\n",
    "x_conv = Flatten()(x_conv)\n",
    "\n",
    "othr_input = Input(shape=othr_input, name='othr_input')\n",
    "\n",
    "x = concatenate([x_conv, othr_input])\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(nn_output_dim, activation='sigmoid')(x)\n",
    "\n",
    "syllable_location_model = Model(inputs=[conv_input, othr_input], outputs=x)\n",
    "opt = optimizers.Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "syllable_location_model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[actual_accuracy,])\n",
    "syllable_location_model.load_weights('../syllables/v2_4/20_epoch.h5')\n",
    "\n",
    "\n",
    "conv_input_shape=(10, 252)\n",
    "othr_input = (140, )\n",
    "\n",
    "conv_input = Input(shape=conv_input_shape, name='conv_input')\n",
    "\n",
    "# syllabled letters\n",
    "x_conv = Conv1D(200, (2), padding='same', activation='relu')(conv_input)\n",
    "x_conv = MaxPooling1D(pool_size=2)(x_conv)\n",
    "x_conv = Flatten()(x_conv)\n",
    "\n",
    "othr_input = Input(shape=othr_input, name='othr_input')\n",
    "\n",
    "x = concatenate([x_conv, othr_input])\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(nn_output_dim, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "syllabled_letters_location_model = Model(inputs=[conv_input, othr_input], outputs=x)\n",
    "opt = optimizers.Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "syllabled_letters_location_model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[actual_accuracy,])\n",
    "syllabled_letters_location_model.load_weights('../syllabled_letters/v2_5_3/20_test_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ TYPE ########################\n",
    "nn_output_dim = 13\n",
    "nn_hdim = 516\n",
    "batch_size = 16\n",
    "actual_epoch = 20\n",
    "num_fake_epoch = 20\n",
    "\n",
    "# letters\n",
    "conv_input_shape=(23, 36)\n",
    "othr_input = (150, )\n",
    "conv_input = Input(shape=conv_input_shape, name='conv_input')\n",
    "# letters\n",
    "x_conv = Conv1D(115, (3), padding='same', activation='relu')(conv_input)\n",
    "x_conv = Conv1D(46, (3), padding='same', activation='relu')(x_conv)\n",
    "\n",
    "# syllabled letters\n",
    "x_conv = MaxPooling1D(pool_size=2)(x_conv)\n",
    "x_conv = Flatten()(x_conv)\n",
    "\n",
    "othr_input = Input(shape=othr_input, name='othr_input')\n",
    "x = concatenate([x_conv, othr_input])\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(nn_output_dim, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "letter_type_model = Model(inputs=[conv_input, othr_input], outputs=x)\n",
    "opt = optimizers.Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "letter_type_model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[actual_accuracy,])\n",
    "letter_type_model.load_weights('../../accent_classification/letters/v2_1/20_test_epoch.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generates text with every word in new line\n",
    "with open('../../../../reldi-tagger/test_original') as f:\n",
    "    original_text = f.readlines()\n",
    "original_text = ''.join(original_text)\n",
    "# print(original_text)\n",
    "text_with_whitespaces = original_text.replace(',', ' ,').replace('.', ' .').replace('\\n', ' ').replace(\"\\\"\", \" \\\" \").replace(\":\", \" :\").replace(\"ć\", \"č\").replace('–', '-')\n",
    "# print('-------------------------------------------------')\n",
    "text_with_whitespaces = '\\n'.join(text_with_whitespaces.split())\n",
    "text_with_whitespaces += '\\n\\n'\n",
    "# print(text_with_whitespaces)\n",
    "with open('../../../../reldi-tagger/test_with_whitespaces', \"w\") as text_file:\n",
    "    text_file.write(text_with_whitespaces)\n",
    "    \n",
    "# generates text with PoS tags\n",
    "import subprocess\n",
    "\n",
    "myinput = open('../../../../reldi-tagger/test_with_whitespaces', 'r')\n",
    "myoutput = open('../../../../reldi-tagger/test_result', 'w')\n",
    "# print(myinput.readlines())\n",
    "python3_command = \"../../../../reldi-tagger/tagger.py sl\"  # launch your python2 script using bash\n",
    "\n",
    "process = subprocess.run(python3_command.split(), stdin=myinput, stdout=myoutput)\n",
    "\n",
    "# generates interesting words\n",
    "pointless_words = ['.',',','\\\"',':', '-']\n",
    "with open('../../../../reldi-tagger/test_result', \"r\") as text_file:\n",
    "    tagged_input_words = []\n",
    "    for x in text_file.readlines()[:-1]:\n",
    "        splited_line = x[:-1].split('\\t')\n",
    "        if splited_line[0] not in pointless_words and not any(char.isdigit() for char in splited_line[0]):\n",
    "            tagged_input_words.append([splited_line[0].lower(), '', splited_line[1], splited_line[0].lower()])\n",
    "#     tagged_input_words = [x[:-1].split('\\t') for x in text_file.readlines() if x[:-1].split('\\t')[0] not in pointless_words][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data('l', shuffle_all_inputs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = data._read_content('../../../data/SlovarIJS_BESEDE_utf8.lex')\n",
    "dictionary, max_word, max_num_vowels, vowels, accented_vowels = data._create_dict(content)\n",
    "feature_dictionary = data._create_feature_dictionary()\n",
    "syllable_dictionary = data._create_syllables_dictionary(content, vowels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zaliva', '', 'Ncmsg', 'zaliva']\n",
      "[1]\n",
      "[  6.30854402e-06   9.99771297e-01   5.57102567e-06   9.06875703e-12\n",
      "   1.12715172e-15   3.22355225e-20   2.57569017e-26   1.88833358e-21\n",
      "   1.21982240e-26   0.00000000e+00]\n",
      "Urádni podátki polícije kažejó na précej napéte razmére v Piránskem zalívu, jé dánes poročála oddája 24UR. Do dánes se jé zgodílo žé 36 incídentov, v katérih só hrváška plovíla 52 krát zaplúla v vodé, ki veljájo kot obmóčje Slovenskéga nadzóra, toréj prekó črté, ki oznáčuje trí četŕtine Piranskéga zalíva.\n",
      "\n",
      "Slovénska polícija sícer zagótavlja, da né povzróča incídentov in oprávlja nalóge enáko kot préd arbitrážno razsódbo. Hrváška strán pa na vprašánje, zákaj vztrajnó plujé do sredíne zalíva, né odgóvarja.\n",
      "\n",
      "Ribíči pojasnújejo, da na obmóčju, kjér se dogajájo incídenti, lovíjo prédvsem listé, hobotníce in kalámare. Ríbič Zlatkó Novógradec jé za 24UR déjal, da si vsí skupáj želíjo čimpréjšnjo impleméntacijo razsódbe: \"Zdáj smó kot sardíne v konzérvi in s tistím koščkóm morjá bomó mogóče lé maló zadiháli in zagótovo se bó kaká ribá véč znašlá v mreží.\"\n",
      "\n",
      "Vprašánje pa jé tudí, káko bó v priméru incídentov ribíče zaščitíla našá polícija. Téh infórmacij tudí ribíči samí – nimajó.\n",
      "\n",
      "Erjávec pozíva k resní razprávi: Tó ní véč héc\n",
      "\n",
      "Zunánji miníster Kárl Erjávec jé dánes v Brusljú pózval k resní razprávi vladé tá tedén o enóstranskíh dejánjih Hrváške v Piránskem zalívu, ki só po njegóvih besédah nepósredén póseg v suvérenost Slovénije in schéngna. \"Tó pa ní véč héc,\" jé poúdaril miníster, ki pričákuje, da bó Slovénija v povézavi s tém poslála pismó Evrópski komísiji.\n",
      "\n",
      "Miníster jé óbžaloval incídente v Piránskem zalívu in ópozoril, da jé Hrváška jé vés čás želéla, da né bí biló enóstranskíh déjanj, zdáj pa samá tó póčne. \"Po izdáji arbitrážne odlóčbe jé biló 52 incídentov, ki só enóstranské naráve, ker gré za kršítve mejé, določéne na podlági arbitrážne odlóčbe,\" jé izpóstavil.\n",
      "\n",
      "Ób tém jé ópozoril na dejstvó \"izjemnéga poména\" – da jé slovénska južná mejá tudí zunánja schengénska mejá, takó da né gré véč zgólj za kršítev mejé méd Slovénijo in Hrváško, ampák tudí za kršítev schengénske mejé in pravnegá redá ÉU.\n",
      "\n",
      "Erjávec mení, da bó trebá tá tedén v okvíru vladé, s predsedníkom vladé, in tudí v okvíru koálicije opravíti resnó razprávo o tém, káj poménijo tá enóstranská ravnánja hrváške stráni. \"Takšná enóstranská dejánja só nepósredén póseg v suvérenost Slovénije in suvérenost schéngna. Tó pa ní véč héc,\" jé déjal.\n",
      "\n",
      "Véč kot dvé tretjíni Hrvátov ocenjújeta, da smó prí arbitráži Slovénci uspešnéje pojásnjevali svojá stalíšča\n",
      "\n",
      "Po razsódbi arbitrážnega sodíšča o mejí méd Slovénijo in Hrváško na morjú in kopném 56 odstótkov hrváških držávljanov mení, da jé sodbá v príd Slovéniji, jé pokázala razískava, ki jo jé v nedéljo zvéčer objavíla hrváška komércialna Nová TV. Priblížno tretjína vprašánih mení, da bó Hrváška na koncú sprejéla razsódbo.\n",
      "\n",
      "Razískava agencíje Ípsos, v katéri jé 13. in 14. julijá sodélovalo 612 anketírancev, jé šé pokázala, da 12 odstótkov vprašánih mení, da jé bilá razsódba ugodnéjša za Hrváško. Da stá óbe držávi dobíli priblížno enáko, jé océnilo pét odstótkov Hrvátov, da sodbá ní bilá ugódna né za Hrváško in né za Slovénijo, jé prepričánih ósem odstótkov Hrvátov, médtem ko jih 19 odstótkov né vé.\n",
      "\n",
      "Odlóčitev hrvaškéga sabóra íz letá 2015, da bó Hrváška izstópila íz arbitrážnega postópka in né bó sprejéla odlóčitve sodíšča, podpiráta dvé tretjíni anketírancev. Priblížno četŕtina hrváških držávljanov né podpíra stalíšča hrváške vladé, da né bodó sprejéli razsódbe, énajst odstótkov se jih ní mogló odlóčiti.\n",
      "\n",
      "Nekáj mánj kot 40 odstótkov vprašánih jé menílo, da bostá Hrváška in Slovénija doségli novó rešítev, kljúb pritískom Evrópske komísije in Nemčíje, náj Hrváška uvéljavi razsódbo. Da bó Hrváška na koncú popústila in sprejéla razsódbo, pričákuje 31 odstótkov vprašánih, da né bó popústila, pa nekáj véč kot petína.\n",
      "\n",
      "Véč kot dvé tretjíni vprašánih jé océnilo, da jé Slovénija članicám Evrópske uníje uspešnéje pojásnjevala svojá stalíšča, médtem ko jih jé 14 odstótkov menílo, da jé boljé lobirála Hrváška.\n",
      "\n",
      "Hrváški držávljani só razdéljeni prí vprašánju, kdó jé boljé lobíral za Hrváško, predsedníca držáve Kolínda Grabar-Kitarović alí prémier Ándréj Plenković. Za predsedníco jé 29 odstótkov vprašánih, za premíerja pa 26 odstótkov. Da stá óba lobirála enáko, jé menílo 16 odstótkov vprašánih, 15 odstótkov pa jé tistíh, ki só océnili, da nihčé ní lobíral. \"Né vém\" jé bíl odgóvor 14 odstótkov vprašánih.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# X, X_other_features, fake_y = generate_X_and_y(dictionary, max_word, max_num_vowels, tagged_input_words, vowels, accetuated_vowels, feature_dictionary, 'who cares', shuffle=False)\n",
    "%run ../../../prepare_data.py\n",
    "pos = 45\n",
    "print(tagged_input_words[pos])\n",
    "\n",
    "data = Data('l', shuffle_all_inputs=False)\n",
    "x, x_other_features, fake_y = data._generate_x_and_y(dictionary, max_word, max_num_vowels, tagged_input_words, vowels, accented_vowels, feature_dictionary, 'who cares')\n",
    "generator = data._letter_generator(x, x_other_features, fake_y, batch_size, accented_vowels)\n",
    "letter_location_predictions = letter_location_model.predict_generator(generator, len(x)/(batch_size))\n",
    "\n",
    "data = Data('s', shuffle_all_inputs=False)\n",
    "x, x_other_features, fake_y = data._generate_x_and_y(syllable_dictionary, max_word, max_num_vowels, tagged_input_words, vowels, accented_vowels, feature_dictionary, 'who cares')\n",
    "eye = np.eye(len(syllable_dictionary), dtype=int)\n",
    "generator = data._syllable_generator(x, x_other_features, fake_y, batch_size, eye, accented_vowels)\n",
    "syllable_location_predictions = syllable_location_model.predict_generator(generator, len(x)/(batch_size))\n",
    "\n",
    "\n",
    "data = Data('sl', shuffle_all_inputs=False)\n",
    "x, x_other_features, fake_y = data._generate_x_and_y(syllable_dictionary, max_word, max_num_vowels, tagged_input_words, vowels, accented_vowels, feature_dictionary, 'who cares')\n",
    "max_syllable = data._get_max_syllable(syllable_dictionary)\n",
    "syllable_letters_translator = data._create_syllable_letters_translator(max_syllable, syllable_dictionary, dictionary, vowels)\n",
    "generator = data._syllable_generator(x, x_other_features, fake_y, batch_size, syllable_letters_translator, accented_vowels)\n",
    "syllabled_letters_location_predictions = syllabled_letters_location_model.predict_generator(generator, len(x)/(batch_size))\n",
    "\n",
    "\n",
    "predictions = np.mean( np.array([ letter_location_predictions, syllable_location_predictions, syllabled_letters_location_predictions ]), axis=0 )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# data = Data('l', shuffle_all_inputs=False, accent_classification=True)\n",
    "# x, x_other_features, fake_y = data._generate_x_and_y(dictionary, max_word, max_num_vowels, tagged_input_words, vowels, accented_vowels, feature_dictionary, 'who cares')\n",
    "# generator = data._letter_generator(x, x_other_features, fake_y, batch_size, accented_vowels)\n",
    "# letter_type_predictions = letter_type_model.predict_generator(generator, len(x)/(batch_size))\n",
    "\n",
    "\n",
    "# letter_type_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#predictions = model.predict([X, X_other_features])\n",
    "print(data.decode_y(predictions[pos]))\n",
    "print(predictions[pos])\n",
    "\n",
    "words_and_accetuation_loc = [[tagged_input_words[i][0], data.decode_y(predictions[i])] for i in range(len(tagged_input_words))]\n",
    "\n",
    "original_text_list = list(original_text)\n",
    "original_text_lowercase = original_text.lower()\n",
    "end_pos = 0\n",
    "for word in words_and_accetuation_loc:\n",
    "    posit = original_text_lowercase.find(word[0], end_pos)\n",
    "    if posit != -1:\n",
    "        start_pos = posit\n",
    "        end_pos = start_pos + len(word[0])\n",
    "    \n",
    "    original_text_list[start_pos:end_pos] = list(accetuate_word(''.join(original_text_list[start_pos:end_pos]), word[1]))\n",
    "\n",
    "    \n",
    "    #print(start_pos)\n",
    "#    if 4005 < start_pos < 4028:\n",
    "#        print(word[0])\n",
    "#        print(original_text_list[start_pos:end_pos])\n",
    "#        print(start_pos)\n",
    "    \n",
    "#    if word[0] == \"zalivu\":\n",
    "#        print(\"TEST\")\n",
    "#        print(start_pos)\n",
    "#        print(end_pos)\n",
    "#        print(original_text_list[start_pos:end_pos])\n",
    "#        print(''.join(original_text_list))\n",
    "    \n",
    "print(''.join(original_text_list))\n",
    "#print(original_text_list[4006:4027])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51840/52058 [============================>.] - ETA: 0s\n",
      "actual_accuracy: 86.97%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate([X_test, X_other_features_test], y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.97414422375043\n"
     ]
    }
   ],
   "source": [
    "def test_accuracy(predictions, y):\n",
    "#     dictionary, max_word, max_num_vowels, content, vowels, accetuated_vowels = create_dict()\n",
    "    num_of_pred = len(predictions)\n",
    "    num_of_correct_pred = 0\n",
    "    for i in range(predictions.shape[0]):\n",
    "        if decode_position(predictions[i]) == decode_position(y[i]):\n",
    "            num_of_correct_pred += 1\n",
    "\n",
    "    return (num_of_correct_pred/float(num_of_pred)) * 100\n",
    "\n",
    "predictions = model.predict([X_test, X_other_features_test])\n",
    "print(test_accuracy(predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incorrects = np.nonzero(predictions != y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.00000000e+00   1.00000000e+00   6.09418273e-23   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "6781\n",
      "['spregovórjena', array([  0.00000000e+00,   4.67960648e-09,   3.46557694e-09,\n",
      "         9.99999046e-01,   7.49402659e-07,   4.68860552e-23,\n",
      "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
      "         0.00000000e+00,   0.00000000e+00], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "test = np.equal(predictions,y_test)\n",
    "print(predictions[0])\n",
    "print(y_test[0])\n",
    "results = [[accetuate_word(decode_input(X_test[i], dictionary), decode_position(predictions[i])), predictions[i]] for i in range(len(predictions)) if decode_position(predictions[i]) != decode_position(y_test[i])]\n",
    "print(len(results))\n",
    "print(results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING CONTENT...\n",
      "CONTENT READ SUCCESSFULY\n",
      "CREATING DICTIONARY...\n",
      "DICTIONARY CREATION SUCCESSFUL!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dictionary, max_word, max_num_vowels, content, vowels, accetuated_vowels = create_dict()\n",
    "feature_dictionary = create_feature_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['à', 'á', 'ä', 'é', 'ë', 'ì', 'í', 'î', 'ó', 'ô', 'ö', 'ú', 'ü', 'a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'policijé'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'A' not in vowels:\n",
    "    vowels.extend(['A', 'E', 'I', 'O', 'U'])\n",
    "print(vowels)\n",
    "def accetuate_word(word, locations):\n",
    "#     word = list(word)\n",
    "    word_list = list(word)\n",
    "    for loc in locations:\n",
    "        vowel_num = 0\n",
    "        #if loc == 0:\n",
    "        #    return word\n",
    "        for i in range(len(word_list)):\n",
    "            if data._is_vowel(word_list, i, vowels):\n",
    "                if word_list[i] == 'a' and vowel_num == loc:\n",
    "                    word_list[i] = 'á'\n",
    "                elif word_list[i] == 'e' and vowel_num == loc:\n",
    "                    word_list[i] = 'é'\n",
    "                elif word_list[i] == 'i' and vowel_num == loc:\n",
    "                    word_list[i] = 'í'\n",
    "                elif word_list[i] == 'o' and vowel_num == loc:\n",
    "                    word_list[i] = 'ó'\n",
    "                elif word_list[i] == 'u' and vowel_num == loc:\n",
    "                    word_list[i] = 'ú'\n",
    "                elif word_list[i] == 'r' and vowel_num == loc:\n",
    "                    word_list[i] = 'ŕ'\n",
    "                elif word_list[i] == 'A' and vowel_num == loc:\n",
    "                    word_list[i] = 'Á'\n",
    "                elif word_list[i] == 'E' and vowel_num == loc:\n",
    "                    word_list[i] = 'É'\n",
    "                elif word_list[i] == 'I' and vowel_num == loc:\n",
    "                    word_list[i] = 'Í'\n",
    "                elif word_list[i] == 'O' and vowel_num == loc:\n",
    "                    word_list[i] = 'Ó'\n",
    "                elif word_list[i] == 'U' and vowel_num == loc:\n",
    "                    word_list[i] = 'Ú'\n",
    "                elif word_list[i] == 'R' and vowel_num == loc:\n",
    "                    word_list[i] = 'Ŕ'\n",
    "                vowel_num += 1\n",
    "#     print(word_list)\n",
    "    return ''.join(word_list)\n",
    "    \n",
    "accetuate_word('policije', [3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING OTHER FEATURES...\n",
      "OTHER FEATURES CREATED!\n",
      "['je', '', 'Va-r3s-n', 'je']\n",
      "[0, 1]\n",
      "[  7.99477637e-01   6.77873671e-01   9.83008295e-02   6.05765490e-05\n",
      "   6.33550807e-12   2.99607361e-09   1.19315509e-08   1.73794911e-06\n",
      "   8.25467694e-09   8.27788467e-13   4.58576916e-13]\n"
     ]
    }
   ],
   "source": [
    "%run ../../../prepare_data.py\n",
    "X, X_other_features, fake_y = generate_X_and_y(dictionary, max_word, max_num_vowels, tagged_input_words, vowels, accetuated_vowels, feature_dictionary, 'who cares', shuffle=False)\n",
    "\n",
    "pos = 18\n",
    "print(tagged_input_words[pos])\n",
    "predictions = model.predict([X, X_other_features])\n",
    "print(decode_position(predictions[pos]))\n",
    "print(predictions[pos])\n",
    "\n",
    "\n",
    "\n",
    "words_and_accetuation_loc = [[tagged_input_words[i][0], decode_position(predictions[i])] for i in range(len(tagged_input_words))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urádni podátki policíje kážejo ná precéj napéte razmére v Piránskem zalívu, je danés poróčala oddája 24UR. Dó danés se je zgodílo žé 36 incidéntov, v katérih so hrváška plovíla 52 krat zaplúla v vóde, ki veljájo kot obmóčje Slovénskega nadzóra, tórej préko čŕte, ki označúje trí četrtíne Piránskega zalíva.\n",
      "\n",
      "Slovénska policíja sícer zagotávlja, da ne povzróča incidéntov in oprávlja nalóge enáko kot préd arbitrážno razsódbo. Hrváška strán pa ná vprašánje, zakáj vztrájno plúje dó sredíne zalíva, ne odgovárja.\n",
      "\n",
      "Ríbiči pojasnújejo, da ná obmóčju, kjér se dogájajo incidénti, lovíjo predvsém líste, hobótnice in kalámare. Ríbič Zlátko Novográdec je za 24UR dejál, da si vsí skúpaj želíjo čimpréjšnjo implementácijo razsódbe: \"Zdáj smo kot sardíne v konzérvi in s tístim kóščkom mórja bómo mogóče le málo zadíhali in zagotóvo se bó káka ríba véč znášla v mréži.\"\n",
      "\n",
      "Vprašánje pa je túdi, kakó bó v priméru incidéntov ríbiče zaščítila náša policíja. Téh informácij túdi ríbiči sámi – nímajo.\n",
      "\n",
      "Erjávec pozíva k résni razprávi: Tó ní véč héc\n",
      "\n",
      "Zunánji miníster Kárl Erjávec je danés v Brúslju pozvál k résni razprávi vláde tá téden o énostránskih dejánjih Hrváške v Piránskem zalívu, ki so pó njégovih besédah néposréden poség v suverénost Slovénije in schéngna. \"Tó pa ní véč héc,\" je poudáril miníster, ki pričakúje, da bó Sloveníja v povezávi s tém poslála písmo Evrópski komisíji.\n",
      "\n",
      "Miníster je obžalovál incidénte v Piránskem zalívu in opozoríl, da je Hrváška je vés čás želéla, da ne bi bílo énostránskih dejánj, zdáj pa sáma tó póčne. \"Pó izdáji arbitrážne odlóčbe je bílo 52 incidéntov, ki so énostránske naráve, ker gré za kršítve méje, dolóčene ná podlági arbitrážne odlóčbe,\" je izpostávil.\n",
      "\n",
      "Ob tém je opozoríl ná déjstvo \"izjémnega poména\" – da je slovénska júžna méja túdi zunánja schengénska méja, tako da ne gré véč zgólj za kršítev méje méd Sloveníjo in Hrváško, ámpak túdi za kršítev schengénske méje in právnega réda EU.\n",
      "\n",
      "Erjávec méni, da bó tréba tá téden v okvíru vláde, s predsédnikom vláde, in túdi v okvíru koalícije opráviti résno razprávo o tém, káj pomeníjo tá énostránska ravnánja hrváške straní. \"Tákšna énostránska dejánja so néposréden poség v suverénost Slovénije in suverénost schéngna. Tó pa ní véč héc,\" je dejál.\n",
      "\n",
      "Véč kot dvé tretjíni Hrvátov ocenjújeta, da smo prí arbitráži Slovénci uspéšneje pojasnjeváli svója stalíšča\n",
      "\n",
      "Pó razsódbi arbitrážnega sodíšča o méji méd Sloveníjo in Hrváško ná mórju in kópnem 56 odstótkov hrváških državljánov méni, da je sódba v príd Slovéniji, je pokazála raziskáva, ki jo je v nedéljo zvečér objávila hrváška komerciálna Nóva TV. Priblížno tretjína vprášanih méni, da bó Hrváška ná kóncu sprejéla razsódbo.\n",
      "\n",
      "Raziskáva agéncije Ípsos, v katéri je 13. in 14. júlija sodeloválo 612 anketírancev, je šé pokazála, da 12 odstótkov vprášanih méni, da je bíla razsódba ugódnejša za Hrváško. Da stá obé držávi dobíli priblížno enáko, je ocenílo pet odstótkov Hrvátov, da sódba ní bíla ugódna ne za Hrváško in ne za Sloveníjo, je prepríčanih osem odstótkov Hrvátov, medtém ko jih 19 odstótkov ne vé.\n",
      "\n",
      "Odločítev hrváškega sabóra iz léta 2015, da bó Hrváška izstopíla iz arbitrážnega postópka in ne bó sprejéla odločítve sodíšča, podpiráta dvé tretjíni anketírancev. Priblížno četrtína hrváških državljánov ne podpíra stalíšča hrváške vláde, da ne bódo sprejéli razsódbe, enájst odstótkov se jih ní móglo odločíti.\n",
      "\n",
      "Nekáj mánj kot 40 odstótkov vprášanih je menílo, da bósta Hrváška in Sloveníja doségli nóvo rešítev, kljúb prítiskom Evrópske komisíje in Nemčíje, naj Hrváška uveljávi razsódbo. Da bó Hrváška ná kóncu popustíla in sprejéla razsódbo, pričakúje 31 odstótkov vprášanih, da ne bó popustíla, pa nekáj véč kot petína.\n",
      "\n",
      "Véč kot dvé tretjíni vprášanih je ocenílo, da je Sloveníja článicam Evrópske uníje uspéšneje pojasnjevála svója stalíšča, medtém ko jih je 14 odstótkov menílo, da je bólje lobírala Hrváška.\n",
      "\n",
      "Hrváški državljáni so razdeljéni prí vprašánju, kdó je bólje lobíral za Hrváško, predsédnica držáve Kolínda Grabar-Kitarović ali premíer Ándrej Plenković. Za predsédnico je 29 odstótkov vprášanih, za premíerja pa 26 odstótkov. Da stá oba lobírala enáko, je menílo 16 odstótkov vprášanih, 15 odstótkov pa je tístih, ki so oceníli, da níhče ní lobíral. \"Ne vém\" je bíl odgóvor 14 odstótkov vprášanih.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "original_text_list = list(original_text)\n",
    "original_text_lowercase = original_text.lower()\n",
    "end_pos = 0\n",
    "for word in words_and_accetuation_loc:\n",
    "    start_pos = original_text_lowercase.find(word[0], end_pos)\n",
    "    end_pos = start_pos + len(word[0])\n",
    "    original_text_list[start_pos:end_pos] = list(accetuate_word(''.join(original_text_list[start_pos:end_pos]), word[1]))\n",
    "\n",
    "print(''.join(original_text_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['uradni', [2]],\n",
       " ['podatki', [2]],\n",
       " ['policije', [3]],\n",
       " ['kažejo', [1]],\n",
       " ['na', [1]],\n",
       " ['precej', [2]],\n",
       " ['napete', [2]],\n",
       " ['razmere', [2]],\n",
       " ['v', [1]],\n",
       " ['piranskem', [2]],\n",
       " ['zalivu', [2]],\n",
       " ['je', [0, 1]],\n",
       " ['danes', [2]],\n",
       " ['poročala', [2]],\n",
       " ['oddaja', [2]],\n",
       " ['do', [1]],\n",
       " ['danes', [2]],\n",
       " ['se', [0]],\n",
       " ['je', [0, 1]],\n",
       " ['zgodilo', [2]],\n",
       " ['že', [1]],\n",
       " ['incidentov', [3]],\n",
       " ['v', [1]],\n",
       " ['katerih', [2]],\n",
       " ['so', [0, 1]],\n",
       " ['hrvaška', [2]],\n",
       " ['plovila', [2]],\n",
       " ['krat', []],\n",
       " ['zaplula', [2]],\n",
       " ['v', [1]],\n",
       " ['vode', [1]],\n",
       " ['ki', [0]],\n",
       " ['veljajo', [2]],\n",
       " ['kot', [0]],\n",
       " ['območje', [2]],\n",
       " ['slovenskega', [2]],\n",
       " ['nadzora', [2]],\n",
       " ['torej', [1]],\n",
       " ['preko', [1]],\n",
       " ['črte', [1]],\n",
       " ['ki', [0]],\n",
       " ['označuje', [3]],\n",
       " ['tri', [1]],\n",
       " ['četrtine', [3]],\n",
       " ['piranskega', [2]],\n",
       " ['zaliva', [2]],\n",
       " ['slovenska', [2]],\n",
       " ['policija', [3]],\n",
       " ['sicer', [1]],\n",
       " ['zagotavlja', [3]],\n",
       " ['da', [0]],\n",
       " ['ne', [0, 1]],\n",
       " ['povzroča', [2]],\n",
       " ['incidentov', [3]],\n",
       " ['in', [0]],\n",
       " ['opravlja', [2]],\n",
       " ['naloge', [2]],\n",
       " ['enako', [2]],\n",
       " ['kot', [0]],\n",
       " ['pred', [1]],\n",
       " ['arbitražno', [3]],\n",
       " ['razsodbo', [2]],\n",
       " ['hrvaška', [2]],\n",
       " ['stran', [1]],\n",
       " ['pa', [0]],\n",
       " ['na', [1]],\n",
       " ['vprašanje', [2]],\n",
       " ['zakaj', [2]],\n",
       " ['vztrajno', [1]],\n",
       " ['pluje', [1]],\n",
       " ['do', [1]],\n",
       " ['sredine', [2]],\n",
       " ['zaliva', [2]],\n",
       " ['ne', [0, 1]],\n",
       " ['odgovarja', [3]],\n",
       " ['ribiči', [1]],\n",
       " ['pojasnujejo', [3]],\n",
       " ['da', [0]],\n",
       " ['na', [1]],\n",
       " ['območju', [2]],\n",
       " ['kjer', [1]],\n",
       " ['se', [0]],\n",
       " ['dogajajo', [2]],\n",
       " ['incidenti', [3]],\n",
       " ['lovijo', [2]],\n",
       " ['predvsem', [2]],\n",
       " ['liste', [1]],\n",
       " ['hobotnice', [2]],\n",
       " ['in', [0]],\n",
       " ['kalamare', [2]],\n",
       " ['ribič', [1]],\n",
       " ['zlatko', [1]],\n",
       " ['novogradec', [3]],\n",
       " ['je', [0, 1]],\n",
       " ['za', [0]],\n",
       " ['dejal', [2]],\n",
       " ['da', [0]],\n",
       " ['si', [0]],\n",
       " ['vsi', [1]],\n",
       " ['skupaj', [1]],\n",
       " ['želijo', [2]],\n",
       " ['čimprejšnjo', [2]],\n",
       " ['implementacijo', [4]],\n",
       " ['razsodbe', [2]],\n",
       " ['zdaj', [1]],\n",
       " ['smo', [0, 1]],\n",
       " ['kot', [0]],\n",
       " ['sardine', [2]],\n",
       " ['v', [1]],\n",
       " ['konzervi', [2]],\n",
       " ['in', [0]],\n",
       " ['s', [1]],\n",
       " ['tistim', [1]],\n",
       " ['koščkom', [1]],\n",
       " ['morja', [1]],\n",
       " ['bomo', [1]],\n",
       " ['mogoče', [2]],\n",
       " ['le', [0, 1]],\n",
       " ['malo', [1]],\n",
       " ['zadihali', [2]],\n",
       " ['in', [0]],\n",
       " ['zagotovo', [3]],\n",
       " ['se', [0]],\n",
       " ['bo', [1]],\n",
       " ['kaka', [1]],\n",
       " ['riba', [1]],\n",
       " ['več', [1]],\n",
       " ['znašla', [1]],\n",
       " ['v', [1]],\n",
       " ['mreži', [1]],\n",
       " ['vprašanje', [2]],\n",
       " ['pa', [0]],\n",
       " ['je', [0, 1]],\n",
       " ['tudi', [1]],\n",
       " ['kako', [2]],\n",
       " ['bo', [1]],\n",
       " ['v', [1]],\n",
       " ['primeru', [2]],\n",
       " ['incidentov', [3]],\n",
       " ['ribiče', [1]],\n",
       " ['zaščitila', [2]],\n",
       " ['naša', [1]],\n",
       " ['policija', [3]],\n",
       " ['teh', [1]],\n",
       " ['informacij', [3]],\n",
       " ['tudi', [1]],\n",
       " ['ribiči', [1]],\n",
       " ['sami', [1]],\n",
       " ['nimajo', [1]],\n",
       " ['erjavec', [2]],\n",
       " ['poziva', [2]],\n",
       " ['k', [1]],\n",
       " ['resni', [1]],\n",
       " ['razpravi', [2]],\n",
       " ['to', [1]],\n",
       " ['ni', [1]],\n",
       " ['več', [1]],\n",
       " ['hec', [1]],\n",
       " ['zunanji', [2]],\n",
       " ['minister', [2]],\n",
       " ['karl', [1]],\n",
       " ['erjavec', [2]],\n",
       " ['je', [0, 1]],\n",
       " ['danes', [2]],\n",
       " ['v', [1]],\n",
       " ['bruslju', [1]],\n",
       " ['pozval', [2]],\n",
       " ['k', [1]],\n",
       " ['resni', [1]],\n",
       " ['razpravi', [2]],\n",
       " ['vlade', [1]],\n",
       " ['ta', [1]],\n",
       " ['teden', [1]],\n",
       " ['o', [0]],\n",
       " ['enostranskih', [1, 3]],\n",
       " ['dejanjih', [2]],\n",
       " ['hrvaške', [2]],\n",
       " ['v', [1]],\n",
       " ['piranskem', [2]],\n",
       " ['zalivu', [2]],\n",
       " ['ki', [0]],\n",
       " ['so', [0, 1]],\n",
       " ['po', [1]],\n",
       " ['njegovih', [1]],\n",
       " ['besedah', [2]],\n",
       " ['neposreden', [1, 3]],\n",
       " ['poseg', [2]],\n",
       " ['v', [1]],\n",
       " ['suverenost', [3]],\n",
       " ['slovenije', [2]],\n",
       " ['in', [0]],\n",
       " ['schengna', [1]],\n",
       " ['to', [1]],\n",
       " ['pa', [0]],\n",
       " ['ni', [1]],\n",
       " ['več', [1]],\n",
       " ['hec', [1]],\n",
       " ['je', [0, 1]],\n",
       " ['poudaril', [3]],\n",
       " ['minister', [2]],\n",
       " ['ki', [0]],\n",
       " ['pričakuje', [3]],\n",
       " ['da', [0]],\n",
       " ['bo', [1]],\n",
       " ['slovenija', [3]],\n",
       " ['v', [1]],\n",
       " ['povezavi', [3]],\n",
       " ['s', [1]],\n",
       " ['tem', [1]],\n",
       " ['poslala', [2]],\n",
       " ['pismo', [1]],\n",
       " ['evropski', [2]],\n",
       " ['komisiji', [3]],\n",
       " ['minister', [2]],\n",
       " ['je', [0, 1]],\n",
       " ['obžaloval', [4]],\n",
       " ['incidente', [3]],\n",
       " ['v', [1]],\n",
       " ['piranskem', [2]],\n",
       " ['zalivu', [2]],\n",
       " ['in', [0]],\n",
       " ['opozoril', [4]],\n",
       " ['da', [0]],\n",
       " ['je', [0, 1]],\n",
       " ['hrvaška', [2]],\n",
       " ['je', [0, 1]],\n",
       " ['ves', [1]],\n",
       " ['čas', [1]],\n",
       " ['želela', [2]],\n",
       " ['da', [0]],\n",
       " ['ne', [0, 1]],\n",
       " ['bi', [0, 1]],\n",
       " ['bilo', [1]],\n",
       " ['enostranskih', [1, 3]],\n",
       " ['dejanj', [2]],\n",
       " ['zdaj', [1]],\n",
       " ['pa', [0]],\n",
       " ['sama', [1]],\n",
       " ['to', [1]],\n",
       " ['počne', [1]],\n",
       " ['po', [1]],\n",
       " ['izdaji', [2]],\n",
       " ['arbitražne', [3]],\n",
       " ['odločbe', [2]],\n",
       " ['je', [0, 1]],\n",
       " ['bilo', [1]],\n",
       " ['incidentov', [3]],\n",
       " ['ki', [0]],\n",
       " ['so', [0, 1]],\n",
       " ['enostranske', [1, 3]],\n",
       " ['narave', [2]],\n",
       " ['ker', [0]],\n",
       " ['gre', [1]],\n",
       " ['za', [0]],\n",
       " ['kršitve', [2]],\n",
       " ['meje', [1]],\n",
       " ['določene', [2]],\n",
       " ['na', [1]],\n",
       " ['podlagi', [2]],\n",
       " ['arbitražne', [3]],\n",
       " ['odločbe', [2]],\n",
       " ['je', [0, 1]],\n",
       " ['izpostavil', [3]],\n",
       " ['ob', [0]],\n",
       " ['tem', [1]],\n",
       " ['je', [0, 1]],\n",
       " ['opozoril', [4]],\n",
       " ['na', [1]],\n",
       " ['dejstvo', [1]],\n",
       " ['izjemnega', [2]],\n",
       " ['pomena', [2]],\n",
       " ['da', [0]],\n",
       " ['je', [0, 1]],\n",
       " ['slovenska', [2]],\n",
       " ['južna', [1]],\n",
       " ['meja', [1]],\n",
       " ['tudi', [1]],\n",
       " ['zunanja', [2]],\n",
       " ['schengenska', [2]],\n",
       " ['meja', [1]],\n",
       " ['tako', [0]],\n",
       " ['da', [0]],\n",
       " ['ne', [0, 1]],\n",
       " ['gre', [1]],\n",
       " ['več', [1]],\n",
       " ['zgolj', [1]],\n",
       " ['za', [0]],\n",
       " ['kršitev', [2]],\n",
       " ['meje', [1]],\n",
       " ['med', [1]],\n",
       " ['slovenijo', [3]],\n",
       " ['in', [0]],\n",
       " ['hrvaško', [2]],\n",
       " ['ampak', [1]],\n",
       " ['tudi', [1]],\n",
       " ['za', [0]],\n",
       " ['kršitev', [2]],\n",
       " ['schengenske', [2]],\n",
       " ['meje', [1]],\n",
       " ['in', [0]],\n",
       " ['pravnega', [1]],\n",
       " ['reda', [1]],\n",
       " ['eu', []],\n",
       " ['erjavec', [2]],\n",
       " ['meni', [1]],\n",
       " ['da', [0]],\n",
       " ['bo', [1]],\n",
       " ['treba', [1]],\n",
       " ['ta', [1]],\n",
       " ['teden', [1]],\n",
       " ['v', [1]],\n",
       " ['okviru', [2]],\n",
       " ['vlade', [1]],\n",
       " ['s', [1]],\n",
       " ['predsednikom', [2]],\n",
       " ['vlade', [1]],\n",
       " ['in', [0]],\n",
       " ['tudi', [1]],\n",
       " ['v', [1]],\n",
       " ['okviru', [2]],\n",
       " ['koalicije', [3]],\n",
       " ['opraviti', [2]],\n",
       " ['resno', [1]],\n",
       " ['razpravo', [2]],\n",
       " ['o', [0]],\n",
       " ['tem', [1]],\n",
       " ['kaj', [1]],\n",
       " ['pomenijo', [3]],\n",
       " ['ta', [1]],\n",
       " ['enostranska', [1, 3]],\n",
       " ['ravnanja', [2]],\n",
       " ['hrvaške', [2]],\n",
       " ['strani', [2]],\n",
       " ['takšna', [1]],\n",
       " ['enostranska', [1, 3]],\n",
       " ['dejanja', [2]],\n",
       " ['so', [0, 1]],\n",
       " ['neposreden', [1, 3]],\n",
       " ['poseg', [2]],\n",
       " ['v', [1]],\n",
       " ['suverenost', [3]],\n",
       " ['slovenije', [2]],\n",
       " ['in', [0]],\n",
       " ['suverenost', [3]],\n",
       " ['schengna', [1]],\n",
       " ['to', [1]],\n",
       " ['pa', [0]],\n",
       " ['ni', [1]],\n",
       " ['več', [1]],\n",
       " ['hec', [1]],\n",
       " ['je', [0, 1]],\n",
       " ['dejal', [2]],\n",
       " ['več', [1]],\n",
       " ['kot', [0]],\n",
       " ['dve', [1]],\n",
       " ['tretjini', [2]],\n",
       " ['hrvatov', [2]],\n",
       " ['ocenjujeta', [3]],\n",
       " ['da', [0]],\n",
       " ['smo', [0, 1]],\n",
       " ['pri', [1]],\n",
       " ['arbitraži', [3]],\n",
       " ['slovenci', [2]],\n",
       " ['uspešneje', [2]],\n",
       " ['pojasnjevali', [4]],\n",
       " ['svoja', [1]],\n",
       " ['stališča', [2]],\n",
       " ['po', [1]],\n",
       " ['razsodbi', [2]],\n",
       " ['arbitražnega', [3]],\n",
       " ['sodišča', [2]],\n",
       " ['o', [0]],\n",
       " ['meji', [1]],\n",
       " ['med', [1]],\n",
       " ['slovenijo', [3]],\n",
       " ['in', [0]],\n",
       " ['hrvaško', [2]],\n",
       " ['na', [1]],\n",
       " ['morju', [1]],\n",
       " ['in', [0]],\n",
       " ['kopnem', [1]],\n",
       " ['odstotkov', [2]],\n",
       " ['hrvaških', [2]],\n",
       " ['državljanov', [3]],\n",
       " ['meni', [1]],\n",
       " ['da', [0]],\n",
       " ['je', [0, 1]],\n",
       " ['sodba', [1]],\n",
       " ['v', [1]],\n",
       " ['prid', [1]],\n",
       " ['sloveniji', [2]],\n",
       " ['je', [0, 1]],\n",
       " ['pokazala', [3]],\n",
       " ['raziskava', [3]],\n",
       " ['ki', [0]],\n",
       " ['jo', [0]],\n",
       " ['je', [0, 1]],\n",
       " ['v', [1]],\n",
       " ['nedeljo', [2]],\n",
       " ['zvečer', [2]],\n",
       " ['objavila', [2]],\n",
       " ['hrvaška', [2]],\n",
       " ['komercialna', [4]],\n",
       " ['nova', [1]],\n",
       " ['tv', [1]],\n",
       " ['približno', [2]],\n",
       " ['tretjina', [2]],\n",
       " ['vprašanih', [1]],\n",
       " ['meni', [1]],\n",
       " ['da', [0]],\n",
       " ['bo', [1]],\n",
       " ['hrvaška', [2]],\n",
       " ['na', [1]],\n",
       " ['koncu', [1]],\n",
       " ['sprejela', [2]],\n",
       " ['razsodbo', [2]],\n",
       " ['raziskava', [3]],\n",
       " ['agencije', [2]],\n",
       " ['ipsos', [1]],\n",
       " ['v', [1]],\n",
       " ['kateri', [2]],\n",
       " ['je', [0, 1]],\n",
       " ['in', [0]],\n",
       " ['julija', [1]],\n",
       " ['sodelovalo', [4]],\n",
       " ['anketirancev', [3]],\n",
       " ['je', [0, 1]],\n",
       " ['še', [1]],\n",
       " ['pokazala', [3]],\n",
       " ['da', [0]],\n",
       " ['odstotkov', [2]],\n",
       " ['vprašanih', [1]],\n",
       " ['meni', [1]],\n",
       " ['da', [0]],\n",
       " ['je', [0, 1]],\n",
       " ['bila', [1]],\n",
       " ['razsodba', [2]],\n",
       " ['ugodnejša', [2]],\n",
       " ['za', [0]],\n",
       " ['hrvaško', [2]],\n",
       " ['da', [0]],\n",
       " ['sta', [1]],\n",
       " ['obe', [2]],\n",
       " ['državi', [2]],\n",
       " ['dobili', [2]],\n",
       " ['približno', [2]],\n",
       " ['enako', [2]],\n",
       " ['je', [0, 1]],\n",
       " ['ocenilo', [3]],\n",
       " ['pet', []],\n",
       " ['odstotkov', [2]],\n",
       " ['hrvatov', [2]],\n",
       " ['da', [0]],\n",
       " ['sodba', [1]],\n",
       " ['ni', [1]],\n",
       " ['bila', [1]],\n",
       " ['ugodna', [2]],\n",
       " ['ne', [0, 1]],\n",
       " ['za', [0]],\n",
       " ['hrvaško', [2]],\n",
       " ['in', [0]],\n",
       " ['ne', [0, 1]],\n",
       " ['za', [0]],\n",
       " ['slovenijo', [3]],\n",
       " ['je', [0, 1]],\n",
       " ['prepričanih', [2]],\n",
       " ['osem', []],\n",
       " ['odstotkov', [2]],\n",
       " ['hrvatov', [2]],\n",
       " ['medtem', [2]],\n",
       " ['ko', [0]],\n",
       " ['jih', [0]],\n",
       " ['odstotkov', [2]],\n",
       " ['ne', [0, 1]],\n",
       " ['ve', [1]],\n",
       " ['odločitev', [3]],\n",
       " ['hrvaškega', [2]],\n",
       " ['sabora', [2]],\n",
       " ['iz', [0]],\n",
       " ['leta', [1]],\n",
       " ['da', [0]],\n",
       " ['bo', [1]],\n",
       " ['hrvaška', [2]],\n",
       " ['izstopila', [3]],\n",
       " ['iz', [0]],\n",
       " ['arbitražnega', [3]],\n",
       " ['postopka', [2]],\n",
       " ['in', [0]],\n",
       " ['ne', [0, 1]],\n",
       " ['bo', [1]],\n",
       " ['sprejela', [2]],\n",
       " ['odločitve', [3]],\n",
       " ['sodišča', [2]],\n",
       " ['podpirata', [3]],\n",
       " ['dve', [1]],\n",
       " ['tretjini', [2]],\n",
       " ['anketirancev', [3]],\n",
       " ['približno', [2]],\n",
       " ['četrtina', [3]],\n",
       " ['hrvaških', [2]],\n",
       " ['državljanov', [3]],\n",
       " ['ne', [0, 1]],\n",
       " ['podpira', [2]],\n",
       " ['stališča', [2]],\n",
       " ['hrvaške', [2]],\n",
       " ['vlade', [1]],\n",
       " ['da', [0]],\n",
       " ['ne', [0, 1]],\n",
       " ['bodo', [1]],\n",
       " ['sprejeli', [2]],\n",
       " ['razsodbe', [2]],\n",
       " ['enajst', [2]],\n",
       " ['odstotkov', [2]],\n",
       " ['se', [0]],\n",
       " ['jih', [0]],\n",
       " ['ni', [1]],\n",
       " ['moglo', [1]],\n",
       " ['odločiti', [3]],\n",
       " ['nekaj', [2]],\n",
       " ['manj', [1]],\n",
       " ['kot', [0]],\n",
       " ['odstotkov', [2]],\n",
       " ['vprašanih', [1]],\n",
       " ['je', [0, 1]],\n",
       " ['menilo', [2]],\n",
       " ['da', [0]],\n",
       " ['bosta', [1]],\n",
       " ['hrvaška', [2]],\n",
       " ['in', [0]],\n",
       " ['slovenija', [3]],\n",
       " ['dosegli', [2]],\n",
       " ['novo', [1]],\n",
       " ['rešitev', [2]],\n",
       " ['kljub', [1]],\n",
       " ['pritiskom', [1]],\n",
       " ['evropske', [2]],\n",
       " ['komisije', [3]],\n",
       " ['in', [0]],\n",
       " ['nemčije', [2]],\n",
       " ['naj', [0]],\n",
       " ['hrvaška', [2]],\n",
       " ['uveljavi', [3]],\n",
       " ['razsodbo', [2]],\n",
       " ['da', [0]],\n",
       " ['bo', [1]],\n",
       " ['hrvaška', [2]],\n",
       " ['na', [1]],\n",
       " ['koncu', [1]],\n",
       " ['popustila', [3]],\n",
       " ['in', [0]],\n",
       " ['sprejela', [2]],\n",
       " ['razsodbo', [2]],\n",
       " ['pričakuje', [3]],\n",
       " ['odstotkov', [2]],\n",
       " ['vprašanih', [1]],\n",
       " ['da', [0]],\n",
       " ['ne', [0, 1]],\n",
       " ['bo', [1]],\n",
       " ['popustila', [3]],\n",
       " ['pa', [0]],\n",
       " ['nekaj', [2]],\n",
       " ['več', [1]],\n",
       " ['kot', [0]],\n",
       " ['petina', [2]],\n",
       " ['več', [1]],\n",
       " ['kot', [0]],\n",
       " ['dve', [1]],\n",
       " ['tretjini', [2]],\n",
       " ['vprašanih', [1]],\n",
       " ['je', [0, 1]],\n",
       " ['ocenilo', [3]],\n",
       " ['da', [0]],\n",
       " ['je', [0, 1]],\n",
       " ['slovenija', [3]],\n",
       " ['članicam', [1]],\n",
       " ['evropske', [2]],\n",
       " ['unije', [2]],\n",
       " ['uspešneje', [2]],\n",
       " ['pojasnjevala', [4]],\n",
       " ['svoja', [1]],\n",
       " ['stališča', [2]],\n",
       " ['medtem', [2]],\n",
       " ['ko', [0]],\n",
       " ['jih', [0]],\n",
       " ['je', [0, 1]],\n",
       " ['odstotkov', [2]],\n",
       " ['menilo', [2]],\n",
       " ['da', [0]],\n",
       " ['je', [0, 1]],\n",
       " ['bolje', [1]],\n",
       " ['lobirala', [2]],\n",
       " ['hrvaška', [2]],\n",
       " ['hrvaški', [2]],\n",
       " ['državljani', [3]],\n",
       " ['so', [0, 1]],\n",
       " ['razdeljeni', [3]],\n",
       " ['pri', [1]],\n",
       " ['vprašanju', [2]],\n",
       " ['kdo', [1]],\n",
       " ['je', [0, 1]],\n",
       " ['bolje', [1]],\n",
       " ['lobiral', [2]],\n",
       " ['za', [0]],\n",
       " ['hrvaško', [2]],\n",
       " ['predsednica', [2]],\n",
       " ['države', [2]],\n",
       " ['kolinda', [2]],\n",
       " ['grabar-kitarovič', [4]],\n",
       " ['ali', [0]],\n",
       " ['premier', [2]],\n",
       " ['andrej', [1]],\n",
       " ['plenkovič', [3]],\n",
       " ['za', [0]],\n",
       " ['predsednico', [2]],\n",
       " ['je', [0, 1]],\n",
       " ['odstotkov', [2]],\n",
       " ['vprašanih', [1]],\n",
       " ['za', [0]],\n",
       " ['premierja', [2]],\n",
       " ['pa', [0]],\n",
       " ['odstotkov', [2]],\n",
       " ['da', [0]],\n",
       " ['sta', [1]],\n",
       " ['oba', [0]],\n",
       " ['lobirala', [2]],\n",
       " ['enako', [2]],\n",
       " ['je', [0, 1]],\n",
       " ['menilo', [2]],\n",
       " ['odstotkov', [2]],\n",
       " ['vprašanih', [1]],\n",
       " ['odstotkov', [2]],\n",
       " ['pa', [0]],\n",
       " ['je', [0, 1]],\n",
       " ['tistih', [1]],\n",
       " ['ki', [0]],\n",
       " ['so', [0, 1]],\n",
       " ['ocenili', [3]],\n",
       " ['da', [0]],\n",
       " ['nihče', [1]],\n",
       " ['ni', [1]],\n",
       " ['lobiral', [2]],\n",
       " ['ne', [0, 1]],\n",
       " ['vem', [1]],\n",
       " ['je', [0, 1]],\n",
       " ['bil', [1]],\n",
       " ['odgovor', [2]],\n",
       " ['odstotkov', [2]],\n",
       " ['vprašanih', [1]]]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_and_accetuation_loc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
